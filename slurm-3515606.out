/var/lib/slurm/slurmd/job3515606/slurm_script: line 9: batch_scripts/MT50_batch/seed.sh: No such file or directory
SLURM_JOBID=3515606
working directory=/viscam/u/jialugao/Imitation-SoftModule
########################
logging outputs to  /viscam/u/jialugao/Imitation-SoftModule/data/Base_bc_reach_window-close-v1_2640.000125-01-2022_23-01-54
########################
{'expert_policy_file': '../Multi-Task-RL/log/MT50_Single_Task/window-close-v1/Fixed/238/model/model_pf_best.pth', 'exp_name': 'bc_reach', 'do_dagger': False, 'ep_len': 200, 'gradient_steps': 1, 'n_iter': 10000, 'render_interval': 1, 'eval_interval': 200, 'batch_size': 64, 'eval_batch_size': 32, 'train_batch_size': 32, 'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'video_log_freq': -1, 'scalar_log_freq': 1, 'no_gpu': False, 'which_gpu': 0, 'max_replay_buffer_size': 1000000, 'save_params': False, 'seed': 32, 'worker_nums': 1, 'eval_worker_nums': 1, 'config': 'config/BC.json', 'no_cuda': True, 'random_init': False, 'device': 'cpu', 'id': 'MT50_Single_Task', 'task_name': 'window-close-v1', 'task_env': 'MT50_task_env', 'cuda': False, 'log_dir': '/viscam/u/jialugao/Imitation-SoftModule/data/Base_bc_reach_window-close-v1_2640.000125-01-2022_23-01-54', 'agent_class': <class 'agents.bc_agent.MLPAgent'>, 'agent_params': {'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'max_replay_buffer_size': 1000000, 'discrete': False, 'ac_dim': 4, 'ob_dim': 9}}
{'env_name': 'single_task', 'env': {'reward_scale': 1, 'obs_norm': False}, 'meta_env': {'obs_type': 'with_goal', 'random_init': False}, 'replay_buffer': {'size': 1000000.0}, 'net': {'hidden_shapes': [400, 400], 'append_hidden_shapes': [400], 'base_type': <class 'networks.base.MLPBase'>}, 'general_setting': {'discount': 0.99, 'pretrain_epochs': 20, 'num_epochs': 7500, 'epoch_frames': 200, 'max_episode_frames': 200, 'batch_size': 1280, 'min_pool': 10000, 'target_hard_update_period': 1000, 'use_soft_update': True, 'tau': 0.005, 'opt_times': 200, 'eval_episodes': 100, 'train_render': False, 'eval_render': False, 'env': <NormAct<RewardShift<SingleWrapperNone>>>, 'logger': <utils.logger.Logger object at 0x7f1e274f6f10>, 'device': device(type='cpu')}, 'sac': {'plr': 0.0003, 'qlr': 0.0003, 'reparameterization': True, 'automatic_entropy_tuning': True, 'policy_std_reg_weight': 0, 'policy_mean_reg_weight': 0}}
Loading expert policy from... ../Multi-Task-RL/log/MT50_Single_Task/window-close-v1/Fixed/238/model/model_pf_best.pth
tensor([[ 0.0827, -0.0212, -0.0631,  ...,  0.0045, -0.0244, -0.0703],
        [ 0.0094, -0.0367, -0.0412,  ...,  0.0480, -0.0070, -0.0776],
        [ 0.0037, -0.0818, -0.0599,  ...,  0.0370, -0.0274, -0.0492],
        ...,
        [ 1.7904, -0.6646,  0.1201,  ..., -0.0313,  0.0626,  0.0672],
        [-0.0128, -0.0481, -0.0513,  ..., -0.0026, -0.0020, -0.0261],
        [ 0.0080, -0.0131, -0.0708,  ...,  0.0225, -0.0586, -0.0263]])
Done restoring expert policy...
<NormAct<RewardShift<AugObs<SawyerWindowCloseEnv instance>>>>


-------------------------------- Iteration 0 -------------------------------- 
initial ob: [-0.03445605  0.50704462  0.23981209  0.12        0.73000003  0.15000001
 -0.08        0.785       0.15       -0.08        0.785       0.15      ]
expert:[ 0.78797233  0.8097568   0.72471565 -0.1359227 ]
expert:[ 0.9858839   0.93762064  0.13594571 -0.8721751 ]
expert:[ 0.99365836  0.9362953  -0.2846213  -0.90716434]
expert:[ 0.9927276   0.8791433  -0.58815426 -0.7941038 ]
expert:[ 0.990528    0.71853393 -0.7127966  -0.7257434 ]
expert:[ 0.9910239   0.49899337 -0.6435265  -0.7039158 ]
expert:[ 0.9946711   0.31101206  0.26972172 -0.5536467 ]
expert:[ 0.9954318  -0.14465126  0.8338946  -0.35146046]
expert:[ 0.9952917  -0.4043629   0.9199861  -0.03780571]
expert:[ 0.9916221  -0.11976755  0.83598137 -0.03068186]
expert:[0.98932904 0.91680187 0.35171643 0.09815071]
expert:[ 0.9812979   0.9653626  -0.53940237 -0.5206396 ]
expert:[ 0.97292954  0.9961252  -0.9787171  -0.9259401 ]
expert:[ 0.91156983  0.9980973  -0.990655   -0.9780224 ]
expert:[-0.5893312   0.99756813 -0.99305135 -0.9930876 ]
expert:[-0.9816773   0.9976828  -0.9938985  -0.99309295]
expert:[-0.9923096  0.9969253 -0.9924394 -0.9933441]
expert:[-0.99223363  0.9967646  -0.9913516  -0.99304587]
expert:[-0.9908939  0.9779626 -0.9363259 -0.9686477]
expert:[-0.97992426 -0.30965716 -0.22320934 -0.30679744]
expert:[-0.9836971  -0.36680758 -0.07734554 -0.22078171]
expert:[-0.9870012  -0.26324016  0.25082815 -0.47357434]
expert:[-0.9855615 -0.3045171  0.264306  -0.4304021]
expert:[-0.9845522  -0.3285702   0.30019456 -0.42490458]
expert:[-0.9844474  -0.32924694  0.37226796 -0.46978468]
expert:[-0.98500836 -0.3355201   0.40255016 -0.50501823]
expert:[-0.9855453  -0.34827927  0.43150795 -0.54771984]
expert:[-0.98593706 -0.3696025   0.45049426 -0.5842059 ]
expert:[-0.9850634  -0.39359456  0.39174497 -0.5737265 ]
expert:[-0.98376757 -0.43312424  0.29242912 -0.54749024]
expert:[-0.9820195  -0.461369    0.17543258 -0.50028294]
expert:[-0.97984767 -0.49168015  0.00919871 -0.42992237]
expert:[-0.9771294  -0.4793855  -0.12207256 -0.40300363]
expert:[-0.9752482  -0.4488583  -0.25654188 -0.37726182]
expert:[-0.9740431  -0.44617918 -0.31429812 -0.37063465]
expert:[-0.9753305  -0.43265748 -0.2759102  -0.17231213]
expert:[-0.9887566  -0.44751784 -0.85119534  0.48971188]
expert:[-0.987791   -0.42648834 -0.85629463  0.5157237 ]
expert:[-0.98071694 -0.40770552 -0.7420692   0.4063128 ]
expert:[-0.9734484  -0.38979605 -0.5698718   0.31919044]
expert:[-0.9690527  -0.3492319  -0.31258127  0.11978126]
expert:[-0.9731675  -0.3232011  -0.17767133 -0.02524145]
expert:[-0.9758106  -0.32211035 -0.19259222 -0.12358432]
expert:[-0.97843635 -0.31740433 -0.31874487 -0.14403415]
expert:[-0.9811822  -0.31768343 -0.43703803 -0.13122475]
expert:[-0.9836855  -0.31574392 -0.5417385  -0.1010168 ]
expert:[-0.98497087 -0.31514186 -0.6153918  -0.07988364]
expert:[-0.9854069  -0.318318   -0.6697016  -0.06485743]
expert:[-0.9857186  -0.32507727 -0.71404946 -0.04744611]
expert:[-0.9853608  -0.33729517 -0.7497374  -0.02911469]
expert:[-0.98467124 -0.35562962 -0.78076965 -0.01330445]
expert:[-9.8387092e-01 -3.8034469e-01 -8.0043054e-01 -2.1570921e-04]
expert:[-0.98280895 -0.41408426 -0.8212098   0.0044601 ]
expert:[-0.9818159  -0.44766143 -0.8397727   0.00419927]
expert:[-0.979817   -0.4798745  -0.84868693 -0.0117067 ]
expert:[-0.97749096 -0.49156842 -0.85085374 -0.03352131]
expert:[-0.975098   -0.4960463  -0.84840596 -0.05248587]
expert:[-0.97244406 -0.5013593  -0.84458447 -0.07308634]
expert:[-0.9692771  -0.504559   -0.8427294  -0.08761153]
expert:[-0.96531445 -0.50386584 -0.84454733 -0.09142213]
expert:[-0.96044815 -0.5101173  -0.8479279  -0.09758319]
expert:[-0.95495516 -0.5390164  -0.85238916 -0.11312769]
expert:[-0.9485672  -0.56672245 -0.8570279  -0.12798621]
expert:[-0.942329   -0.5933687  -0.85959476 -0.13904046]
expert:[-0.94324446 -0.6183271  -0.8645644  -0.14825104]
expert:[-0.94626456 -0.6473795  -0.8684189  -0.160214  ]
expert:[-0.9490657  -0.672231   -0.8703212  -0.17183098]
expert:[-0.9490028  -0.6866193  -0.86517847 -0.17862065]
expert:[-0.9463842  -0.6927001  -0.8496447  -0.18233198]
expert:[-0.9410803  -0.7138497  -0.82586235 -0.18738064]
expert:[-0.9219596  -0.77739555 -0.75642335 -0.18676674]
expert:[-0.8847089  -0.82026917 -0.68587047 -0.15885696]
expert:[-0.82583433 -0.84975415 -0.6223788  -0.13064691]
expert:[-0.80632573 -0.8711917  -0.5621892  -0.04842994]
expert:[-0.7838956  -0.8855884  -0.4521565   0.06504063]
expert:[-0.75510013 -0.89157    -0.40422317  0.15154372]
expert:[-0.7213847  -0.8884096  -0.34027612  0.21119918]
expert:[-0.70352143 -0.8846379  -0.28323323  0.2623572 ]
expert:[-0.70781237 -0.87772924 -0.23194878  0.28824124]
expert:[-0.7122031  -0.8693239  -0.184584    0.30934933]
expert:[-0.7135895  -0.858215   -0.12271536  0.33210656]
expert:[-0.71307904 -0.8475654  -0.05746241  0.35522932]
expert:[-0.709499   -0.8358518   0.01518525  0.3868673 ]
expert:[-0.7068826  -0.8214356   0.09600633  0.43990752]
expert:[-0.7021172  -0.80794054  0.16401018  0.49055624]
expert:[-0.69679064 -0.797385    0.20830472  0.5316041 ]
expert:[-0.68652153 -0.78983295  0.22874367  0.55193824]
expert:[-0.67752564 -0.7839114   0.2451863   0.5692217 ]
expert:[-0.6709668  -0.77862364  0.25755838  0.5805096 ]
expert:[-0.6696221 -0.7756921  0.2631288  0.5820838]
expert:[-0.66502136 -0.7711714   0.26548776  0.5871112 ]
expert:[-0.6630414  -0.7675566   0.26302624  0.59192866]
expert:[-0.6623692  -0.75838965  0.2577934   0.5955824 ]
expert:[-0.66001564 -0.74428725  0.2464844   0.5979661 ]
expert:[-0.658392   -0.731149    0.23610687  0.60453427]
expert:[-0.65778965 -0.71987635  0.2272772   0.6173466 ]
expert:[-0.65722376 -0.70829767  0.21837497  0.62978673]
expert:[-0.65671533 -0.6963584   0.20956795  0.6417636 ]
expert:[-0.65884125 -0.6844525   0.19765398  0.6566972 ]
expert:[-0.6631079  -0.6723252   0.18372902  0.6724348 ]
expert:[-0.668021   -0.664019    0.17018735  0.6825093 ]
expert:[-0.67165726 -0.6547718   0.15591112  0.6921673 ]
expert:[-0.66199607 -0.63026434  0.1365041   0.70271087]
expert:[-0.6423422  -0.5892167   0.10270391  0.71249944]
expert:[-0.615381   -0.55082387  0.06132069  0.7216608 ]
expert:[-0.58474445 -0.5062361   0.02016056  0.73125654]
expert:[-0.5528536  -0.49929225 -0.02699091  0.7378199 ]
expert:[-0.519019   -0.49216205 -0.07364967  0.74419534]
expert:[-0.4808319  -0.48553714 -0.1221291   0.749561  ]
expert:[-0.4300346  -0.48931888 -0.12931478  0.7620336 ]
expert:[-0.42007983 -0.4956758  -0.13623774  0.76960045]
expert:[-0.42237175 -0.50275767 -0.14339143  0.77578   ]
expert:[-0.42455268 -0.5098933  -0.15051697  0.7818162 ]
expert:[-0.4285977  -0.5187072  -0.15999213  0.7902277 ]
expert:[-0.43366346 -0.527887   -0.16961941  0.7983518 ]
expert:[-0.44271252 -0.5369733  -0.1765561   0.8038216 ]
expert:[-0.45106593 -0.5457683  -0.18078534  0.8092394 ]
expert:[-0.4579612  -0.55374354 -0.17950994  0.8146588 ]
expert:[-0.46482602 -0.5616259  -0.1784403   0.8200325 ]
expert:[-0.47322476 -0.5663746  -0.177048    0.825881  ]
expert:[-0.48242676 -0.5701376  -0.17398688  0.83103937]
expert:[-0.491415   -0.5738801  -0.17069304  0.8360202 ]
expert:[-0.50015056 -0.57748866 -0.16714409  0.84083045]
expert:[-0.5087327  -0.58114326 -0.16370246  0.84549934]
expert:[-0.5170836  -0.5845189  -0.16010751  0.8498697 ]
expert:[-0.5252637  -0.5879251  -0.15652618  0.8541273 ]
expert:[-0.53326184 -0.5913103  -0.15289122  0.8582623 ]
expert:[-0.5383306  -0.593405   -0.14893152  0.86116207]
expert:[-0.5393184  -0.59380835 -0.14476252  0.86241585]
expert:[-0.53975475 -0.5942051  -0.14093627  0.8634664 ]
expert:[-0.5398448  -0.5945036  -0.13718261  0.864377  ]
expert:[-0.5396304  -0.5945896  -0.13337295  0.8651189 ]
expert:[-0.53919196 -0.5944533  -0.12962629  0.865665  ]
expert:[-0.5385059  -0.5941214  -0.12563795  0.86611557]
expert:[-0.5376972  -0.59380376 -0.12177753  0.86651754]
expert:[-0.53681755 -0.5934926  -0.11808495  0.86687374]
expert:[-0.5359346  -0.5931703  -0.11465822  0.8671792 ]
expert:[-0.5349886  -0.5927922  -0.11125982  0.86744434]
expert:[-0.53399533 -0.59238064 -0.10790211  0.8676793 ]
expert:[-0.5329399  -0.5918641  -0.10445926  0.8678754 ]
expert:[-0.5318379  -0.5913015  -0.10098661  0.8680492 ]
expert:[-0.5307624  -0.59079015 -0.09771483  0.86821413]
expert:[-0.52966404 -0.5902143  -0.09441111  0.86835396]
expert:[-0.5285596  -0.58971035 -0.0912106   0.8685022 ]
expert:[-0.52737427 -0.5891103  -0.08778483  0.8686336 ]
expert:[-0.52619815 -0.588624   -0.08451227  0.8687842 ]
expert:[-0.52493227 -0.5880368  -0.08097196  0.8689213 ]
expert:[-0.523636   -0.58749336 -0.07741687  0.86907   ]
expert:[-0.5223226 -0.5869927 -0.0738771  0.8692285]
expert:[-0.5209965  -0.5865158  -0.07034568  0.86939204]
expert_success: 1.0
path_length: 150
