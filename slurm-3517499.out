SLURM_JOBID=3517499
working directory=/viscam/u/jialugao/Imitation-SoftModule
{'obs_type': 'with_goal'}
obs type:  with_goal
{'expert_policy_file': 'policy/expert/MT10_Similar/', 'exp_name': 'bc_reach', 'do_dagger': False, 'ep_len': 200, 'gradient_steps': 1, 'n_iter': 100000, 'render_interval': 40, 'eval_interval': 1000, 'batch_size': 64, 'eval_batch_size': 32, 'train_batch_size': 32, 'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'video_log_freq': -1, 'scalar_log_freq': 1, 'no_gpu': False, 'which_gpu': 0, 'max_replay_buffer_size': 1000000, 'save_params': False, 'seed': 32, 'worker_nums': 1, 'eval_worker_nums': 1, 'config': 'config/soft_module_fixed_mt10_similar.json', 'no_cuda': True, 'random_init': False, 'device': 'cpu', 'id': 'MT50_Single_Task', 'task_name': None, 'task_env': 'MT50_task_env', 'cuda': False, 'agent_class': <class 'agents.bc_agent.SoftModuleAgent'>, 'agent_params': {'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'max_replay_buffer_size': 1000000, 'discrete': False}}
{'env_name': 'mt10_similar', 'env': {'reward_scale': 1, 'obs_norm': False}, 'meta_env': {'obs_type': 'with_goal', 'random_init': False}, 'replay_buffer': {'size': 1000000.0}, 'expert_net': {'hidden_shapes': [400, 400], 'append_hidden_shapes': [400]}, 'net': {'hidden_shapes': [400, 400], 'em_hidden_shapes': [400], 'num_layers': 2, 'num_modules': 2, 'module_hidden': 256, 'num_gating_layers': 2, 'gating_hidden': 256, 'add_bn': False, 'pre_softmax': False, 'base_type': <class 'networks.base.MLPBase'>}, 'general_setting': {'discount': 0.99, 'pretrain_epochs': 20, 'num_epochs': 7500, 'epoch_frames': 200, 'max_episode_frames': 200, 'batch_size': 1280, 'min_pool': 10000, 'target_hard_update_period': 1000, 'use_soft_update': True, 'tau': 0.005, 'opt_times': 200, 'eval_episodes': 1, 'train_render': False, 'eval_render': False, 'env': <NormAct<RewardShift<MTEnv instance>>>, 'device': device(type='cpu')}, 'sac': {'plr': 0.0003, 'qlr': 0.0003, 'reparameterization': True, 'automatic_entropy_tuning': True, 'policy_std_reg_weight': 0, 'policy_mean_reg_weight': 0}}
Loading expert policy from... policy/expert/MT10_Similar/
Done restoring expert policy...
<NormAct<RewardShift<AugObs<SawyerReachPushPickPlaceEnv instance>>>>
<NormAct<RewardShift<AugObs<SawyerButtonPressEnv instance>>>>
<NormAct<RewardShift<AugObs<SawyerCoffeePushEnv instance>>>>
<NormAct<RewardShift<AugObs<SawyerSoccerEnv instance>>>>
<NormAct<RewardShift<AugObs<SawyerReachPushPickPlaceWallEnv instance>>>>
<NormAct<RewardShift<AugObs<SawyerSweepEnv instance>>>>
<NormAct<RewardShift<AugObs<SawyerSweepIntoGoalEnv instance>>>>
<NormAct<RewardShift<AugObs<SawyerPlateSlideEnv instance>>>>
<NormAct<RewardShift<AugObs<SawyerPlateSlideSideEnv instance>>>>
<NormAct<RewardShift<AugObs<SawyerDrawerCloseEnv instance>>>>
/viscam/u/jialugao/.anaconda3/envs/metaworldEnv/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: [33mWARN: Could not seed environment <MTEnv instance>[0m
  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))


-------------------------------- Iteration 0 -------------------------------- 
initial ob: [-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
  0.1         0.8         0.02        0.1         0.8         0.02      ]
expert_success: 1.0
path_length: 150

initial ob: [-0.03264849  0.51488124  0.2368859   0.          0.75        0.12
  0.          0.79999998  0.09        0.          0.79999998  0.09      ]
expert_success: 1.0
path_length: 150

initial ob: [-3.26504931e-02  5.14881056e-01  2.36887642e-01 -1.77416902e-07
  5.99999879e-01  2.79199750e-02  0.00000000e+00  8.00000000e-01
  0.00000000e+00  0.00000000e+00  8.00000000e-01  0.00000000e+00]
expert_success: 1.0
path_length: 150

initial ob: [-0.03265121  0.51487852  0.23688147  0.          0.6         0.02998765
  0.          0.9         0.03        0.          0.9         0.03      ]
expert_success: 1.0
path_length: 150

initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
  0.05        0.8         0.015       0.05        0.8         0.015     ]
expert_success: 1.0
path_length: 150

initial ob: [-0.03358889  0.51377023  0.23633834  0.          0.6         0.02
  0.          0.95       -0.3         0.          0.95       -0.3       ]
expert_success: 1.0
path_length: 150

initial ob: [-0.03358889  0.51377023  0.23633834  0.          0.6         0.01997144
  0.          0.84        0.02        0.          0.84        0.02      ]
expert_success: 1.0
path_length: 150

initial ob: [-0.03264849  0.51488124  0.2368859   0.          0.6         0.015
  0.          0.85        0.02        0.          0.85        0.02      ]
expert_success: 1.0
path_length: 150

initial ob: [-0.03264849  0.51488124  0.2368859   0.          0.6         0.015
 -0.25        0.6         0.02       -0.25        0.6         0.02      ]
expert_success: 1.0
path_length: 150

initial ob: [-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.7         0.04      ]
expert_success: 1.0
path_length: 150

{'push-v1_success_rate': array(1., dtype=float32), 'button-press-v1_success_rate': array(1., dtype=float32), 'coffee-push-v1_success_rate': array(1., dtype=float32), 'soccer-v1_success_rate': array(1., dtype=float32), 'push-wall-v1_success_rate': array(1., dtype=float32), 'sweep-v1_success_rate': array(1., dtype=float32), 'sweep-into-v1_success_rate': array(1., dtype=float32), 'plate-slide-v1_success_rate': array(1., dtype=float32), 'plate-slide-side-v1_success_rate': array(1., dtype=float32), 'drawer-close-v1_success_rate': array(1., dtype=float32), 'mean_success_rate': 1.0}


-------------------------------- Iteration 0 -------------------------------- 
training time:  1.819610834121704
evaluation time:  9.720872163772583
epoch time:  11.540507078170776
loss:  0.88800603


-------------------------------- Iteration 1000 -------------------------------- 
training time:  0.01181650161743164
evaluation time:  9.9403235912323
epoch time:  9.952162981033325
loss:  0.23043716


-------------------------------- Iteration 2000 -------------------------------- 
training time:  0.012592315673828125
evaluation time:  9.903836965560913
epoch time:  9.916448593139648
loss:  0.14243421


-------------------------------- Iteration 3000 -------------------------------- 
training time:  0.012901544570922852
evaluation time:  9.947634220123291
epoch time:  9.960556983947754
loss:  0.18126637


-------------------------------- Iteration 4000 -------------------------------- 
training time:  0.011774539947509766
evaluation time:  9.987714290618896
epoch time:  9.999512672424316
loss:  0.084602244


-------------------------------- Iteration 5000 -------------------------------- 
training time:  0.01410531997680664
evaluation time:  9.859187126159668
epoch time:  9.873313665390015
loss:  0.19937356


-------------------------------- Iteration 6000 -------------------------------- 
training time:  0.013878583908081055
evaluation time:  9.878836154937744
epoch time:  9.892741441726685
loss:  0.12185272


-------------------------------- Iteration 7000 -------------------------------- 
training time:  0.012390851974487305
evaluation time:  10.194853782653809
epoch time:  10.207263708114624
loss:  0.091560714


-------------------------------- Iteration 8000 -------------------------------- 
training time:  0.01586127281188965
evaluation time:  9.853551864624023
epoch time:  9.869478702545166
loss:  0.09948635


-------------------------------- Iteration 9000 -------------------------------- 
training time:  0.01376795768737793
evaluation time:  9.918611288070679
epoch time:  9.932397365570068
loss:  0.07786532


-------------------------------- Iteration 10000 -------------------------------- 
training time:  0.012465476989746094
evaluation time:  10.04671049118042
epoch time:  10.05919885635376
loss:  0.09143


-------------------------------- Iteration 11000 -------------------------------- 
training time:  0.014173507690429688
evaluation time:  9.97031307220459
epoch time:  9.98450493812561
loss:  0.081767924


-------------------------------- Iteration 12000 -------------------------------- 
training time:  0.014279603958129883
evaluation time:  9.95673942565918
epoch time:  9.97104287147522
loss:  0.06851229


-------------------------------- Iteration 13000 -------------------------------- 
training time:  0.012491941452026367
evaluation time:  9.823320865631104
epoch time:  9.835831642150879
loss:  0.08600765


-------------------------------- Iteration 14000 -------------------------------- 
training time:  0.014600515365600586
evaluation time:  9.929484128952026
epoch time:  9.944109678268433
loss:  0.078687444


-------------------------------- Iteration 15000 -------------------------------- 
training time:  0.013307571411132812
evaluation time:  9.926641702651978
epoch time:  9.93996548652649
loss:  0.021489218


-------------------------------- Iteration 16000 -------------------------------- 
training time:  0.012775182723999023
evaluation time:  10.050988912582397
epoch time:  10.063787698745728
loss:  0.04647153


-------------------------------- Iteration 17000 -------------------------------- 
training time:  0.014553308486938477
evaluation time:  10.038476467132568
epoch time:  10.053054332733154
loss:  0.0839044


-------------------------------- Iteration 18000 -------------------------------- 
training time:  0.012486457824707031
evaluation time:  9.973663806915283
epoch time:  9.986199617385864
loss:  0.035315655


-------------------------------- Iteration 19000 -------------------------------- 
training time:  0.013129234313964844
evaluation time:  9.936391592025757
epoch time:  9.9495530128479
loss:  0.062264554


-------------------------------- Iteration 20000 -------------------------------- 
training time:  0.012523651123046875
evaluation time:  10.03097414970398
epoch time:  10.043517351150513
loss:  0.041648634


-------------------------------- Iteration 21000 -------------------------------- 
training time:  0.014399290084838867
evaluation time:  9.910197257995605
epoch time:  9.924667119979858
loss:  0.0842299


-------------------------------- Iteration 22000 -------------------------------- 
training time:  0.016159534454345703
evaluation time:  10.001200914382935
epoch time:  10.01738715171814
loss:  0.027569015


-------------------------------- Iteration 23000 -------------------------------- 
training time:  0.013597488403320312
evaluation time:  9.879356384277344
epoch time:  9.89297103881836
loss:  0.076790795


-------------------------------- Iteration 24000 -------------------------------- 
training time:  0.01627063751220703
evaluation time:  10.058961391448975
epoch time:  10.075291156768799
loss:  0.016730469


-------------------------------- Iteration 25000 -------------------------------- 
training time:  0.01404714584350586
evaluation time:  9.83091950416565
epoch time:  9.844985008239746
loss:  0.052855477


-------------------------------- Iteration 26000 -------------------------------- 
training time:  0.013540029525756836
evaluation time:  9.898971557617188
<string>:6: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
epoch time:  9.912531852722168
loss:  0.046194673


-------------------------------- Iteration 27000 -------------------------------- 
training time:  0.014528036117553711
evaluation time:  10.072802066802979
epoch time:  10.087347507476807
loss:  0.035990387


-------------------------------- Iteration 28000 -------------------------------- 
training time:  0.012517452239990234
evaluation time:  9.936219453811646
epoch time:  9.948763608932495
loss:  0.030408222


-------------------------------- Iteration 29000 -------------------------------- 
training time:  0.014206647872924805
evaluation time:  9.813462972640991
epoch time:  9.827694654464722
loss:  0.066820726


-------------------------------- Iteration 30000 -------------------------------- 
training time:  0.0150909423828125
evaluation time:  9.868363618850708
epoch time:  9.883487462997437
loss:  0.07701562


-------------------------------- Iteration 31000 -------------------------------- 
training time:  0.016348600387573242
evaluation time:  10.082345485687256
epoch time:  10.098711013793945
loss:  0.049017504


-------------------------------- Iteration 32000 -------------------------------- 
training time:  0.012558698654174805
evaluation time:  9.899006843566895
epoch time:  9.911592483520508
loss:  0.050015196


-------------------------------- Iteration 33000 -------------------------------- 
training time:  0.016531944274902344
evaluation time:  10.022470474243164
epoch time:  10.03902292251587
loss:  0.03175223


-------------------------------- Training stopped due to early stopping -------------------------------- 
min loss:  0.0049500954


-------------------------------- Test Results -------------------------------- 
button-press-v1_success_rate _success_rate:  1.0
coffee-push-v1_success_rate _success_rate:  0.0
drawer-close-v1_success_rate _success_rate:  0.0
plate-slide-side-v1_success_rate _success_rate:  1.0
plate-slide-v1_success_rate _success_rate:  1.0
push-v1_success_rate _success_rate:  1.0
push-wall-v1_success_rate _success_rate:  0.0
soccer-v1_success_rate _success_rate:  0.0
sweep-into-v1_success_rate _success_rate:  0.0
sweep-v1_success_rate _success_rate:  0.0
mean_success_rate:  0.4
Done
