/var/lib/slurm/slurmd/job3515745/slurm_script: line 9: batch_scripts/MT50_batch/seed.sh: No such file or directory
SLURM_JOBID=3515745
working directory=/viscam/u/jialugao/Imitation-SoftModule
########################
logging outputs to  /viscam/u/jialugao/Imitation-SoftModule/data/Base_bc_reach_plate-slide-back-v1_2640.000125-01-2022_23-53-59
########################
{'expert_policy_file': '../Multi-Task-RL/log/MT50_Single_Task/plate-slide-back-v1/Fixed/238/model/model_pf_best.pth', 'exp_name': 'bc_reach', 'do_dagger': False, 'ep_len': 200, 'gradient_steps': 1, 'n_iter': 100000, 'render_interval': 1, 'eval_interval': 200, 'batch_size': 64, 'eval_batch_size': 32, 'train_batch_size': 32, 'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'video_log_freq': -1, 'scalar_log_freq': 1, 'no_gpu': False, 'which_gpu': 0, 'max_replay_buffer_size': 1000000, 'save_params': False, 'seed': 32, 'worker_nums': 1, 'eval_worker_nums': 1, 'config': 'config/BC.json', 'no_cuda': True, 'random_init': False, 'device': 'cpu', 'id': 'MT50_Single_Task', 'task_name': 'plate-slide-back-v1', 'task_env': 'MT50_task_env', 'cuda': False, 'log_dir': '/viscam/u/jialugao/Imitation-SoftModule/data/Base_bc_reach_plate-slide-back-v1_2640.000125-01-2022_23-53-59', 'agent_class': <class 'agents.bc_agent.MLPAgent'>, 'agent_params': {'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'max_replay_buffer_size': 1000000, 'discrete': False, 'ac_dim': 4, 'ob_dim': 9}}
{'env_name': 'single_task', 'env': {'reward_scale': 1, 'obs_norm': False}, 'meta_env': {'obs_type': 'with_goal', 'random_init': False}, 'replay_buffer': {'size': 1000000.0}, 'net': {'hidden_shapes': [400, 400], 'append_hidden_shapes': [400], 'base_type': <class 'networks.base.MLPBase'>}, 'general_setting': {'discount': 0.99, 'pretrain_epochs': 20, 'num_epochs': 7500, 'epoch_frames': 200, 'max_episode_frames': 200, 'batch_size': 1280, 'min_pool': 10000, 'target_hard_update_period': 1000, 'use_soft_update': True, 'tau': 0.005, 'opt_times': 200, 'eval_episodes': 100, 'train_render': False, 'eval_render': False, 'env': <NormAct<RewardShift<SingleWrapperNone>>>, 'logger': <utils.logger.Logger object at 0x7f67318c8b50>, 'device': device(type='cpu')}, 'sac': {'plr': 0.0003, 'qlr': 0.0003, 'reparameterization': True, 'automatic_entropy_tuning': True, 'policy_std_reg_weight': 0, 'policy_mean_reg_weight': 0}}
Loading expert policy from... ../Multi-Task-RL/log/MT50_Single_Task/plate-slide-back-v1/Fixed/238/model/model_pf_best.pth
tensor([[-0.0091, -0.0206, -0.0588,  ..., -0.0365, -0.0244, -0.0685],
        [ 0.0494, -0.0407, -0.0450,  ...,  0.0090, -0.0126, -0.0809],
        [-0.0371, -0.0888, -0.0473,  ..., -0.0016, -0.0337, -0.0542],
        ...,
        [ 1.2710, -0.1710,  0.2019,  ...,  0.0400, -0.0493, -0.0492],
        [-0.4082, -0.0702, -0.6497,  ..., -0.0461,  0.1019,  0.0772],
        [ 0.0231, -0.0194, -0.0860,  ..., -0.0211, -0.0692, -0.0368]])
Done restoring expert policy...
<NormAct<RewardShift<AugObs<SawyerPlateSlideBackEnv instance>>>>


-------------------------------- Iteration 0 -------------------------------- 
initial ob: [-0.03264849  0.51488124  0.2368859   0.          0.8         0.015
  0.          0.6         0.015       0.          0.6         0.015     ]
expert:[-0.12096916  0.7840984  -0.23868093 -0.7927766 ]
expert:[-0.8839768   0.9456229  -0.87070286 -0.8994679 ]
expert:[-0.94642204  0.9587954  -0.94314396 -0.8613095 ]
expert:[-0.92295575  0.95006996 -0.9442573  -0.744123  ]
expert:[-0.8602482   0.93256855 -0.9349005  -0.5847631 ]
expert:[-0.7381714   0.88436055 -0.9186607  -0.46738854]
expert:[ 0.1220265   0.78856564 -0.8945581  -0.2134779 ]
expert:[ 0.94525826  0.9598123  -0.93117625 -0.12758057]
expert:[ 0.97946     0.98245    -0.9539837  -0.41053241]
expert:[ 0.97934073  0.98689204 -0.97664374 -0.8247014 ]
expert:[ 0.9563461  0.9901138 -0.9793923 -0.9193549]
expert:[ 0.45021814  0.9785757  -0.95760316 -0.7574054 ]
expert:[-0.57800025  0.9158123  -0.8875263  -0.180914  ]
expert:[-0.4187449   0.83217376 -0.7296199  -0.05760756]
expert:[ 0.74200493  0.882552    0.03004668 -0.17952454]
expert:[ 0.95502263  0.9485991   0.22953926 -0.5246596 ]
expert:[ 0.62157017  0.9223649  -0.35668862 -0.47411743]
expert:[-0.9104056 -0.937695  -0.9848377  0.7151412]
expert:[-0.9708431 -0.9935552 -0.9950345  0.7952836]
expert:[-0.97216845 -0.9965021  -0.99540013  0.8625795 ]
expert:[-0.95849943 -0.9978411  -0.9964361   0.93427736]
expert:[-0.17732936 -0.9976666  -0.99762946  0.97032404]
expert:[ 0.07449862 -0.99612933 -0.9962434   0.963536  ]
expert:[ 0.15553549 -0.99534845 -0.99559087  0.9383385 ]
expert:[ 0.1685146  -0.99487627 -0.99558794  0.925979  ]
expert:[ 0.20557722 -0.99341273 -0.99568564  0.89264536]
expert:[ 0.258737   -0.99075794 -0.99563813  0.8406816 ]
expert:[ 0.2836978  -0.9875908  -0.99550456  0.8071427 ]
expert:[ 0.24935558 -0.9863373  -0.9955053   0.8318205 ]
expert:[ 0.14844361 -0.9861095  -0.9954801   0.88580066]
expert:[ 0.04593417 -0.9851499  -0.99534875  0.922942  ]
expert:[-0.01294155 -0.982921   -0.9953461   0.9361473 ]
expert:[-0.08041093 -0.9793144  -0.99531543  0.9449399 ]
expert:[-0.13522317 -0.97484887 -0.9955481   0.94746745]
expert:[-0.18835428 -0.96906024 -0.9957942   0.94704723]
expert:[-0.12925962 -0.9109768  -0.99343514  0.9139599 ]
expert:[-0.06945235 -0.7369266  -0.98674446  0.8562188 ]
expert:[-0.03611776 -0.49897122 -0.9747852   0.80851924]
expert:[ 0.0030636  -0.3266478  -0.95752245  0.75591177]
expert:[ 0.0520791  -0.23555547 -0.93891144  0.74251294]
expert:[ 0.07842345 -0.1482482  -0.9164259   0.7423806 ]
expert:[ 0.08062429 -0.09524258 -0.9024393   0.76008326]
expert:[ 0.06212505 -0.05824534 -0.90011215  0.7867673 ]
expert:[ 0.02667143 -0.02729593 -0.9049253   0.81216836]
expert:[ 0.00542661 -0.00367339 -0.90902156  0.8277941 ]
expert:[-0.0090727   0.0091622  -0.91266805  0.83759785]
expert:[-0.01864111  0.01929482 -0.9153819   0.84382087]
expert:[-0.02328982  0.02607764 -0.91655654  0.847359  ]
expert:[-0.02396727  0.02897896 -0.9163325   0.8485606 ]
expert:[-0.02184889  0.02996171 -0.9153667   0.848562  ]
expert:[-0.01786859  0.02907842 -0.91354805  0.84754336]
expert:[-0.01223067  0.02768325 -0.91127175  0.84554243]
expert:[-0.0063148   0.02638356 -0.90893185  0.8431294 ]
expert:[-0.00108787  0.02394546 -0.9067739   0.8406836 ]
expert:[ 0.0034744   0.02011508 -0.9048898   0.83802885]
expert:[ 0.00679835  0.01688144 -0.9036534   0.83593065]
expert:[ 0.00872159  0.01439794 -0.90313935  0.8345142 ]
expert:[ 0.00933057  0.01268757 -0.90330136  0.83377343]
expert:[ 0.00880616  0.01166911 -0.9040263   0.83363104]
expert:[ 0.00743336  0.01119501 -0.90515053  0.8339464 ]
expert:[ 0.00532656  0.01142035 -0.9064796   0.8345688 ]
expert:[ 0.00299676  0.01200949 -0.9078264   0.83528477]
expert:[ 8.1043673e-04  1.2431338e-02 -9.0910095e-01  8.3596569e-01]
expert:[-0.00122242  0.01236462 -0.910211    0.83655274]
expert:[-0.0026532   0.01203121 -0.9110432   0.83687335]
expert:[-0.00339388  0.01144753 -0.91157836  0.8368944 ]
expert:[-0.00354246  0.01062577 -0.9118477   0.83665323]
expert:[-0.00317423  0.00961313 -0.91189045  0.8361873 ]
expert:[-0.00237754  0.00848249 -0.91175747  0.8355451 ]
expert:[-0.00146321  0.00720521 -0.9115505   0.8348405 ]
expert:[-5.2466238e-04  5.9723444e-03 -9.1132128e-01  8.3413953e-01]
expert:[ 3.2391027e-04  4.8473990e-03 -9.1112065e-01  8.3349955e-01]
expert:[ 0.0009556   0.00387464 -0.9109939   0.8329783 ]
expert:[ 0.00134921  0.00308402 -0.91095465  0.83259267]
expert:[ 0.00147404  0.00247767 -0.9110099   0.8323548 ]
expert:[ 0.00138938  0.00204009 -0.9111416   0.83224016]
expert:[ 0.00112823  0.00174266 -0.9113316   0.83222926]
expert:[ 7.5788412e-04  1.5473949e-03 -9.1155320e-01  8.3228773e-01]
expert:[ 3.6252660e-04  1.4185300e-03 -9.1177607e-01  8.3237576e-01]
expert:[-1.1570752e-05  1.3210765e-03 -9.1197932e-01  8.3246732e-01]
expert:[-3.0077994e-04  1.2307459e-03 -9.1214228e-01  8.3253258e-01]
expert:[-4.9170846e-04  1.1276300e-03 -9.1225845e-01  8.3256167e-01]
expert:[-5.7421991e-04  1.0043379e-03 -9.1232520e-01  8.3254838e-01]
expert:[-5.608312e-04  8.617041e-04 -9.123479e-01  8.324975e-01]
expert:[-4.7941130e-04  7.0404995e-04 -9.1233736e-01  8.3241957e-01]
expert:[-3.4072250e-04  5.4353470e-04 -9.1230124e-01  8.3232152e-01]
expert:[-1.8759072e-04  3.8799641e-04 -9.1225481e-01  8.3222067e-01]
expert:[-2.0984560e-05  2.5075674e-04 -9.1220349e-01  8.3212048e-01]
expert:[ 1.15629286e-04  1.36256218e-04 -9.12160873e-01  8.32038045e-01]
expert:[ 2.0979717e-04  5.0514936e-05 -9.1213268e-01  8.3197880e-01]
expert:[ 2.5098026e-04 -6.1690807e-06 -9.1212273e-01  8.3194661e-01]
expert:[ 2.5263056e-04 -3.5762787e-05 -9.1212785e-01  8.3193642e-01]
expert:[ 2.3637712e-04 -4.1395426e-05 -9.1214204e-01  8.3193910e-01]
expert:[ 1.7498061e-04 -3.2544136e-05 -9.1216969e-01  8.3196229e-01]
expert:[ 1.18002295e-04 -1.26361847e-05 -9.12197769e-01  8.31987023e-01]
expert:[ 4.7042966e-05  1.0341406e-05 -9.1222882e-01  8.3201784e-01]
expert:[-3.6843121e-06  3.2573938e-05 -9.1225326e-01  8.3204120e-01]
expert:[-5.1259995e-05  4.8726797e-05 -9.1227430e-01  8.3206189e-01]
expert:[-7.9352409e-05  5.8740377e-05 -9.1228759e-01  8.3207422e-01]
expert:[-9.1943890e-05  6.0528517e-05 -9.1229403e-01  8.3207870e-01]
expert:[-7.8912824e-05  5.6684017e-05 -9.1229171e-01  8.3207279e-01]
expert:[-7.0229173e-05  4.6908855e-05 -9.1228819e-01  8.3206666e-01]
expert:[-3.3196062e-05  3.4660101e-05 -9.1227746e-01  8.3204973e-01]
expert:[-1.8775463e-06  2.1010637e-05 -9.1226715e-01  8.3203453e-01]
expert:[ 2.1304935e-05  8.7320805e-06 -9.1225904e-01  8.3202273e-01]
expert:[ 3.8936734e-05 -1.4901161e-07 -9.1225326e-01  8.3201373e-01]
expert:[ 4.6569854e-05 -5.6028366e-06 -9.1225070e-01  8.3200943e-01]
expert:[ 7.0426613e-05 -6.3180923e-06 -9.1224623e-01  8.3200026e-01]
expert:[ 6.5281987e-05 -4.8577785e-06 -9.1224933e-01  8.3200216e-01]
expert:[ 5.180016e-05 -5.662441e-07 -9.122555e-01  8.320079e-01]
expert:[ 5.1371753e-05  5.8114529e-06 -9.1225970e-01  8.3200938e-01]
expert:[ 3.0022115e-05  1.2606382e-05 -9.1226852e-01  8.3201861e-01]
expert:[ 4.5634806e-06  1.7821789e-05 -9.1227835e-01  8.3202869e-01]
expert:[-5.3644180e-07  2.4288893e-05 -9.1228336e-01  8.3203191e-01]
expert:[-7.6591969e-06  2.6613474e-05 -9.1228771e-01  8.3203477e-01]
expert:[-1.8406659e-05  2.7388334e-05 -9.1229248e-01  8.3203852e-01]
expert:[-8.5867941e-06  2.7537346e-05 -9.1229147e-01  8.3203477e-01]
expert:[ 2.1681190e-06  2.5480986e-05 -9.1229010e-01  8.3202994e-01]
expert:[ 1.7940998e-05  2.3007393e-05 -9.1228718e-01  8.3202326e-01]
expert:[ 2.3540109e-05  2.0891428e-05 -9.1228688e-01  8.3202046e-01]
expert:[ 3.1385571e-05  1.8119812e-05 -9.1228634e-01  8.3201641e-01]
expert:[ 2.3569912e-05  1.6957521e-05 -9.1228968e-01  8.3201861e-01]
expert:[ 3.4365803e-05  1.7344952e-05 -9.1228944e-01  8.3201444e-01]
expert:[ 2.3256987e-05  1.7791986e-05 -9.1229403e-01  8.3201826e-01]
expert:[ 7.3239207e-06  1.7821789e-05 -9.1230011e-01  8.3202356e-01]
expert:[ 4.7311187e-06  1.9341707e-05 -9.1230321e-01  8.3202451e-01]
expert:[ 1.0218471e-05  2.0653009e-05 -9.1230434e-01  8.3202261e-01]
expert:[ 4.0456653e-06  1.9639730e-05 -9.1230762e-01  8.3202416e-01]
expert:[ 1.4513731e-05  1.9878149e-05 -9.1230690e-01  8.3202010e-01]
expert:[ 2.2307038e-05  1.9371510e-05 -9.1230696e-01  8.3201677e-01]
expert:[ 1.28000975e-05  1.85370445e-05 -9.12310541e-01  8.32019627e-01]
expert:[ 1.7989427e-05  1.8030405e-05 -9.1231132e-01  8.3201724e-01]
expert:[ 2.1427870e-05  1.7672777e-05 -9.1231251e-01  8.3201557e-01]
expert:[ 9.3393028e-06  1.7523766e-05 -9.1231692e-01  8.3201951e-01]
expert:[ 5.8934093e-06  1.7285347e-05 -9.1231936e-01  8.3202040e-01]
expert:[ 1.0222197e-05  1.7672777e-05 -9.1232049e-01  8.3201849e-01]
expert:[ 8.6538494e-06  1.7046928e-05 -9.1232216e-01  8.3201849e-01]
expert:[ 1.4502555e-05  1.7136335e-05 -9.1232252e-01  8.3201623e-01]
expert:[ 1.3533980e-05  1.5765429e-05 -9.1232425e-01  8.3201581e-01]
expert:[ 2.2150576e-05  1.5944242e-05 -9.1232389e-01  8.3201236e-01]
expert:[ 2.1066517e-05  1.5676022e-05 -9.1232592e-01  8.3201236e-01]
expert:[ 3.8795173e-05  1.7672777e-05 -9.1232389e-01  8.3200610e-01]
expert:[ 4.4737011e-05  1.8745661e-05 -9.1232485e-01  8.3200389e-01]
expert:[ 3.9875507e-05  2.0384789e-05 -9.1232896e-01  8.3200562e-01]
expert:[ 3.568828e-05  2.270937e-05 -9.123329e-01  8.320073e-01]
expert:[ 2.6740134e-05  2.6315451e-05 -9.1233838e-01  8.3201116e-01]
expert:[ 2.1412969e-05  2.8729439e-05 -9.1234303e-01  8.3201319e-01]
expert:[ 1.3582408e-05  3.1352043e-05 -9.1234821e-01  8.3201629e-01]
expert:[ 1.0974705e-05  3.2365322e-05 -9.1235179e-01  8.3201694e-01]
expert:[ 6.7763031e-06  3.3527613e-05 -9.1235554e-01  8.3201844e-01]
expert_success: 1.0
path_length: 150



-------------------------------- Iteration 0 -------------------------------- 
initial ob: [-0.03264849  0.51488124  0.2368859   0.          0.8         0.015
  0.          0.6         0.015       0.          0.6         0.015     ]
agent_success: 0

training time:  0.21278166770935059
evaluation time:  13.412464618682861
epoch time:  13.625281810760498


-------------------------------- Iteration 200 -------------------------------- 
initial ob: [-0.03264849  0.51488124  0.2368859   0.          0.8         0.015
  0.          0.6         0.015       0.          0.6         0.015     ]
agent_success: 0

training time:  0.0021257400512695312
evaluation time:  13.511069297790527
epoch time:  13.51322889328003


-------------------------------- Iteration 400 -------------------------------- 
initial ob: [-0.03264849  0.51488124  0.2368859   0.          0.8         0.015
  0.          0.6         0.015       0.          0.6         0.015     ]
agent_success: 0

training time:  0.0021522045135498047
evaluation time:  13.481224775314331
epoch time:  13.48340368270874


-------------------------------- Iteration 600 -------------------------------- 
initial ob: [-0.03264849  0.51488124  0.2368859   0.          0.8         0.015
  0.          0.6         0.015       0.          0.6         0.015     ]
agent_success: 0

training time:  0.002292156219482422
evaluation time:  13.527228116989136
epoch time:  13.52955174446106


-------------------------------- Iteration 800 -------------------------------- 
initial ob: [-0.03264849  0.51488124  0.2368859   0.          0.8         0.015
  0.          0.6         0.015       0.          0.6         0.015     ]
agent_success: 0

training time:  0.002190113067626953
evaluation time:  13.47279405593872
epoch time:  13.475028038024902


-------------------------------- Iteration 1000 -------------------------------- 
initial ob: [-0.03264849  0.51488124  0.2368859   0.          0.8         0.015
  0.          0.6         0.015       0.          0.6         0.015     ]
agent_success: 0

training time:  0.002067089080810547
evaluation time:  13.514136552810669
epoch time:  13.516248226165771


-------------------------------- Training stopped due to early stopping -------------------------------- 
min loss:  0.00346311


-------------------------------- Test Results -------------------------------- 
initial ob: [-0.03264849  0.51488124  0.2368859   0.          0.8         0.015
  0.          0.6         0.015       0.          0.6         0.015     ]
agent_success: 0

mean_success_rate:  0.0
Done
