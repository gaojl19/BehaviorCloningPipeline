/var/lib/slurm/slurmd/job3515736/slurm_script: line 9: batch_scripts/MT50_batch/seed.sh: No such file or directory
SLURM_JOBID=3515736
working directory=/viscam/u/jialugao/Imitation-SoftModule
########################
logging outputs to  /viscam/u/jialugao/Imitation-SoftModule/data/Base_bc_reach_button-press-wall-v1_2640.000125-01-2022_23-54-01
########################
{'expert_policy_file': '../Multi-Task-RL/log/MT50_Single_Task/button-press-wall-v1/Fixed/238/model/model_pf_best.pth', 'exp_name': 'bc_reach', 'do_dagger': False, 'ep_len': 200, 'gradient_steps': 1, 'n_iter': 100000, 'render_interval': 1, 'eval_interval': 200, 'batch_size': 64, 'eval_batch_size': 32, 'train_batch_size': 32, 'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'video_log_freq': -1, 'scalar_log_freq': 1, 'no_gpu': False, 'which_gpu': 0, 'max_replay_buffer_size': 1000000, 'save_params': False, 'seed': 32, 'worker_nums': 1, 'eval_worker_nums': 1, 'config': 'config/BC.json', 'no_cuda': True, 'random_init': False, 'device': 'cpu', 'id': 'MT50_Single_Task', 'task_name': 'button-press-wall-v1', 'task_env': 'MT50_task_env', 'cuda': False, 'log_dir': '/viscam/u/jialugao/Imitation-SoftModule/data/Base_bc_reach_button-press-wall-v1_2640.000125-01-2022_23-54-01', 'agent_class': <class 'agents.bc_agent.MLPAgent'>, 'agent_params': {'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'max_replay_buffer_size': 1000000, 'discrete': False, 'ac_dim': 4, 'ob_dim': 9}}
{'env_name': 'single_task', 'env': {'reward_scale': 1, 'obs_norm': False}, 'meta_env': {'obs_type': 'with_goal', 'random_init': False}, 'replay_buffer': {'size': 1000000.0}, 'net': {'hidden_shapes': [400, 400], 'append_hidden_shapes': [400], 'base_type': <class 'networks.base.MLPBase'>}, 'general_setting': {'discount': 0.99, 'pretrain_epochs': 20, 'num_epochs': 7500, 'epoch_frames': 200, 'max_episode_frames': 200, 'batch_size': 1280, 'min_pool': 10000, 'target_hard_update_period': 1000, 'use_soft_update': True, 'tau': 0.005, 'opt_times': 200, 'eval_episodes': 100, 'train_render': False, 'eval_render': False, 'env': <NormAct<RewardShift<SingleWrapperNone>>>, 'logger': <utils.logger.Logger object at 0x7f3098b90ed0>, 'device': device(type='cpu')}, 'sac': {'plr': 0.0003, 'qlr': 0.0003, 'reparameterization': True, 'automatic_entropy_tuning': True, 'policy_std_reg_weight': 0, 'policy_mean_reg_weight': 0}}
Loading expert policy from... ../Multi-Task-RL/log/MT50_Single_Task/button-press-wall-v1/Fixed/238/model/model_pf_best.pth
tensor([[ 0.0247, -0.0136, -0.0509,  ..., -0.0365, -0.0179, -0.0638],
        [ 0.0202, -0.0283, -0.0305,  ...,  0.0090, -0.0019, -0.0716],
        [-0.0184, -0.0770, -0.0473,  ..., -0.0016, -0.0237, -0.0456],
        ...,
        [ 0.0561, -0.0705, -0.0005,  ...,  0.0400, -0.0406, -0.0358],
        [ 0.0088, -0.0361, -0.0431,  ..., -0.0461,  0.0102, -0.0154],
        [ 0.0117, -0.0028, -0.0590,  ..., -0.0211, -0.0488, -0.0169]])
Done restoring expert policy...
<NormAct<RewardShift<AugObs<SawyerButtonPressWallEnv instance>>>>


-------------------------------- Iteration 0 -------------------------------- 
initial ob: [-0.03264849  0.51488124  0.2368859   0.          0.81        0.12
  0.          0.85999998  0.12        0.          0.85999998  0.12      ]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert:[-0.26526567  0.92893296 -0.91043484 -0.02263851]
expert_success: 1.0
path_length: 150



-------------------------------- Iteration 0 -------------------------------- 
initial ob: [-0.03264849  0.51488124  0.2368859   0.          0.81        0.12
  0.          0.85999998  0.12        0.          0.85999998  0.12      ]
agent_success: 0

training time:  0.1316969394683838
evaluation time:  6.8138747215271
epoch time:  6.945603132247925


-------------------------------- Training stopped due to early stopping -------------------------------- 
min loss:  0.0044718785


-------------------------------- Test Results -------------------------------- 
initial ob: [-0.03264849  0.51488124  0.2368859   0.          0.81        0.12
  0.          0.85999998  0.12        0.          0.85999998  0.12      ]
agent_success: 0

mean_success_rate:  0.0
Done
