/var/lib/slurm/slurmd/job3515632/slurm_script: line 9: batch_scripts/MT50_batch/seed.sh: No such file or directory
SLURM_JOBID=3515632
working directory=/viscam/u/jialugao/Imitation-SoftModule
########################
logging outputs to  /viscam/u/jialugao/Imitation-SoftModule/data/Base_bc_reach_lever-pull-v1_2640.000125-01-2022_23-01-55
########################
{'expert_policy_file': '../Multi-Task-RL/log/MT50_Single_Task/lever-pull-v1/Fixed/238/model/model_pf_best.pth', 'exp_name': 'bc_reach', 'do_dagger': False, 'ep_len': 200, 'gradient_steps': 1, 'n_iter': 10000, 'render_interval': 1, 'eval_interval': 200, 'batch_size': 64, 'eval_batch_size': 32, 'train_batch_size': 32, 'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'video_log_freq': -1, 'scalar_log_freq': 1, 'no_gpu': False, 'which_gpu': 0, 'max_replay_buffer_size': 1000000, 'save_params': False, 'seed': 32, 'worker_nums': 1, 'eval_worker_nums': 1, 'config': 'config/BC.json', 'no_cuda': True, 'random_init': False, 'device': 'cpu', 'id': 'MT50_Single_Task', 'task_name': 'lever-pull-v1', 'task_env': 'MT50_task_env', 'cuda': False, 'log_dir': '/viscam/u/jialugao/Imitation-SoftModule/data/Base_bc_reach_lever-pull-v1_2640.000125-01-2022_23-01-55', 'agent_class': <class 'agents.bc_agent.MLPAgent'>, 'agent_params': {'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'max_replay_buffer_size': 1000000, 'discrete': False, 'ac_dim': 4, 'ob_dim': 9}}
{'env_name': 'single_task', 'env': {'reward_scale': 1, 'obs_norm': False}, 'meta_env': {'obs_type': 'with_goal', 'random_init': False}, 'replay_buffer': {'size': 1000000.0}, 'net': {'hidden_shapes': [400, 400], 'append_hidden_shapes': [400], 'base_type': <class 'networks.base.MLPBase'>}, 'general_setting': {'discount': 0.99, 'pretrain_epochs': 20, 'num_epochs': 7500, 'epoch_frames': 200, 'max_episode_frames': 200, 'batch_size': 1280, 'min_pool': 10000, 'target_hard_update_period': 1000, 'use_soft_update': True, 'tau': 0.005, 'opt_times': 200, 'eval_episodes': 100, 'train_render': False, 'eval_render': False, 'env': <NormAct<RewardShift<SingleWrapperNone>>>, 'logger': <utils.logger.Logger object at 0x7f7bcb716ad0>, 'device': device(type='cpu')}, 'sac': {'plr': 0.0003, 'qlr': 0.0003, 'reparameterization': True, 'automatic_entropy_tuning': True, 'policy_std_reg_weight': 0, 'policy_mean_reg_weight': 0}}
Loading expert policy from... ../Multi-Task-RL/log/MT50_Single_Task/lever-pull-v1/Fixed/238/model/model_pf_best.pth
tensor([[ 0.9906, -0.2491, -1.3749,  ..., -0.0365, -0.1147,  0.0977],
        [ 0.0457, -0.0492, -0.0804,  ...,  0.0090, -0.0206,  0.0101],
        [ 0.7374, -1.1216,  0.1293,  ..., -0.0016,  0.2316, -0.2306],
        ...,
        [ 0.0519, -0.0816, -0.0038,  ...,  0.0400, -0.0530,  0.0395],
        [ 0.7605, -0.1619, -0.7062,  ..., -0.0461, -0.0032,  0.0592],
        [-0.0018, -0.0085, -0.0700,  ..., -0.0211, -0.0535,  0.0574]])
Done restoring expert policy...
<NormAct<RewardShift<AugObs<SawyerLeverPullEnv instance>>>>


-------------------------------- Iteration 0 -------------------------------- 
initial ob: [-0.03445708  0.5070419   0.23981725  0.          0.59855685  0.07018032
  0.          0.75       -0.12        0.          0.75       -0.12      ]
expert:[ 0.9907351   0.47214496 -0.99989295 -0.21779835]
expert:[ 0.9954839  -0.622361   -0.9998696   0.41104078]
expert:[ 0.99276364 -0.95095116 -0.99989194  0.32432276]
expert:[ 0.9156073  -0.99356776 -0.9999839  -0.6542386 ]
expert:[-0.9447672   0.7849054  -0.9998886  -0.65194243]
expert:[-0.99158126  0.912788   -0.9992191  -0.65471244]
expert:[-0.99625796  0.9274578  -0.9985788  -0.8440074 ]
expert:[-0.9954998   0.89508367 -0.99818975 -0.9271927 ]
expert:[-0.9863007  0.5769945 -0.9979753 -0.9538986]
expert:[-0.8689497  -0.70228195 -0.99851286 -0.9780521 ]
expert:[ 0.46201676 -0.9648605  -0.99785346 -0.9736062 ]
expert:[ 0.94853216 -0.9427491  -0.96888083 -0.8250167 ]
expert:[ 0.9635844  -0.83601403 -0.92407924 -0.7925958 ]
expert:[ 0.9646971  -0.76536185 -0.9147832  -0.7838099 ]
expert:[ 0.96466464 -0.74740696 -0.91696376 -0.78000456]
expert:[ 0.9643985  -0.74447125 -0.92183393 -0.77715296]
expert:[ 0.96346414 -0.74203074 -0.92783684 -0.77553535]
expert:[ 0.96084076 -0.7311895  -0.9358972  -0.77615947]
expert:[ 0.9551117  -0.7134638  -0.9452592  -0.77417135]
expert:[ 0.944413   -0.68926734 -0.95452267 -0.76286775]
expert:[ 0.5747077  -0.38170412 -0.94236356 -0.570915  ]
expert:[ 0.10830836 -0.09233153 -0.9214893  -0.47001192]
expert:[-0.00446591  0.0325645  -0.9039832  -0.40096983]
expert:[-0.03984823  0.07904017 -0.8988058  -0.38602364]
expert:[-0.05501078  0.10316963 -0.8973085  -0.38381287]
expert:[-0.06405034  0.12007648 -0.89678305 -0.38401148]
expert:[-0.07078395  0.13396432 -0.8964869  -0.38398007]
expert:[-0.07667258  0.14643669 -0.89615417 -0.38294268]
expert:[-0.0825056   0.15830694 -0.8956553  -0.38067073]
expert:[-0.08810037  0.16998702 -0.8950763  -0.37726033]
expert:[-0.09349633  0.18193448 -0.8944381  -0.37260148]
expert:[-0.10110108  0.19577082 -0.8931974  -0.36536792]
expert:[-0.10994492  0.21444626 -0.8915916  -0.35315096]
expert:[-0.12246763  0.23642552 -0.888977   -0.33670464]
expert:[-0.13846987  0.25787768 -0.8853453  -0.31952867]
expert:[-0.15490545  0.27843958 -0.88140345 -0.30213317]
expert:[-0.1696765   0.29673302 -0.877702   -0.28601477]
expert:[-0.18297517  0.31320956 -0.87422603 -0.27087745]
expert:[-0.19804864  0.32805887 -0.870043   -0.256304  ]
expert:[-0.20738126  0.336952   -0.86725235 -0.2464106 ]
expert:[-0.21574119  0.3410515  -0.8645658  -0.2403921 ]
expert:[-0.21467991  0.3378824  -0.86455894 -0.2409701 ]
expert:[-0.22016914  0.33560404 -0.8625405  -0.24033506]
expert:[-0.22048712  0.33025753 -0.86204153 -0.24255301]
expert:[-0.22443822  0.32556528 -0.8604214  -0.24406947]
expert:[-0.22270498  0.3178174  -0.86052376 -0.24847701]
expert:[-0.22465579  0.3113152  -0.85949075 -0.25162438]
expert:[-0.22622281  0.30434445 -0.8585969  -0.2554206 ]
expert:[-0.22301714  0.29536423 -0.85921204 -0.26132303]
expert:[-0.22141516  0.28772113 -0.8593453  -0.26599523]
expert:[-0.22172718  0.2810026  -0.8589185  -0.269998  ]
expert:[-0.22125259  0.27374023 -0.8587469  -0.2745773 ]
expert:[-0.21976478  0.26566434 -0.85887814 -0.2797976 ]
expert:[-0.2135188   0.2547951  -0.86042696 -0.28721064]
expert:[-0.20920984  0.24442314 -0.8613041  -0.29357597]
expert:[-0.20686932  0.233186   -0.8614865  -0.29997066]
expert:[-0.20021492  0.2073289  -0.8621852  -0.3135684 ]
expert:[-0.18449485  0.14973453 -0.86389637 -0.34188187]
expert:[-0.15929325  0.05741354 -0.8665817  -0.38462257]
expert:[-0.1277352  -0.05264561 -0.8718025  -0.4365978 ]
expert:[-0.08876107 -0.16451994 -0.8795185  -0.49142578]
expert:[-0.06218701 -0.2489229  -0.88438725 -0.53184617]
expert:[-0.04903157 -0.29111627 -0.8868395  -0.55255395]
expert:[-0.05189949 -0.28175554 -0.88662404 -0.5496144 ]
expert:[-0.07191954 -0.21650647 -0.8834873  -0.5208715 ]
expert:[-0.10697702 -0.09852591 -0.87749714 -0.46654442]
expert:[-0.15079673  0.05554656 -0.87016296 -0.39433005]
expert:[-0.19517982  0.21952793 -0.86581564 -0.31925258]
expert:[-0.21547686  0.2896951  -0.86347336 -0.28256783]
expert:[-0.21645424  0.2919011  -0.86309266 -0.27971393]
expert:[-0.20764437  0.2620124  -0.8639274  -0.2940018 ]
expert:[-0.1874011   0.19268303 -0.86610246 -0.32773468]
expert:[-0.15593031  0.0821334  -0.8694751  -0.37890506]
expert:[-0.11739387 -0.05066622 -0.8749938  -0.43902215]
expert:[-0.07686053 -0.17934269 -0.88260907 -0.50162715]
expert:[-0.0433636  -0.27924144 -0.8886593  -0.5492219 ]
expert:[-0.02502729 -0.3297036  -0.89218223 -0.5737217 ]
expert:[-0.02359489 -0.3238529  -0.8926853  -0.5726058 ]
expert:[-0.04339227 -0.25381672 -0.889899   -0.5421564 ]
expert:[-0.08094435 -0.12236234 -0.88396966 -0.48255888]
expert:[-0.128765    0.05407304 -0.87714916 -0.40339836]
expert:[-0.17676722  0.23627293 -0.87309587 -0.3203896 ]
expert:[-0.19544722  0.29993033 -0.87097204 -0.28608838]
expert:[-0.19417691  0.2980542  -0.87105036 -0.28553212]
expert:[-0.18408166  0.26920044 -0.87228185 -0.29977477]
expert:[-0.16785087  0.21122909 -0.87364686 -0.32724068]
expert:[-0.1427087   0.11636929 -0.8756211  -0.3700336 ]
expert:[-0.10434149 -0.01150829 -0.88001585 -0.42606467]
expert:[-0.06240491 -0.14178193 -0.88687587 -0.48656106]
expert:[-0.02488811 -0.24994136 -0.8934918  -0.5384904 ]
expert:[-0.0067081  -0.31067073 -0.89626235 -0.5662062 ]
expert:[ 0.00124854 -0.32145458 -0.89797044 -0.5727145 ]
expert:[-0.00883419 -0.27267545 -0.8970594  -0.5526101 ]
expert:[-0.03762248 -0.1626027  -0.8931625  -0.5040881 ]
expert:[-0.07891318 -0.00101159 -0.888495   -0.43578604]
expert:[-0.12542106  0.18505873 -0.88541603 -0.3565475 ]
expert:[-0.1490725   0.2738851  -0.88357747 -0.31268582]
expert:[-0.14969732  0.28236476 -0.8837205  -0.3073679 ]
expert:[-0.14461096  0.2656892  -0.8840349  -0.31427023]
expert:[-0.1336735   0.22620845 -0.884728   -0.33207202]
expert:[-0.10748885  0.14779676 -0.88771105 -0.36988577]
expert:[-0.0721507   0.03570614 -0.89144933 -0.42072225]
expert:[-0.04084132 -0.0843128  -0.8938643  -0.4676588 ]
expert:[-0.00276332 -0.19836795 -0.89927614 -0.5183387 ]
expert:[ 0.02811951 -0.27912766 -0.90436655 -0.5572268 ]
expert:[ 0.0439694  -0.31148022 -0.9071619  -0.5738644 ]
expert:[ 0.04139024 -0.28726754 -0.9073458  -0.5649551 ]
expert:[ 0.02020337 -0.20356941 -0.904886   -0.52900213]
expert:[-0.01454885 -0.06354298 -0.9020857  -0.47445208]
expert:[-0.05755931  0.11184038 -0.8996419  -0.4048335 ]
expert:[-0.09253138  0.24642436 -0.8975088  -0.3432863 ]
expert:[-0.10318527  0.2756108  -0.8960843  -0.3258783 ]
expert:[-0.09937773  0.2645275  -0.89628917 -0.32967418]
expert:[-0.08573284  0.23114836 -0.8979525  -0.34643322]
expert:[-0.06955716  0.1724802  -0.89895195 -0.37261862]
expert:[-0.03984347  0.0775184  -0.9016625  -0.41546252]
expert:[-0.0025928  -0.04072529 -0.90522367 -0.46593156]
expert:[ 0.02784897 -0.15216    -0.90755594 -0.5080467 ]
expert:[ 0.05774757 -0.24271122 -0.91085714 -0.54503286]
expert:[ 0.07890344 -0.29167125 -0.91417557 -0.5691075 ]
expert:[ 0.08367206 -0.28889966 -0.9153229  -0.5699611 ]
expert:[ 0.07050859 -0.22935115 -0.91421413 -0.5457153 ]
expert:[ 0.04325098 -0.11172097 -0.9131401  -0.50487787]
expert:[ 0.00503116  0.04729167 -0.9112744  -0.4453411 ]
expert:[-0.03592473  0.2088823  -0.90923345 -0.37595242]
expert:[-0.04948945  0.2613714  -0.90846616 -0.35019487]
expert:[-0.05318649  0.2604672  -0.9073532  -0.3468168 ]
expert:[-0.04243753  0.23282756 -0.9084172  -0.35992905]
expert:[-0.02405331  0.1809763  -0.91016376 -0.3847546 ]
expert:[-0.00496473  0.10434249 -0.910947   -0.4168632 ]
expert:[ 0.0279559  -0.00267381 -0.9136119  -0.4627733 ]
expert:[ 0.06240747 -0.11469866 -0.9165903  -0.50725156]
expert:[ 0.08636476 -0.20569862 -0.91808116 -0.54029536]
expert:[ 0.10613282 -0.26505676 -0.91988003 -0.5631176 ]
expert:[ 0.11495607 -0.27819037 -0.9212424  -0.570047  ]
expert:[ 0.10841468 -0.23712644 -0.9216036  -0.5575784 ]
expert:[ 0.0868146  -0.14144914 -0.9209326  -0.52526766]
expert:[ 0.05346438 -0.00169108 -0.9194277  -0.47504786]
expert:[ 0.01319225  0.15874319 -0.9176074  -0.4093171 ]
expert:[-0.00619201  0.23308603 -0.91661376 -0.37517032]
expert:[-0.00706369  0.2386558  -0.91655505 -0.37141088]
expert:[-0.00874584  0.22729684 -0.9155458  -0.37307683]
expert:[ 0.00318455  0.19193082 -0.9164891  -0.38931563]
expert:[ 0.02381566  0.12742095 -0.91809124 -0.41856715]
expert:[ 0.05109741  0.03577603 -0.92001635 -0.45783874]
expert:[ 0.07409724 -0.06414989 -0.92076606 -0.4955226 ]
expert:[ 0.10280286 -0.16161765 -0.9229725  -0.53229713]
expert:[ 0.12576093 -0.23370592 -0.9248945  -0.5596956 ]
expert:[ 0.13739827 -0.26447636 -0.9260849  -0.5722252 ]
expert:[ 0.13499969 -0.24538817 -0.92640215 -0.56704086]
expert_success: 0
path_length: 150
