/var/lib/slurm/slurmd/job3511528/slurm_script: line 9: batch_scripts/MT50_batch/seed.sh: No such file or directory
SLURM_JOBID=3511528
working directory=/viscam/u/jialugao/Imitation-SoftModule
########################
logging outputs to  /viscam/u/jialugao/Imitation-SoftModule/data/Base_bc_reach_reach-wall-v1_2640.000123-01-2022_22-52-03
########################
{'expert_policy_file': '../Multi-Task-RL/log/MT50_Single_Task/reach-wall-v1/Fixed/238/model/model_pf_best.pth', 'exp_name': 'bc_reach', 'do_dagger': False, 'ep_len': 200, 'gradient_steps': 1, 'n_iter': 10000, 'render_interval': 1, 'eval_interval': 200, 'batch_size': 64, 'eval_batch_size': 32, 'train_batch_size': 32, 'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'video_log_freq': -1, 'scalar_log_freq': 1, 'no_gpu': False, 'which_gpu': 0, 'max_replay_buffer_size': 1000000, 'save_params': False, 'seed': 32, 'worker_nums': 1, 'eval_worker_nums': 1, 'config': 'config/BC.json', 'no_cuda': True, 'random_init': False, 'device': 'cpu', 'id': 'MT50_Single_Task', 'task_name': 'reach-wall-v1', 'task_env': 'MT50_task_env', 'cuda': False, 'log_dir': '/viscam/u/jialugao/Imitation-SoftModule/data/Base_bc_reach_reach-wall-v1_2640.000123-01-2022_22-52-03', 'agent_class': <class 'agents.bc_agent.MLPAgent'>, 'agent_params': {'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'max_replay_buffer_size': 1000000, 'discrete': False, 'ac_dim': 4, 'ob_dim': 9}}
{'env_name': 'single_task', 'env': {'reward_scale': 1, 'obs_norm': False}, 'meta_env': {'obs_type': 'with_goal', 'random_init': False}, 'replay_buffer': {'size': 1000000.0}, 'net': {'hidden_shapes': [400, 400], 'append_hidden_shapes': [400], 'base_type': <class 'networks.base.MLPBase'>}, 'general_setting': {'discount': 0.99, 'pretrain_epochs': 20, 'num_epochs': 7500, 'epoch_frames': 200, 'max_episode_frames': 200, 'batch_size': 1280, 'min_pool': 10000, 'target_hard_update_period': 1000, 'use_soft_update': True, 'tau': 0.005, 'opt_times': 200, 'eval_episodes': 100, 'train_render': False, 'eval_render': False, 'env': <NormAct<RewardShift<SingleWrapperNone>>>, 'logger': <utils.logger.Logger object at 0x7fdae7b66dd0>, 'device': device(type='cpu')}, 'sac': {'plr': 0.0003, 'qlr': 0.0003, 'reparameterization': True, 'automatic_entropy_tuning': True, 'policy_std_reg_weight': 0, 'policy_mean_reg_weight': 0}}
Loading expert policy from... ../Multi-Task-RL/log/MT50_Single_Task/reach-wall-v1/Fixed/238/model/model_pf_best.pth
Done restoring expert policy...
<NormAct<RewardShift<SawyerReachPushPickPlaceWallEnv instance>>>
<NormAct<RewardShift<SawyerReachPushPickPlaceWallEnv instance>>>


-------------------------------- Iteration 0 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
expert_success: 1.0



-------------------------------- Iteration 0 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 0

training time:  0.11502981185913086
evaluation time:  7.217729330062866
epoch time:  7.33278751373291


-------------------------------- Iteration 200 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.0023550987243652344
evaluation time:  7.1701977252960205
epoch time:  7.1725757122039795


-------------------------------- Iteration 400 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.002529144287109375
evaluation time:  7.089770793914795
epoch time:  7.092318296432495


-------------------------------- Iteration 600 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.0026082992553710938
evaluation time:  7.058314800262451
epoch time:  7.0609400272369385


-------------------------------- Iteration 800 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.0022830963134765625
evaluation time:  6.988473653793335
epoch time:  6.9907755851745605


-------------------------------- Iteration 1000 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.002311229705810547
evaluation time:  6.996686220169067
epoch time:  6.999020338058472


-------------------------------- Iteration 1200 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.0022606849670410156
evaluation time:  6.9739789962768555
epoch time:  6.976257562637329


-------------------------------- Iteration 1400 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.0024895668029785156
evaluation time:  6.995998859405518
epoch time:  6.998555421829224


-------------------------------- Iteration 1600 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.0028426647186279297
evaluation time:  7.026043653488159
epoch time:  7.028898239135742


-------------------------------- Iteration 1800 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.0022592544555664062
evaluation time:  6.9565269947052
epoch time:  6.9587953090667725


-------------------------------- Iteration 2000 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.0022881031036376953
evaluation time:  6.939422369003296
epoch time:  6.941734313964844


-------------------------------- Iteration 2200 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.002263784408569336
evaluation time:  6.948010206222534
epoch time:  6.950283765792847


-------------------------------- Iteration 2400 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.0022737979888916016
evaluation time:  6.94646954536438
epoch time:  6.9487645626068115


-------------------------------- Iteration 2600 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.002258777618408203
evaluation time:  6.939794063568115
epoch time:  6.9420647621154785


-------------------------------- Iteration 2800 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.0024576187133789062
evaluation time:  6.917013883590698
epoch time:  6.919480562210083


-------------------------------- Iteration 3000 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.002290964126586914
evaluation time:  6.97629451751709
epoch time:  6.978597402572632


-------------------------------- Iteration 3200 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.0022661685943603516
evaluation time:  6.961847305297852
epoch time:  6.964135408401489


-------------------------------- Iteration 3400 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.0022559165954589844
evaluation time:  6.962821960449219
epoch time:  6.965086221694946


-------------------------------- Iteration 3600 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.002254962921142578
evaluation time:  6.9321815967559814
epoch time:  6.934452772140503


-------------------------------- Iteration 3800 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.0022797584533691406
evaluation time:  6.944124460220337
epoch time:  6.946413278579712


-------------------------------- Iteration 4000 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.0022611618041992188
evaluation time:  6.932313680648804
epoch time:  6.934586048126221


-------------------------------- Iteration 4200 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.002268552780151367
evaluation time:  6.948919057846069
epoch time:  6.951197862625122


-------------------------------- Iteration 4400 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.002282381057739258
evaluation time:  6.980550289154053
epoch time:  6.982853174209595


-------------------------------- Iteration 4600 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.0023298263549804688
evaluation time:  6.976884365081787
epoch time:  6.979225158691406


-------------------------------- Iteration 4800 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.002277374267578125
evaluation time:  6.975712776184082
epoch time:  6.977999448776245


-------------------------------- Iteration 5000 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.002288341522216797
evaluation time:  6.966554641723633
epoch time:  6.9688520431518555


-------------------------------- Iteration 5200 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.0022652149200439453
evaluation time:  6.948676824569702
epoch time:  6.950952053070068


-------------------------------- Iteration 5400 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.0022535324096679688
evaluation time:  6.950192928314209
epoch time:  6.952463626861572


-------------------------------- Iteration 5600 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.0022699832916259766
evaluation time:  6.926859378814697
epoch time:  6.929137945175171


-------------------------------- Iteration 5800 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.0022821426391601562
evaluation time:  6.931027889251709
epoch time:  6.933329343795776


-------------------------------- Iteration 6000 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.002272367477416992
evaluation time:  7.000424861907959
epoch time:  7.0027196407318115


-------------------------------- Iteration 6200 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.0022971630096435547
evaluation time:  7.005373239517212
epoch time:  7.007678985595703


-------------------------------- Iteration 6400 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.002292156219482422
evaluation time:  6.972340106964111
epoch time:  6.974642992019653


-------------------------------- Iteration 6600 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.0023152828216552734
evaluation time:  6.986253976821899
epoch time:  6.988590955734253


-------------------------------- Iteration 6800 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.0022668838500976562
evaluation time:  6.9395740032196045
epoch time:  6.941850423812866


-------------------------------- Iteration 7000 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.002261638641357422
evaluation time:  6.944830417633057
epoch time:  6.94710373878479


-------------------------------- Iteration 7200 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.002275705337524414
evaluation time:  6.938371658325195
epoch time:  6.9406657218933105


-------------------------------- Iteration 7400 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

training time:  0.002273082733154297
evaluation time:  6.933963060379028
epoch time:  6.936244487762451


-------------------------------- Training stopped due to early stopping -------------------------------- 
min loss:  0.09964791


-------------------------------- Test Results -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
 -0.05        0.8         0.2       ]
agent_success: 1.0

mean_success_rate:  1.0
Done
