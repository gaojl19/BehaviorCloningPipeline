/var/lib/slurm/slurmd/job3513849/slurm_script: line 9: batch_scripts/MT50_batch/seed.sh: No such file or directory
SLURM_JOBID=3513849
working directory=/viscam/u/jialugao/Imitation-SoftModule
########################
logging outputs to  /viscam/u/jialugao/Imitation-SoftModule/data/Base_bc_reach_dissassemble-v1_2640.000124-01-2022_18-56-05
########################
{'expert_policy_file': '../Multi-Task-RL/log/MT50_Single_Task/dissassemble-v1/Fixed/238/model/model_pf_best.pth', 'exp_name': 'bc_reach', 'do_dagger': False, 'ep_len': 200, 'gradient_steps': 1, 'n_iter': 10000, 'render_interval': 1, 'eval_interval': 200, 'batch_size': 64, 'eval_batch_size': 32, 'train_batch_size': 32, 'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'video_log_freq': -1, 'scalar_log_freq': 1, 'no_gpu': False, 'which_gpu': 0, 'max_replay_buffer_size': 1000000, 'save_params': False, 'seed': 32, 'worker_nums': 1, 'eval_worker_nums': 1, 'config': 'config/BC.json', 'no_cuda': True, 'random_init': False, 'device': 'cpu', 'id': 'MT50_Single_Task', 'task_name': 'dissassemble-v1', 'task_env': 'MT50_task_env', 'cuda': False, 'log_dir': '/viscam/u/jialugao/Imitation-SoftModule/data/Base_bc_reach_dissassemble-v1_2640.000124-01-2022_18-56-05', 'agent_class': <class 'agents.bc_agent.MLPAgent'>, 'agent_params': {'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'max_replay_buffer_size': 1000000, 'discrete': False, 'ac_dim': 4, 'ob_dim': 9}}
{'env_name': 'single_task', 'env': {'reward_scale': 1, 'obs_norm': False}, 'meta_env': {'obs_type': 'with_goal', 'random_init': False}, 'replay_buffer': {'size': 1000000.0}, 'net': {'hidden_shapes': [400, 400], 'append_hidden_shapes': [400], 'base_type': <class 'networks.base.MLPBase'>}, 'general_setting': {'discount': 0.99, 'pretrain_epochs': 20, 'num_epochs': 7500, 'epoch_frames': 200, 'max_episode_frames': 200, 'batch_size': 1280, 'min_pool': 10000, 'target_hard_update_period': 1000, 'use_soft_update': True, 'tau': 0.005, 'opt_times': 200, 'eval_episodes': 100, 'train_render': False, 'eval_render': False, 'env': <NormAct<RewardShift<SingleWrapperNone>>>, 'logger': <utils.logger.Logger object at 0x7fb29c634e10>, 'device': device(type='cpu')}, 'sac': {'plr': 0.0003, 'qlr': 0.0003, 'reparameterization': True, 'automatic_entropy_tuning': True, 'policy_std_reg_weight': 0, 'policy_mean_reg_weight': 0}}
Loading expert policy from... ../Multi-Task-RL/log/MT50_Single_Task/dissassemble-v1/Fixed/238/model/model_pf_best.pth
tensor([[-0.6432,  0.0067,  0.0789,  ..., -0.0365, -0.0035, -0.0495],
        [ 0.0092, -0.0261, -0.0293,  ...,  0.0090,  0.0009, -0.0688],
        [-0.1540, -0.1006, -0.2400,  ..., -0.0016,  0.0179, -0.0039],
        ...,
        [ 0.4273, -0.1463, -0.0337,  ...,  0.0400, -0.0160, -0.0113],
        [-0.2304, -0.0659, -0.2723,  ..., -0.0461,  0.0360,  0.0104],
        [-0.0700,  0.0525, -0.3062,  ..., -0.0211, -0.0479, -0.0159]])
Done restoring expert policy...
<NormAct<RewardShift<AugObs<SawyerNutDisassembleEnv instance>>>>


-------------------------------- Iteration 0 -------------------------------- 
initial ob: [-0.03265068  0.5148846   0.23688553  0.09        0.8         0.02
  0.          0.8         0.17        0.          0.8         0.17      ]
expert:[ 0.9934635  0.8785628  0.9895196 -0.9654936]
expert:[ 0.9925552  0.8433663  0.989733  -0.9528556]
expert:[ 0.99204487  0.80664694  0.9901595  -0.9396164 ]
expert:[ 0.99203837  0.78746706  0.9906276  -0.9322659 ]
expert:[ 0.99207467  0.78385526  0.9908015  -0.9301528 ]
expert:[ 0.99266225  0.7922592   0.9912226  -0.9335331 ]
expert:[ 0.9078949   0.9017407  -0.2809772  -0.87420875]
expert:[ 0.8578113   0.9333549  -0.9164983  -0.86478376]
expert:[ 0.8757545  0.938626  -0.9256183 -0.8687666]
expert:[ 0.8677358   0.9334953  -0.9184993  -0.86227715]
expert:[ 0.78775764  0.90043485 -0.87606055 -0.81758803]
expert:[ 0.582942    0.81251603 -0.7599501  -0.6913284 ]
expert:[ 0.20211811  0.66119254 -0.34058297 -0.38760796]
expert:[-0.08598331  0.5351429   0.31683832 -0.07027376]
expert:[-0.21374679  0.489965    0.7063921   0.02326993]
expert:[-0.2493849   0.4554732   0.7790386   0.07200969]
expert:[-0.24147977  0.43140823  0.75527716  0.08708552]
expert:[-0.18149266  0.4092434   0.5907875   0.06656524]
expert:[-0.13143031  0.3777841   0.32085776 -0.00520472]
expert:[-0.06339006  0.3512094   0.10483852 -0.0950552 ]
expert:[ 0.00377761  0.33202785 -0.04934339 -0.16636708]
expert:[ 0.06437567  0.31291634 -0.17200027 -0.21656153]
expert:[ 0.10305458  0.28719538 -0.23503166 -0.23696166]
expert:[ 0.11557655  0.2492645  -0.2454484  -0.22930948]
expert:[ 0.10777039  0.19953094 -0.22193421 -0.20343867]
expert:[ 0.08699082  0.14220949 -0.1749638  -0.16441947]
expert:[ 0.05955812  0.08471204 -0.11211877 -0.11850405]
expert:[ 0.03157389  0.03513581 -0.03770587 -0.06902625]
expert:[ 0.00946956 -0.00595896  0.02922646 -0.02619023]
expert:[-0.00682486 -0.03839223  0.08051217  0.00721325]
expert:[-0.01753285 -0.05930446  0.11308878  0.02854764]
expert:[-0.02123731 -0.06691527  0.12408026  0.03677702]
expert:[-0.02018559 -0.06550522  0.11893305  0.03350643]
expert:[-0.01497026 -0.05670042  0.10036692  0.02111211]
expert:[-0.00639671 -0.04141558  0.07186742  0.00288027]
expert:[ 0.0032969  -0.02325161  0.03947974 -0.0178665 ]
expert:[ 0.01237791 -0.00547776  0.00870937 -0.03769027]
expert:[ 0.01967816  0.00965962 -0.01662125 -0.05413961]
expert:[ 0.02455679  0.02013986 -0.03387129 -0.06539975]
expert:[ 0.0265451   0.02649912 -0.04214144 -0.07126766]
expert:[ 0.02578791  0.02888071 -0.0418906  -0.07199828]
expert:[ 0.0232019   0.0285898  -0.03606175 -0.06927657]
expert:[ 0.01964698  0.02690271 -0.02720299 -0.06478117]
expert:[ 0.01544873  0.023862   -0.01617884 -0.05887412]
expert:[ 0.0110686   0.01961327 -0.00423489 -0.05217024]
expert:[ 0.00700194  0.01510392  0.00687874 -0.04576741]
expert:[ 0.00372323  0.0112122   0.01577711 -0.04058227]
expert:[ 0.00144579  0.00832233  0.02180155 -0.03702947]
expert:[ 0.00025433  0.00665042  0.02465458 -0.03531214]
expert:[ 0.00015962  0.00630306  0.02427464 -0.03549506]
expert:[ 0.00102183  0.00719388  0.02115821 -0.03733046]
expert:[ 0.00249255  0.00888987  0.01623517 -0.04024492]
expert:[ 0.0042304   0.010938    0.01054035 -0.04361587]
expert:[ 0.00591061  0.01289852  0.0050528  -0.04685548]
expert:[ 0.00718328  0.01440159  0.00082087 -0.04936333]
expert:[ 0.00797672  0.01522051 -0.0019379  -0.05097849]
expert:[ 0.00827025  0.01531896 -0.00316436 -0.05166254]
expert:[ 0.00812631  0.01479937 -0.00305985 -0.05154063]
expert:[ 0.00764801  0.01382044 -0.00195277 -0.05081694]
expert:[ 0.00696257  0.01257243 -0.00023259 -0.049729  ]
expert:[ 0.00619015  0.01122973  0.00173852 -0.0484964 ]
expert:[ 0.00543412  0.00994046  0.00365097 -0.04730666]
expert:[ 0.00477785  0.00882406  0.00525499 -0.04631097]
expert:[ 0.00428014  0.00797199  0.00637166 -0.04562   ]
expert:[ 0.00397037  0.00744526  0.00690743 -0.04529659]
expert:[ 0.00384883  0.00722237  0.00686877 -0.0453295 ]
expert:[ 0.00388476  0.00725468  0.00635222 -0.04565903]
expert:[ 0.00402756  0.00746236  0.00551547 -0.04618755]
expert:[ 0.00421806  0.00775059  0.0045426  -0.04680099]
expert:[ 0.00440074  0.0080364   0.00360366 -0.04739555]
expert:[ 0.00453241  0.00826448  0.00282682 -0.04789611]
expert:[ 0.00459029  0.00837832  0.00228756 -0.04824993]
expert:[ 0.00456773  0.00836677  0.0020051  -0.04844513]
expert:[ 0.00447165  0.00825742  0.00195175 -0.04850424]
expert:[ 0.00432141  0.0080617   0.00207128 -0.04845606]
expert:[ 0.00413949  0.00781242  0.00229427 -0.04834289]
expert:[ 0.00394811  0.00754069  0.002553   -0.04820564]
expert:[ 0.00376662  0.00727761  0.00278786 -0.04808117]
expert:[ 0.00360804  0.00704141  0.00295988 -0.047993  ]
expert:[ 0.00347957  0.00684252  0.00304785 -0.04795397]
expert:[ 0.00338231  0.0066829   0.00304889 -0.04796589]
expert:[ 0.0033128   0.00655857  0.00297377 -0.04802249]
expert:[ 0.00326335  0.00645826  0.00284614 -0.04810928]
expert:[ 0.0032261   0.00637091  0.00269008 -0.04821168]
expert:[ 0.00319272  0.00628572  0.00253028 -0.04831515]
expert:[ 0.00315658  0.00619316  0.00238685 -0.04840745]
expert:[ 0.0031139   0.0060895   0.00227013 -0.04848274]
expert:[ 0.00306244  0.00597158  0.00218653 -0.04853722]
expert:[ 0.00300185  0.00584233  0.00213448 -0.04857228]
expert:[ 0.00293201  0.0057039   0.00211117 -0.04858931]
expert:[ 0.00285889  0.00556153  0.00210236 -0.04859751]
expert:[ 0.00278574  0.00542109  0.00209758 -0.04860359]
expert:[ 0.00271508  0.00528699  0.00208899 -0.04861242]
expert:[ 0.0026488   0.00516031  0.00207116 -0.0486269 ]
expert:[ 0.00258766  0.00504353  0.0020415  -0.04864898]
expert:[ 0.00253166  0.00493456  0.00200079 -0.04867764]
expert:[ 0.00247985  0.00483325  0.00195147 -0.04871171]
expert:[ 0.00243126  0.00473771  0.00189665 -0.04874917]
expert:[ 0.00238434  0.00464755  0.00184046 -0.04878815]
expert:[ 0.00233773  0.00456382  0.001786   -0.04882764]
expert:[ 0.00229094  0.00448319  0.00173503 -0.04886564]
expert:[ 0.00224292  0.00440703  0.00168955 -0.04890191]
expert:[ 0.00219483  0.00432921  0.00164883 -0.04893463]
expert:[ 0.00214672  0.00425046  0.00161265 -0.04896415]
expert:[ 0.00209881  0.00417046  0.00158017 -0.04899082]
expert:[ 0.00205159  0.00408997  0.00155006 -0.0490155 ]
expert:[ 0.00200513  0.00401251  0.00152059 -0.04904049]
expert:[ 0.00195989  0.00393831  0.00149046 -0.04906614]
expert:[ 0.00191606  0.00386299  0.00146081 -0.04909058]
expert:[ 0.00187382  0.00378909  0.0014302  -0.04911518]
expert:[ 0.00183299  0.00371467  0.00139958 -0.04913894]
expert:[ 0.00179343  0.00364004  0.00136925 -0.04916179]
expert:[ 0.00175525  0.00356738  0.00133826 -0.04918485]
expert:[ 0.00171784  0.00349328  0.00130892 -0.04920604]
expert:[ 0.00168151  0.00342003  0.00127978 -0.04922685]
expert:[ 0.00164598  0.003348    0.00125132 -0.04924705]
expert:[ 0.0016112   0.00327529  0.00122429 -0.04926569]
expert:[ 0.00157718  0.00320422  0.00119772 -0.04928407]
expert:[ 0.00154364  0.00313503  0.00117217 -0.04930202]
expert:[ 0.00151108  0.00306706  0.00114651 -0.04931976]
expert:[ 0.00147914  0.00299931  0.001122   -0.0493365 ]
expert:[ 0.00144799  0.00293422  0.00109731 -0.04935357]
expert:[ 0.0014173   0.00287081  0.00107359 -0.04937011]
expert:[ 0.00138754  0.00280859  0.00104965 -0.0493867 ]
expert:[ 0.00135831  0.00274739  0.00102658 -0.04940261]
expert:[ 0.00132954  0.00268855  0.00100403 -0.04941851]
expert:[ 0.00130166  0.00263052  0.00098143 -0.04943414]
expert:[ 0.00127406  0.00257416  0.00095987 -0.04944938]
expert:[ 0.00124716  0.00251969  0.00093834 -0.04946464]
expert:[ 0.00122076  0.00246607  0.00091743 -0.04947948]
expert:[ 0.00119478  0.0024136   0.00089741 -0.04949377]
expert:[ 0.00116945  0.00236233  0.00087755 -0.04950789]
expert:[ 0.00114448  0.00231142  0.00085871 -0.0495212 ]
expert:[ 0.00112012  0.00226245  0.00083986 -0.04953472]
expert:[ 0.00109637  0.00221458  0.00082109 -0.0495481 ]
expert:[ 0.00107296  0.00216807  0.00080309 -0.04956112]
expert:[ 0.00105001  0.00212169  0.00078587 -0.04957343]
expert:[ 0.0010276   0.00207716  0.00076849 -0.04958598]
expert:[ 0.00100595  0.00204455  0.00074634 -0.04959844]
expert:[ 0.00098475  0.00201504  0.0007238  -0.04961064]
expert:[ 0.00096363  0.00198457  0.00070315 -0.04962143]
expert:[ 0.00094263  0.00195349  0.00068451 -0.04963079]
expert:[ 0.00092155  0.00192183  0.00066782 -0.0496388 ]
expert:[ 0.00090059  0.00188739  0.00065368 -0.04964451]
expert:[ 0.00087985  0.00185212  0.00064105 -0.04964895]
expert:[ 0.00085943  0.00181606  0.00062948 -0.04965243]
expert:[ 0.00083962  0.0017799   0.00061805 -0.04965562]
expert:[ 0.00082038  0.00174357  0.00060674 -0.04965845]
expert:[ 0.0008021   0.00170729  0.00059461 -0.0496615 ]
expert:[ 0.00078442  0.00167155  0.00058228 -0.04966463]
expert:[ 0.00076741  0.00163595  0.00056975 -0.04966768]
expert:[ 0.00075089  0.00160067  0.00055727 -0.04967059]
expert:[ 0.00073503  0.00156593  0.00054435 -0.04967374]
expert:[ 0.00071951  0.00153168  0.00053183 -0.04967669]
expert:[ 0.00070432  0.00149854  0.00051954 -0.04967967]
expert:[ 0.00068956  0.00146475  0.00050762 -0.04968211]
expert:[ 0.00067497  0.00143258  0.00049614 -0.04968472]
expert:[ 0.00066055  0.001401    0.0004852  -0.04968712]
expert:[ 0.00064642  0.00136957  0.00047476 -0.04968913]
expert:[ 0.00063261  0.00133943  0.00046422 -0.04969146]
expert:[ 0.00061912  0.00130963  0.00045401 -0.04969357]
expert:[ 0.00060575  0.00128085  0.00044433 -0.04969564]
expert:[ 0.00059275  0.00125258  0.00043465 -0.04969776]
expert:[ 0.00057989  0.00122514  0.00042548 -0.04969971]
expert:[ 0.00056759  0.00119932  0.00041545 -0.04970248]
expert:[ 0.0005554   0.00117304  0.00040638 -0.04970452]
expert:[ 0.00054339  0.00114728  0.00039761 -0.04970639]
expert:[ 0.00053182  0.00112201  0.00038878 -0.04970837]
expert:[ 0.00052025  0.00109825  0.00038032 -0.04971053]
expert:[ 0.00050898  0.00107478  0.00037205 -0.04971257]
expert:[ 0.00049807  0.00105155  0.00036378 -0.04971455]
expert:[ 0.00048729  0.00102873  0.00035585 -0.0497164 ]
expert:[ 0.00047668  0.00100669  0.00034828 -0.04971823]
expert:[ 0.00046647  0.00098571  0.00034018 -0.04972051]
expert:[ 0.00045647  0.00096391  0.00033274 -0.04972208]
expert:[ 0.00044666  0.0009435   0.00032515 -0.0497241 ]
expert:[ 0.00043679  0.00092266  0.00031878 -0.04972527]
expert:[ 0.00042749  0.00090303  0.00031145 -0.0497272 ]
expert:[ 0.00041807  0.00088378  0.00030496 -0.04972874]
expert:[ 0.00040909  0.00086448  0.00029827 -0.04973028]
expert:[ 0.00040029  0.00084645  0.00029138 -0.04973214]
expert:[ 0.00039164  0.00082769  0.00028528 -0.04973338]
expert:[ 0.00038319  0.00081064  0.00027869 -0.04973529]
expert:[ 0.0003748   0.00079223  0.00027317 -0.04973614]
expert:[ 0.0003668   0.00077526  0.00026679 -0.0497378 ]
expert:[ 0.00035885  0.00075839  0.00026116 -0.04973904]
expert:[ 0.0003511   0.00074199  0.0002555  -0.04974034]
expert:[ 0.00034348  0.00072653  0.00024979 -0.04974193]
expert:[ 0.00033619  0.00071097  0.00024392 -0.04974344]
expert:[ 0.00032878  0.00069566  0.00023891 -0.04974454]
expert:[ 0.0003216   0.00067984  0.00023416 -0.04974527]
expert:[ 0.00031471  0.00066553  0.0002288  -0.04974671]
expert:[ 0.00030803  0.00065088  0.00022358 -0.04974791]
expert:[ 0.00030125  0.00063713  0.00021888 -0.04974907]
expert:[ 0.00029485  0.00062288  0.00021389 -0.0497501 ]
expert:[ 0.00028848  0.00060966  0.00020922 -0.04975132]
expert:[ 0.0002821   0.00059679  0.0002049  -0.04975236]
expert:[ 0.00027617  0.00058357  0.00020009 -0.04975344]
expert:[ 0.00027006  0.00057139  0.00019587 -0.04975457]
expert:[ 0.00026426  0.00055875  0.00019161 -0.04975545]
expert_success: 0
path_length: 200



-------------------------------- Iteration 0 -------------------------------- 
initial ob: [-0.03265068  0.5148846   0.23688553  0.09        0.8         0.02
  0.          0.8         0.17        0.          0.8         0.17      ]
agent_success: 0

training time:  0.19812893867492676
evaluation time:  13.41456389427185
epoch time:  13.612722396850586


-------------------------------- Training stopped due to early stopping -------------------------------- 
min loss:  0.0031177877


-------------------------------- Test Results -------------------------------- 
initial ob: [-0.03265068  0.5148846   0.23688553  0.09        0.8         0.02
  0.          0.8         0.17        0.          0.8         0.17      ]
agent_success: 0

mean_success_rate:  0.0
Done
