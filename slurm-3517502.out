SLURM_JOBID=3517502
working directory=/viscam/u/jialugao/Imitation-SoftModule
{'obs_type': 'with_goal'}
obs type:  with_goal
{'expert_policy_file': 'policy/expert/MT10_Fail/', 'exp_name': 'bc_reach', 'do_dagger': False, 'ep_len': 200, 'gradient_steps': 1, 'n_iter': 100000, 'render_interval': 40, 'eval_interval': 1000, 'batch_size': 64, 'eval_batch_size': 32, 'train_batch_size': 32, 'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'video_log_freq': -1, 'scalar_log_freq': 1, 'no_gpu': False, 'which_gpu': 0, 'max_replay_buffer_size': 1000000, 'save_params': False, 'seed': 32, 'worker_nums': 1, 'eval_worker_nums': 1, 'config': 'config/soft_module_fixed_mt10_fail.json', 'no_cuda': True, 'random_init': False, 'device': 'cpu', 'id': 'MT50_Single_Task', 'task_name': None, 'task_env': 'MT50_task_env', 'cuda': False, 'agent_class': <class 'agents.bc_agent.SoftModuleAgent'>, 'agent_params': {'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'max_replay_buffer_size': 1000000, 'discrete': False}}
{'env_name': 'mt10_fail', 'env': {'reward_scale': 1, 'obs_norm': False}, 'meta_env': {'obs_type': 'with_goal', 'random_init': False}, 'replay_buffer': {'size': 1000000.0}, 'expert_net': {'hidden_shapes': [400, 400], 'append_hidden_shapes': [400]}, 'net': {'hidden_shapes': [400, 400], 'em_hidden_shapes': [400], 'num_layers': 2, 'num_modules': 2, 'module_hidden': 256, 'num_gating_layers': 2, 'gating_hidden': 256, 'add_bn': False, 'pre_softmax': False, 'base_type': <class 'networks.base.MLPBase'>}, 'general_setting': {'discount': 0.99, 'pretrain_epochs': 20, 'num_epochs': 7500, 'epoch_frames': 200, 'max_episode_frames': 200, 'batch_size': 1280, 'min_pool': 10000, 'target_hard_update_period': 1000, 'use_soft_update': True, 'tau': 0.005, 'opt_times': 200, 'eval_episodes': 1, 'train_render': False, 'eval_render': False, 'env': <NormAct<RewardShift<MTEnv instance>>>, 'device': device(type='cpu')}, 'sac': {'plr': 0.0003, 'qlr': 0.0003, 'reparameterization': True, 'automatic_entropy_tuning': True, 'policy_std_reg_weight': 0, 'policy_mean_reg_weight': 0}}
Loading expert policy from... policy/expert/MT10_Fail/
Done restoring expert policy...
<NormAct<RewardShift<AugObs<SawyerNutDisassembleEnv instance>>>>
<NormAct<RewardShift<AugObs<SawyerNutAssemblyEnv instance>>>>
<NormAct<RewardShift<AugObs<SawyerHandInsertEnv instance>>>>
<NormAct<RewardShift<AugObs<SawyerReachPushPickPlaceEnv instance>>>>
<NormAct<RewardShift<AugObs<SawyerReachPushPickPlaceWallEnv instance>>>>
<NormAct<RewardShift<AugObs<SawyerStickPushEnv instance>>>>
<NormAct<RewardShift<AugObs<SawyerPickOutOfHoleEnv instance>>>>
<NormAct<RewardShift<AugObs<SawyerBoxCloseEnv instance>>>>
<NormAct<RewardShift<AugObs<SawyerBinPickingEnv instance>>>>
<NormAct<RewardShift<AugObs<SawyerBasketballEnv instance>>>>
/viscam/u/jialugao/.anaconda3/envs/metaworldEnv/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: [33mWARN: Could not seed environment <MTEnv instance>[0m
  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))


-------------------------------- Iteration 0 -------------------------------- 
initial ob: [-0.03265068  0.5148846   0.23688553  0.09        0.8         0.02
  0.          0.8         0.17        0.          0.8         0.17      ]
expert_success: 0
path_length: 200

initial ob: [-0.03265068  0.5148846   0.23688553  0.06        0.60000002  0.02
  0.1         0.80000001  0.1         0.1         0.80000001  0.1       ]
expert_success: 0
path_length: 200

initial ob: [-0.03359098  0.51376544  0.23633854  0.          0.6         0.01997144
  0.          0.83999997 -0.08        0.          0.83999997 -0.08      ]
expert_success: 1.0
path_length: 200

initial ob: [-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
  0.1         0.8         0.2         0.1         0.8         0.2       ]
expert_success: 1.0
path_length: 150

initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
  0.05        0.8         0.2         0.05        0.8         0.2       ]
expert_success: 1.0
path_length: 150

initial ob: [-0.032652    0.51487875  0.23688607 -0.1         0.6         0.02
  0.2         0.6         0.08        0.4         0.6         0.02
  0.4         0.6         0.02      ]
expert_success: 1.0
path_length: 200

initial ob: [-0.03357615  0.51377786  0.2363442   0.          0.84       -0.03
  0.          0.6         0.2         0.          0.6         0.2       ]
expert_success: 0
path_length: 200

initial ob: [-0.0326477   0.51488164  0.23687858  0.          0.60000002  0.11
  0.          0.9         0.133       0.          0.9         0.133     ]
expert_success: 1.0
path_length: 200

initial ob: [-0.03264955  0.51487925  0.23688598 -0.12        0.7         0.04532742
  0.12        0.7         0.02        0.12        0.7         0.02      ]
expert_success: 0
path_length: 150

initial ob: [-0.03264993  0.51487868  0.2368869   0.          0.60000002  0.03
  0.          0.85        0.25        0.          0.85        0.25      ]
expert_success: 1.0
path_length: 150

{'dissassemble-v1_success_rate': array(0., dtype=float32), 'assembly-v1_success_rate': array(0., dtype=float32), 'hand-insert-v1_success_rate': array(1., dtype=float32), 'pick-place-v1_success_rate': array(1., dtype=float32), 'pick-place-wall-v1_success_rate': array(1., dtype=float32), 'stick-push-v1_success_rate': array(1., dtype=float32), 'pick-out-of-hole-v1_success_rate': array(0., dtype=float32), 'box-close-v1_success_rate': array(1., dtype=float32), 'bin-picking-v1_success_rate': array(0., dtype=float32), 'basket-ball-v1_success_rate': array(1., dtype=float32), 'mean_success_rate': 0.6}


-------------------------------- Iteration 0 -------------------------------- 
training time:  1.2958803176879883
evaluation time:  7.77904200553894
epoch time:  9.074939489364624
loss:  0.6749379


-------------------------------- Iteration 1000 -------------------------------- 
training time:  0.011887311935424805
evaluation time:  7.837610960006714
epoch time:  7.84951376914978
loss:  0.17831731


-------------------------------- Iteration 2000 -------------------------------- 
training time:  0.012104272842407227
evaluation time:  7.795751333236694
epoch time:  7.807872772216797
loss:  0.16944803


-------------------------------- Iteration 3000 -------------------------------- 
training time:  0.011846780776977539
evaluation time:  7.751563787460327
epoch time:  7.763438940048218
loss:  0.16210806


-------------------------------- Iteration 4000 -------------------------------- 
training time:  0.01190495491027832
evaluation time:  7.933063983917236
epoch time:  7.9449827671051025
loss:  0.207412


-------------------------------- Iteration 5000 -------------------------------- 
training time:  0.011891365051269531
evaluation time:  7.828639268875122
epoch time:  7.840548992156982
loss:  0.08665166


-------------------------------- Iteration 6000 -------------------------------- 
training time:  0.011916875839233398
evaluation time:  7.81393027305603
epoch time:  7.82586145401001
loss:  0.2145195


-------------------------------- Iteration 7000 -------------------------------- 
training time:  0.011911630630493164
evaluation time:  7.958512783050537
epoch time:  7.970454454421997
loss:  0.108401135


-------------------------------- Iteration 8000 -------------------------------- 
training time:  0.013286828994750977
evaluation time:  7.82303261756897
epoch time:  7.836362361907959
loss:  0.16852602


-------------------------------- Iteration 9000 -------------------------------- 
training time:  0.011976957321166992
evaluation time:  7.806822776794434
epoch time:  7.818819284439087
loss:  0.12384262


-------------------------------- Iteration 10000 -------------------------------- 
training time:  0.012038707733154297
evaluation time:  7.937699556350708
epoch time:  7.949766397476196
loss:  0.17991218


-------------------------------- Iteration 11000 -------------------------------- 
training time:  0.011898279190063477
evaluation time:  7.824585676193237
epoch time:  7.836504697799683
loss:  0.1065785


-------------------------------- Iteration 12000 -------------------------------- 
training time:  0.012718677520751953
evaluation time:  7.7997636795043945
epoch time:  7.812511444091797
loss:  0.11856476


-------------------------------- Iteration 13000 -------------------------------- 
training time:  0.011933088302612305
evaluation time:  7.873930931091309
epoch time:  7.88587760925293
loss:  0.063727945


-------------------------------- Iteration 14000 -------------------------------- 
training time:  0.013180017471313477
evaluation time:  7.8962273597717285
epoch time:  7.909424304962158
loss:  0.11528987


-------------------------------- Iteration 15000 -------------------------------- 
training time:  0.01292872428894043
evaluation time:  7.819029331207275
epoch time:  7.831979036331177
loss:  0.084427744


-------------------------------- Iteration 16000 -------------------------------- 
training time:  0.011894464492797852
evaluation time:  7.829195022583008
epoch time:  7.8411033153533936
loss:  0.046609383


-------------------------------- Iteration 17000 -------------------------------- 
training time:  0.011847734451293945
evaluation time:  7.932321548461914
epoch time:  7.944185018539429
loss:  0.07469535


-------------------------------- Iteration 18000 -------------------------------- 
training time:  0.011791467666625977
evaluation time:  7.819222688674927
epoch time:  7.8310546875
loss:  0.09498807


-------------------------------- Iteration 19000 -------------------------------- 
training time:  0.01197671890258789
evaluation time:  7.852751731872559
epoch time:  7.864742279052734
loss:  0.07646391


-------------------------------- Iteration 20000 -------------------------------- 
training time:  0.012020349502563477
evaluation time:  7.9609551429748535
epoch time:  7.972989797592163
loss:  0.07351886


-------------------------------- Iteration 21000 -------------------------------- 
training time:  0.011885404586791992
evaluation time:  7.82295560836792
epoch time:  7.834896564483643
loss:  0.113434695


-------------------------------- Iteration 22000 -------------------------------- 
training time:  0.011876583099365234
evaluation time:  7.844434976577759
epoch time:  7.856324911117554
loss:  0.09705081


-------------------------------- Iteration 23000 -------------------------------- 
training time:  0.012017250061035156
evaluation time:  7.85462498664856
epoch time:  7.866662263870239
loss:  0.04853817


-------------------------------- Iteration 24000 -------------------------------- 
training time:  0.011868000030517578
evaluation time:  7.8880674839019775
epoch time:  7.899976968765259
loss:  0.07230979


-------------------------------- Iteration 25000 -------------------------------- 
training time:  0.011998176574707031
evaluation time:  7.842426061630249
epoch time:  7.854437828063965
loss:  0.07548179


-------------------------------- Iteration 26000 -------------------------------- 
training time:  0.011904716491699219
evaluation time:  7.816802740097046
epoch time:  7.828722715377808
<string>:6: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
loss:  0.10640997


-------------------------------- Iteration 27000 -------------------------------- 
training time:  0.012142419815063477
evaluation time:  7.940024375915527
epoch time:  7.952196359634399
loss:  0.10713034


-------------------------------- Iteration 28000 -------------------------------- 
training time:  0.01228952407836914
evaluation time:  7.865718126296997
epoch time:  7.878021478652954
loss:  0.07926881


-------------------------------- Iteration 29000 -------------------------------- 
training time:  0.011851787567138672
evaluation time:  7.788125514984131
epoch time:  7.799991846084595
loss:  0.048651993


-------------------------------- Iteration 30000 -------------------------------- 
training time:  0.01203465461730957
evaluation time:  7.81964373588562
epoch time:  7.831705570220947
loss:  0.049690664


-------------------------------- Iteration 31000 -------------------------------- 
training time:  0.012032747268676758
evaluation time:  7.940884113311768
epoch time:  7.952929258346558
loss:  0.06208341


-------------------------------- Iteration 32000 -------------------------------- 
training time:  0.012202739715576172
evaluation time:  7.820789575576782
epoch time:  7.833012104034424
loss:  0.03702747


-------------------------------- Iteration 33000 -------------------------------- 
training time:  0.012703657150268555
evaluation time:  7.798873424530029
epoch time:  7.811596870422363
loss:  0.050376303


-------------------------------- Iteration 34000 -------------------------------- 
training time:  0.012284278869628906
evaluation time:  7.957784652709961
epoch time:  7.9700822830200195
loss:  0.056445714


-------------------------------- Iteration 35000 -------------------------------- 
training time:  0.012121200561523438
evaluation time:  7.824669122695923
epoch time:  7.836836814880371
loss:  0.026383761


-------------------------------- Iteration 36000 -------------------------------- 
training time:  0.011937379837036133
evaluation time:  7.853308916091919
epoch time:  7.865274906158447
loss:  0.040844582


-------------------------------- Iteration 37000 -------------------------------- 
training time:  0.012528657913208008
evaluation time:  7.84274435043335
epoch time:  7.855286121368408
loss:  0.020725489


-------------------------------- Iteration 38000 -------------------------------- 
training time:  0.012027263641357422
evaluation time:  7.8983376026153564
epoch time:  7.910403490066528
loss:  0.060553342


-------------------------------- Iteration 39000 -------------------------------- 
training time:  0.012160778045654297
evaluation time:  7.805013179779053
epoch time:  7.817198276519775
loss:  0.05249636


-------------------------------- Iteration 40000 -------------------------------- 
training time:  0.012518882751464844
evaluation time:  7.839505910873413
epoch time:  7.852038860321045
loss:  0.02202639


-------------------------------- Iteration 41000 -------------------------------- 
training time:  0.011979818344116211
evaluation time:  7.919498920440674
epoch time:  7.931498050689697
loss:  0.067390785


-------------------------------- Training stopped due to early stopping -------------------------------- 
min loss:  0.0035692207


-------------------------------- Test Results -------------------------------- 
assembly-v1_success_rate _success_rate:  0.0
basket-ball-v1_success_rate _success_rate:  0.0
bin-picking-v1_success_rate _success_rate:  0.0
box-close-v1_success_rate _success_rate:  0.0
dissassemble-v1_success_rate _success_rate:  0.0
hand-insert-v1_success_rate _success_rate:  1.0
pick-out-of-hole-v1_success_rate _success_rate:  0.0
pick-place-v1_success_rate _success_rate:  0.0
pick-place-wall-v1_success_rate _success_rate:  1.0
stick-push-v1_success_rate _success_rate:  1.0
mean_success_rate:  0.3
Done
