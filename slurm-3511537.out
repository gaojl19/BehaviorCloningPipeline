/var/lib/slurm/slurmd/job3511537/slurm_script: line 9: batch_scripts/MT50_batch/seed.sh: No such file or directory
SLURM_JOBID=3511537
working directory=/viscam/u/jialugao/Imitation-SoftModule
########################
logging outputs to  /viscam/u/jialugao/Imitation-SoftModule/data/Base_bc_reach_button-press-topdown-wall-v1_2640.000123-01-2022_22-52-12
########################
{'expert_policy_file': '../Multi-Task-RL/log/MT50_Single_Task/button-press-topdown-wall-v1/Fixed/238/model/model_pf_best.pth', 'exp_name': 'bc_reach', 'do_dagger': False, 'ep_len': 200, 'gradient_steps': 1, 'n_iter': 10000, 'render_interval': 1, 'eval_interval': 200, 'batch_size': 64, 'eval_batch_size': 32, 'train_batch_size': 32, 'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'video_log_freq': -1, 'scalar_log_freq': 1, 'no_gpu': False, 'which_gpu': 0, 'max_replay_buffer_size': 1000000, 'save_params': False, 'seed': 32, 'worker_nums': 1, 'eval_worker_nums': 1, 'config': 'config/BC.json', 'no_cuda': True, 'random_init': False, 'device': 'cpu', 'id': 'MT50_Single_Task', 'task_name': 'button-press-topdown-wall-v1', 'task_env': 'MT50_task_env', 'cuda': False, 'log_dir': '/viscam/u/jialugao/Imitation-SoftModule/data/Base_bc_reach_button-press-topdown-wall-v1_2640.000123-01-2022_22-52-12', 'agent_class': <class 'agents.bc_agent.MLPAgent'>, 'agent_params': {'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'max_replay_buffer_size': 1000000, 'discrete': False, 'ac_dim': 4, 'ob_dim': 9}}
{'env_name': 'single_task', 'env': {'reward_scale': 1, 'obs_norm': False}, 'meta_env': {'obs_type': 'with_goal', 'random_init': False}, 'replay_buffer': {'size': 1000000.0}, 'net': {'hidden_shapes': [400, 400], 'append_hidden_shapes': [400], 'base_type': <class 'networks.base.MLPBase'>}, 'general_setting': {'discount': 0.99, 'pretrain_epochs': 20, 'num_epochs': 7500, 'epoch_frames': 200, 'max_episode_frames': 200, 'batch_size': 1280, 'min_pool': 10000, 'target_hard_update_period': 1000, 'use_soft_update': True, 'tau': 0.005, 'opt_times': 200, 'eval_episodes': 100, 'train_render': False, 'eval_render': False, 'env': <NormAct<RewardShift<SingleWrapperNone>>>, 'logger': <utils.logger.Logger object at 0x7f91a2fc2cd0>, 'device': device(type='cpu')}, 'sac': {'plr': 0.0003, 'qlr': 0.0003, 'reparameterization': True, 'automatic_entropy_tuning': True, 'policy_std_reg_weight': 0, 'policy_mean_reg_weight': 0}}
Loading expert policy from... ../Multi-Task-RL/log/MT50_Single_Task/button-press-topdown-wall-v1/Fixed/238/model/model_pf_best.pth
Done restoring expert policy...
<NormAct<RewardShift<SawyerButtonPressTopdownWallEnv instance>>>
<NormAct<RewardShift<SawyerButtonPressTopdownWallEnv instance>>>


-------------------------------- Iteration 0 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
expert_success: 1.0



-------------------------------- Iteration 0 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 0

training time:  0.11455774307250977
evaluation time:  7.207931756973267
epoch time:  7.322517395019531


-------------------------------- Iteration 200 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 0

training time:  0.0023467540740966797
evaluation time:  8.449212551116943
epoch time:  8.451578617095947


-------------------------------- Iteration 400 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 0

training time:  0.002291440963745117
evaluation time:  7.772642374038696
epoch time:  7.7749574184417725


-------------------------------- Iteration 600 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 0

training time:  0.0022962093353271484
evaluation time:  7.869836807250977
epoch time:  7.872154951095581


-------------------------------- Iteration 800 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

training time:  0.002271413803100586
evaluation time:  7.47640585899353
epoch time:  7.478698968887329


-------------------------------- Iteration 1000 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

training time:  0.002298593521118164
evaluation time:  8.866310358047485
epoch time:  8.868626832962036


-------------------------------- Iteration 1200 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

training time:  0.00241851806640625
evaluation time:  7.749774694442749
epoch time:  7.752216100692749


-------------------------------- Iteration 1400 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

training time:  0.0023016929626464844
evaluation time:  8.9414963722229
epoch time:  8.94386601448059


-------------------------------- Iteration 1600 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

training time:  0.0022814273834228516
evaluation time:  8.406749725341797
epoch time:  8.409042119979858


-------------------------------- Iteration 1800 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

training time:  0.0022840499877929688
evaluation time:  8.014943361282349
epoch time:  8.017241954803467


-------------------------------- Iteration 2000 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

training time:  0.002305269241333008
evaluation time:  7.726708889007568
epoch time:  7.729037046432495


-------------------------------- Iteration 2200 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

training time:  0.002278566360473633
evaluation time:  8.05585265159607
epoch time:  8.058152675628662


-------------------------------- Iteration 2400 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

training time:  0.002277851104736328
evaluation time:  7.80818510055542
epoch time:  7.810473442077637


-------------------------------- Iteration 2600 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

training time:  0.002303600311279297
evaluation time:  8.019073724746704
epoch time:  8.021388292312622


-------------------------------- Iteration 2800 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

training time:  0.0023183822631835938
evaluation time:  7.824197769165039
epoch time:  7.826542854309082


-------------------------------- Iteration 3000 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

training time:  0.002298116683959961
evaluation time:  7.845797538757324
epoch time:  7.848106384277344


-------------------------------- Iteration 3200 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

training time:  0.0023059844970703125
evaluation time:  8.12499213218689
epoch time:  8.127310037612915


-------------------------------- Iteration 3400 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

training time:  0.0022957324981689453
evaluation time:  7.7626612186431885
epoch time:  7.764967441558838


-------------------------------- Iteration 3600 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

training time:  0.002274751663208008
evaluation time:  8.14577031135559
epoch time:  8.14805555343628


-------------------------------- Iteration 3800 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

training time:  0.002279043197631836
evaluation time:  7.776433944702148
epoch time:  7.778721570968628


-------------------------------- Iteration 4000 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

training time:  0.002290487289428711
evaluation time:  7.873067617416382
epoch time:  7.875365734100342


-------------------------------- Iteration 4200 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

training time:  0.002285003662109375
evaluation time:  7.650912284851074
epoch time:  7.653205633163452


-------------------------------- Iteration 4400 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

training time:  0.0023076534271240234
evaluation time:  7.786652326583862
epoch time:  7.788976669311523


-------------------------------- Iteration 4600 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

training time:  0.028815031051635742
evaluation time:  7.836002588272095
epoch time:  7.864826917648315


-------------------------------- Iteration 4800 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

training time:  0.002276182174682617
evaluation time:  7.854209661483765
epoch time:  7.856496572494507


-------------------------------- Iteration 5000 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

training time:  0.0022852420806884766
evaluation time:  7.750574827194214
epoch time:  7.752868175506592


-------------------------------- Iteration 5200 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

training time:  0.0022912025451660156
evaluation time:  7.831315279006958
epoch time:  7.833616733551025


-------------------------------- Iteration 5400 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

training time:  0.0023012161254882812
evaluation time:  8.17579960823059
epoch time:  8.178110599517822


-------------------------------- Iteration 5600 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

training time:  0.002299785614013672
evaluation time:  7.910128355026245
epoch time:  7.912444829940796


-------------------------------- Iteration 5800 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

training time:  0.0022945404052734375
evaluation time:  7.640615224838257
epoch time:  7.642928600311279


-------------------------------- Iteration 6000 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

training time:  0.002286672592163086
evaluation time:  7.824565887451172
epoch time:  7.826862096786499


-------------------------------- Iteration 6200 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

training time:  0.002310037612915039
evaluation time:  7.747649431228638
epoch time:  7.7499682903289795


-------------------------------- Iteration 6400 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

training time:  0.002279043197631836
evaluation time:  7.960949659347534
epoch time:  7.963239908218384


-------------------------------- Iteration 6600 -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

training time:  0.002304553985595703
evaluation time:  7.791783332824707
epoch time:  7.7941060066223145


-------------------------------- Training stopped due to early stopping -------------------------------- 
min loss:  0.0956735


-------------------------------- Test Results -------------------------------- 
initial ob: [-0.03265259  0.51487763  0.23688885  0.          0.88        0.13
  0.          0.88000001  0.1       ]
agent_success: 1.0

mean_success_rate:  1.0
Done
