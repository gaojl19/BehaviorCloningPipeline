/var/lib/slurm/slurmd/job3513816/slurm_script: line 9: batch_scripts/MT50_batch/seed.sh: No such file or directory
SLURM_JOBID=3513816
working directory=/viscam/u/jialugao/Imitation-SoftModule
########################
logging outputs to  /viscam/u/jialugao/Imitation-SoftModule/data/Base_bc_reach_push-wall-v1_2640.000124-01-2022_18-42-58
########################
{'expert_policy_file': '../Multi-Task-RL/log/MT50_Single_Task/push-wall-v1/Fixed/238/model/model_pf_best.pth', 'exp_name': 'bc_reach', 'do_dagger': False, 'ep_len': 200, 'gradient_steps': 1, 'n_iter': 10000, 'render_interval': 1, 'eval_interval': 200, 'batch_size': 64, 'eval_batch_size': 32, 'train_batch_size': 32, 'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'video_log_freq': -1, 'scalar_log_freq': 1, 'no_gpu': False, 'which_gpu': 0, 'max_replay_buffer_size': 1000000, 'save_params': False, 'seed': 32, 'worker_nums': 1, 'eval_worker_nums': 1, 'config': 'config/BC.json', 'no_cuda': True, 'random_init': False, 'device': 'cpu', 'id': 'MT50_Single_Task', 'task_name': 'push-wall-v1', 'task_env': 'MT50_task_env', 'cuda': False, 'log_dir': '/viscam/u/jialugao/Imitation-SoftModule/data/Base_bc_reach_push-wall-v1_2640.000124-01-2022_18-42-58', 'agent_class': <class 'agents.bc_agent.MLPAgent'>, 'agent_params': {'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'max_replay_buffer_size': 1000000, 'discrete': False, 'ac_dim': 4, 'ob_dim': 9}}
{'env_name': 'single_task', 'env': {'reward_scale': 1, 'obs_norm': False}, 'meta_env': {'obs_type': 'with_goal', 'random_init': False}, 'replay_buffer': {'size': 1000000.0}, 'net': {'hidden_shapes': [400, 400], 'append_hidden_shapes': [400], 'base_type': <class 'networks.base.MLPBase'>}, 'general_setting': {'discount': 0.99, 'pretrain_epochs': 20, 'num_epochs': 7500, 'epoch_frames': 200, 'max_episode_frames': 200, 'batch_size': 1280, 'min_pool': 10000, 'target_hard_update_period': 1000, 'use_soft_update': True, 'tau': 0.005, 'opt_times': 200, 'eval_episodes': 100, 'train_render': False, 'eval_render': False, 'env': <NormAct<RewardShift<SingleWrapperNone>>>, 'logger': <utils.logger.Logger object at 0x7f6d08ea8b90>, 'device': device(type='cpu')}, 'sac': {'plr': 0.0003, 'qlr': 0.0003, 'reparameterization': True, 'automatic_entropy_tuning': True, 'policy_std_reg_weight': 0, 'policy_mean_reg_weight': 0}}
Loading expert policy from... ../Multi-Task-RL/log/MT50_Single_Task/push-wall-v1/Fixed/238/model/model_pf_best.pth
tensor([[ 0.0443, -0.0454, -0.2330,  ..., -0.0911, -0.0441, -0.0795],
        [ 0.5664, -0.0485, -0.0414,  ...,  0.0080,  0.0303, -0.0395],
        [ 0.4266, -0.2816, -0.6347,  ...,  0.0363,  0.0495,  0.0274],
        ...,
        [ 0.2082, -0.3932, -0.0124,  ...,  0.0875,  0.0384,  0.0431],
        [-0.3596, -0.0904, -0.1145,  ..., -0.0780,  0.0165, -0.0153],
        [ 0.5132,  0.1098, -0.5202,  ..., -0.1230, -0.1158, -0.0838]])
Done restoring expert policy...
<NormAct<RewardShift<AugObs<SawyerReachPushPickPlaceWallEnv instance>>>>


-------------------------------- Iteration 0 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
  0.05        0.8         0.015       0.05        0.8         0.015     ]
expert:[ 0.9851631   0.91224504 -0.9351646  -0.9532353 ]
expert:[ 0.9679423  0.670392  -0.9515596 -0.8767709]
expert:[-0.39871103 -0.92198765 -0.96769446  0.5663917 ]
expert:[-0.58726275 -0.9618107  -0.9655028   0.4925085 ]
expert:[-0.68355674 -0.972297   -0.96603996  0.41337913]
expert:[-0.7420328 -0.9796199 -0.9718118  0.3672009]
expert:[-0.7353876 -0.9789721 -0.9738928  0.253506 ]
expert:[-0.6394178  -0.9624418  -0.96957195 -0.00899632]
expert:[-0.3809138  -0.8493069  -0.95574963 -0.6187379 ]
expert:[ 0.76783204  0.13179052 -0.92291164 -0.9375822 ]
expert:[ 0.9501849   0.56986845 -0.924276   -0.96432704]
expert:[ 0.941608    0.46727672 -0.8828647  -0.96172464]
expert:[ 0.779474    0.16619468 -0.8089105  -0.96771634]
expert:[-0.16824754 -0.3390239  -0.8449862  -0.872105  ]
expert:[-0.743334   -0.52378726 -0.9101533  -0.1107856 ]
expert:[-0.6329289  -0.675462   -0.93864304  0.7792304 ]
expert:[-0.35873565 -0.5284826  -0.93510836  0.93060225]
expert:[-0.24613272  0.26209712 -0.9124157   0.9043467 ]
expert:[-0.26304498  0.73789597 -0.8875507   0.8611193 ]
expert:[-0.26265323  0.8288054  -0.87030077  0.8279407 ]
expert:[-0.25980702  0.85626304 -0.8616969   0.79865104]
expert:[-0.25171843  0.8731541  -0.8522696   0.7575449 ]
expert:[-0.23186933  0.89360625 -0.84490806  0.7002741 ]
expert:[-0.17513834  0.8921298  -0.8442155   0.627866  ]
expert:[-0.1527603   0.88242877 -0.8528365   0.53082883]
expert:[-0.1943113   0.83422077 -0.89537287  0.31381285]
expert:[ 0.23312595  0.67014176 -0.9145229   0.17503706]
expert:[ 0.71535677  0.39235732 -0.92429745  0.15137377]
expert:[ 0.78648657  0.28261936 -0.9275619   0.04240859]
expert:[ 0.77267987  0.2536596  -0.9234701  -0.01901381]
expert:[ 0.66992116  0.29304093 -0.9265935  -0.05049627]
expert:[ 0.1864946   0.39708874 -0.93681186 -0.10604896]
expert:[-0.52058303  0.5474015  -0.9477915  -0.22433886]
expert:[-0.65845305  0.65439737 -0.9548294  -0.44401067]
expert:[-0.5763623   0.67305106 -0.9377338  -0.6830572 ]
expert:[-0.49900094  0.5655933  -0.90927184 -0.7874667 ]
expert:[-0.44412354  0.3334573  -0.88419634 -0.85725325]
expert:[-0.33777308  0.18429363 -0.8781571  -0.8517615 ]
expert:[-0.1344124   0.1795519  -0.84194046 -0.7887271 ]
expert:[-0.03980073  0.5923521  -0.8810828  -0.8278127 ]
expert:[-0.00608368  0.8860257  -0.8665909  -0.7394485 ]
expert:[-0.15362532  0.8919742  -0.62468475 -0.64157933]
expert:[-0.52131027  0.9036606  -0.30257842 -0.61937296]
expert:[-0.75744545  0.8946148  -0.11062606 -0.65014815]
expert:[-0.74455094  0.66559386 -0.02470448 -0.70635617]
expert:[-0.74556714  0.74159515 -0.05436311 -0.67696935]
expert:[-0.6932227   0.95945233 -0.05266077 -0.30015805]
expert:[-0.4827291   0.9511954  -0.22945696 -0.12493781]
expert:[-0.34798193  0.89680403 -0.32242936 -0.09722379]
expert:[-0.18869682  0.73191684 -0.41657746 -0.0945457 ]
expert:[-0.14191012  0.74319667 -0.48195028 -0.06360335]
expert:[-0.10560657  0.7746193  -0.52833265 -0.01962808]
expert:[-0.09509657  0.7941491  -0.5364462   0.0087768 ]
expert:[-0.11240293  0.8216669  -0.5553194   0.03171879]
expert:[-0.06828596  0.8300455  -0.5799612   0.03789989]
expert:[ 0.12077901  0.8177385  -0.5057323   0.00810302]
expert:[ 0.22716701  0.77557516 -0.4344573  -0.0590333 ]
expert:[ 0.27497324  0.72731674 -0.39743543 -0.11065516]
expert:[ 0.30671138  0.6647576  -0.38949445 -0.15525061]
expert:[ 0.3487329   0.5778253  -0.42081025 -0.19281855]
expert:[ 0.38517818  0.45625284 -0.5346992  -0.28181848]
expert:[ 0.5459557   0.31039196 -0.6408058  -0.4037042 ]
expert:[ 0.7412962   0.07368653 -0.71670365 -0.526772  ]
expert:[ 0.87648976 -0.08923738 -0.83164376 -0.6189803 ]
expert:[ 0.95233506 -0.32242614 -0.88576376 -0.66002   ]
expert:[ 0.9703166  -0.46313694 -0.9312483  -0.7061689 ]
expert:[ 0.98056906 -0.47564164 -0.9681822  -0.71930295]
expert:[ 0.9898146  -0.5209218  -0.98483586 -0.7235701 ]
expert:[ 0.9947411  -0.59605855 -0.99288    -0.71719867]
expert:[ 0.9971426 -0.6473049 -0.9967489 -0.8849778]
expert:[ 0.99761474 -0.6909408  -0.9983129  -0.94628066]
expert:[ 0.99574685 -0.6450772  -0.99866134 -0.9425766 ]
expert:[ 0.9925419  -0.5946998  -0.9977141  -0.94108605]
expert:[ 0.960659   -0.42389068 -0.99630624 -0.9768887 ]
expert:[ 0.8669146  -0.11085282 -0.99006766 -0.9762495 ]
expert:[ 6.6205955e-01  2.3884699e-04 -9.6767086e-01 -9.0441066e-01]
expert:[ 0.4566371   0.03602764 -0.8874613  -0.7678062 ]
expert:[ 0.56510943  0.1310544  -0.7682407  -0.6824183 ]
expert:[ 0.7258062   0.04197678 -0.5920874  -0.75214785]
expert:[ 0.71326697  0.02050339 -0.46551633 -0.6994693 ]
expert:[ 0.5735477   0.11039999 -0.3190168  -0.34426576]
expert:[ 0.31227145  0.08693696 -0.13464727 -0.05579533]
expert:[ 0.15350871  0.02221919 -0.0458423  -0.20690037]
expert:[ 0.14175206 -0.00697548 -0.07595403 -0.24740553]
expert:[ 0.19917984 -0.08580236 -0.11885245 -0.23468472]
expert:[ 0.2742132  -0.14513811 -0.1374725  -0.18846829]
expert:[ 0.3083778  -0.17288609 -0.16384895 -0.13208821]
expert:[ 0.3280025  -0.17192134 -0.18376096 -0.11574387]
expert:[ 0.30139843 -0.19589736 -0.18130405 -0.11485841]
expert:[ 0.27002323 -0.2071791  -0.16477388 -0.1171722 ]
expert:[ 0.24025922 -0.21622229 -0.16127944 -0.13635662]
expert:[ 0.20840898 -0.2263668  -0.15810028 -0.16426498]
expert:[ 0.17791277 -0.23709053 -0.1510091  -0.19879024]
expert:[ 0.15670657 -0.24256924 -0.14574978 -0.22147705]
expert:[ 0.15375488 -0.23980841 -0.14491859 -0.2203374 ]
expert:[ 0.16951914 -0.2302495  -0.14777683 -0.19646913]
expert:[ 0.19910406 -0.22149484 -0.15361455 -0.16913798]
expert:[ 0.23204473 -0.21556233 -0.15724897 -0.14674251]
expert:[ 0.25467512 -0.21284536 -0.16235928 -0.1293398 ]
expert:[ 0.26856038 -0.21530055 -0.16528729 -0.12506914]
expert:[ 0.2631541  -0.22256783 -0.16536497 -0.13707715]
expert:[ 0.23227252 -0.2327981  -0.16286075 -0.16280958]
expert:[ 0.18772085 -0.24099381 -0.15772319 -0.19012295]
expert:[ 0.14737456 -0.24635267 -0.14557919 -0.2189116 ]
expert:[ 0.12659043 -0.24610673 -0.13971938 -0.22906065]
expert:[ 0.13170621 -0.24053098 -0.14063877 -0.21771581]
expert:[ 0.16068129 -0.23172662 -0.14825383 -0.18862282]
expert:[ 0.20546867 -0.22731417 -0.15675092 -0.1660706 ]
expert:[ 0.23195292 -0.22482078 -0.16644622 -0.14548777]
expert:[ 0.2522347  -0.22476013 -0.17211998 -0.13180918]
expert:[ 0.25510854 -0.22840968 -0.17271085 -0.1331572 ]
expert:[ 0.2395016  -0.23473787 -0.16836104 -0.14898318]
expert:[ 0.20607692 -0.24251966 -0.16224134 -0.17429061]
expert:[ 0.16232266 -0.24829257 -0.15482694 -0.19844176]
expert:[ 0.13308428 -0.25234014 -0.14749879 -0.22006212]
expert:[ 0.12682384 -0.25063774 -0.14605245 -0.22118023]
expert:[ 0.14576636 -0.24378109 -0.15110214 -0.20090018]
expert:[ 0.18346006 -0.23743005 -0.15800177 -0.17624114]
expert:[ 0.19817364 -0.23616652 -0.16982272 -0.15945537]
expert:[ 0.21939057 -0.23365456 -0.17711984 -0.13975301]
expert:[ 0.2302803  -0.23486549 -0.18004413 -0.13267979]
expert:[ 0.22491735 -0.23979768 -0.17824781 -0.1410007 ]
expert:[ 0.2043645  -0.24705437 -0.17257181 -0.16187471]
expert:[ 0.18424253 -0.25345156 -0.16342387 -0.18596938]
expert:[ 0.14579324 -0.2572274  -0.1568002  -0.20692672]
expert:[ 0.12555528 -0.25872436 -0.15175737 -0.22015731]
expert:[ 0.13000382 -0.25428703 -0.15289141 -0.21122657]
expert:[ 0.15717362 -0.24711162 -0.15836355 -0.18651323]
expert:[ 0.17071658 -0.2466978  -0.16949758 -0.1738241 ]
expert:[ 0.18508407 -0.24398966 -0.18013406 -0.15299132]
expert:[ 0.2028763  -0.24335065 -0.1858819  -0.13864005]
expert:[ 0.20752929 -0.24654934 -0.18684274 -0.13871026]
expert:[ 0.19507071 -0.25288346 -0.1831718  -0.15352799]
expert:[ 0.17817019 -0.25990131 -0.17472072 -0.176782  ]
expert:[ 0.15996854 -0.2630263  -0.16451117 -0.19471611]
expert:[ 0.12915063 -0.26601714 -0.1588164  -0.21365783]
expert:[ 0.11966853 -0.26467273 -0.15655102 -0.21661526]
expert:[ 0.13568985 -0.258463   -0.16053863 -0.1982786 ]
expert:[ 0.1450378  -0.2562644  -0.16936347 -0.18399829]
expert:[ 0.16014563 -0.2547323  -0.18018086 -0.16640402]
expert:[ 0.17434241 -0.2522385  -0.18781538 -0.14561507]
expert:[ 0.18663651 -0.25094387 -0.19089201 -0.1350474 ]
expert:[ 0.1821737  -0.25788087 -0.19081129 -0.14506821]
expert:[ 0.16871096 -0.26565155 -0.18604186 -0.16668561]
expert:[ 0.15192941 -0.27221444 -0.17639017 -0.19106694]
expert:[ 0.13771795 -0.27383155 -0.16696337 -0.20229481]
expert:[ 0.11512907 -0.27547377 -0.16208595 -0.21540749]
expert:[ 0.11867642 -0.27076697 -0.16260509 -0.20819971]
expert:[ 0.12442483 -0.26558286 -0.16988222 -0.19435568]
expert:[ 0.13786682 -0.26383433 -0.17808431 -0.1801096 ]
expert_success: 1.0
path_length: 150



-------------------------------- Iteration 0 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
  0.05        0.8         0.015       0.05        0.8         0.015     ]
agent_success: 0

training time:  0.2077639102935791
evaluation time:  11.704970359802246
epoch time:  11.912767887115479


-------------------------------- Iteration 200 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
  0.05        0.8         0.015       0.05        0.8         0.015     ]
agent_success: 0

training time:  0.001791238784790039
evaluation time:  12.128959894180298
epoch time:  12.130794048309326


-------------------------------- Iteration 400 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
  0.05        0.8         0.015       0.05        0.8         0.015     ]
agent_success: 0

training time:  0.0018000602722167969
evaluation time:  12.177095651626587
epoch time:  12.178929805755615


-------------------------------- Training stopped due to early stopping -------------------------------- 
min loss:  0.09719099


-------------------------------- Test Results -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
  0.05        0.8         0.015       0.05        0.8         0.015     ]
agent_success: 0

mean_success_rate:  0.0
Done
