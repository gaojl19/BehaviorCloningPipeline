/var/lib/slurm/slurmd/job3513853/slurm_script: line 9: batch_scripts/MT50_batch/seed.sh: No such file or directory
SLURM_JOBID=3513853
working directory=/viscam/u/jialugao/Imitation-SoftModule
########################
logging outputs to  /viscam/u/jialugao/Imitation-SoftModule/data/Base_bc_reach_plate-slide-back-v1_2640.000124-01-2022_18-56-05
########################
{'expert_policy_file': '../Multi-Task-RL/log/MT50_Single_Task/plate-slide-back-v1/Fixed/238/model/model_pf_best.pth', 'exp_name': 'bc_reach', 'do_dagger': False, 'ep_len': 200, 'gradient_steps': 1, 'n_iter': 10000, 'render_interval': 1, 'eval_interval': 200, 'batch_size': 64, 'eval_batch_size': 32, 'train_batch_size': 32, 'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'video_log_freq': -1, 'scalar_log_freq': 1, 'no_gpu': False, 'which_gpu': 0, 'max_replay_buffer_size': 1000000, 'save_params': False, 'seed': 32, 'worker_nums': 1, 'eval_worker_nums': 1, 'config': 'config/BC.json', 'no_cuda': True, 'random_init': False, 'device': 'cpu', 'id': 'MT50_Single_Task', 'task_name': 'plate-slide-back-v1', 'task_env': 'MT50_task_env', 'cuda': False, 'log_dir': '/viscam/u/jialugao/Imitation-SoftModule/data/Base_bc_reach_plate-slide-back-v1_2640.000124-01-2022_18-56-05', 'agent_class': <class 'agents.bc_agent.MLPAgent'>, 'agent_params': {'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'max_replay_buffer_size': 1000000, 'discrete': False, 'ac_dim': 4, 'ob_dim': 9}}
{'env_name': 'single_task', 'env': {'reward_scale': 1, 'obs_norm': False}, 'meta_env': {'obs_type': 'with_goal', 'random_init': False}, 'replay_buffer': {'size': 1000000.0}, 'net': {'hidden_shapes': [400, 400], 'append_hidden_shapes': [400], 'base_type': <class 'networks.base.MLPBase'>}, 'general_setting': {'discount': 0.99, 'pretrain_epochs': 20, 'num_epochs': 7500, 'epoch_frames': 200, 'max_episode_frames': 200, 'batch_size': 1280, 'min_pool': 10000, 'target_hard_update_period': 1000, 'use_soft_update': True, 'tau': 0.005, 'opt_times': 200, 'eval_episodes': 100, 'train_render': False, 'eval_render': False, 'env': <NormAct<RewardShift<SingleWrapperNone>>>, 'logger': <utils.logger.Logger object at 0x7f9de9afcf10>, 'device': device(type='cpu')}, 'sac': {'plr': 0.0003, 'qlr': 0.0003, 'reparameterization': True, 'automatic_entropy_tuning': True, 'policy_std_reg_weight': 0, 'policy_mean_reg_weight': 0}}
Loading expert policy from... ../Multi-Task-RL/log/MT50_Single_Task/plate-slide-back-v1/Fixed/238/model/model_pf_best.pth
tensor([[-0.0091, -0.0206, -0.0588,  ..., -0.0365, -0.0244, -0.0685],
        [ 0.0494, -0.0407, -0.0450,  ...,  0.0090, -0.0126, -0.0809],
        [-0.0371, -0.0888, -0.0473,  ..., -0.0016, -0.0337, -0.0542],
        ...,
        [ 1.2710, -0.1710,  0.2019,  ...,  0.0400, -0.0493, -0.0492],
        [-0.4082, -0.0702, -0.6497,  ..., -0.0461,  0.1019,  0.0772],
        [ 0.0231, -0.0194, -0.0860,  ..., -0.0211, -0.0692, -0.0368]])
Done restoring expert policy...
<NormAct<RewardShift<AugObs<SawyerPlateSlideBackEnv instance>>>>


-------------------------------- Iteration 0 -------------------------------- 
initial ob: [-0.03264849  0.51488124  0.2368859   0.          0.8         0.015
  0.          0.6         0.015       0.          0.6         0.015     ]
expert:[-0.12096916  0.7840984  -0.23868099 -0.79277664]
expert:[-0.8839768  0.9456229 -0.8707028 -0.8994679]
expert:[-0.94642204  0.9587954  -0.94314396 -0.8613095 ]
expert:[-0.92295575  0.95006996 -0.9442573  -0.744123  ]
expert:[-0.8602483   0.93256855 -0.93490046 -0.5847633 ]
expert:[-0.73817134  0.88436055 -0.9186607  -0.4673886 ]
expert:[ 0.12202626  0.7885656  -0.8945581  -0.21347804]
expert:[ 0.94525826  0.9598123  -0.9311762  -0.12758057]
expert:[ 0.97946     0.98245    -0.9539837  -0.41053197]
expert:[ 0.97934073  0.98689204 -0.97664374 -0.8247016 ]
expert:[ 0.9563461  0.9901138 -0.9793923 -0.9193549]
expert:[ 0.45021823  0.9785757  -0.95760316 -0.7574055 ]
expert:[-0.57799983  0.9158123  -0.8875263  -0.1809144 ]
expert:[-0.41874483  0.8321738  -0.7296199  -0.0576077 ]
expert:[ 0.7420054   0.88255215  0.03004688 -0.1795248 ]
expert:[ 0.95502263  0.9485991   0.22953913 -0.5246596 ]
expert:[ 0.6215699   0.9223649  -0.35668936 -0.47411734]
expert:[-0.91040546 -0.9376945  -0.98483765  0.7151403 ]
expert:[-0.9708431 -0.9935552 -0.9950345  0.7952834]
expert:[-0.97216845 -0.9965021  -0.99540013  0.8625794 ]
expert:[-0.9584995 -0.9978411 -0.9964361  0.9342774]
expert:[-0.17733023 -0.9976666  -0.99762946  0.970324  ]
expert:[ 0.07449852 -0.99612933 -0.9962434   0.963536  ]
expert:[ 0.15553541 -0.99534845 -0.99559087  0.9383386 ]
expert:[ 0.16850916 -0.99487644 -0.99558794  0.92598253]
expert:[ 0.20556921 -0.99341285 -0.9956856   0.89265096]
expert:[ 0.2587222  -0.9907584  -0.99563813  0.8406932 ]
expert:[ 0.28369135 -0.9875912  -0.99550456  0.8071493 ]
expert:[ 0.24935247 -0.9863374  -0.9955053   0.8318212 ]
expert:[ 0.14844397 -0.9861094  -0.9954801   0.8857979 ]
expert:[ 0.04593511 -0.98514986 -0.99534875  0.9229408 ]
expert:[-0.01293836 -0.98292106 -0.9953461   0.9361454 ]
expert:[-0.08040611 -0.97931457 -0.99531543  0.9449376 ]
expert:[-0.13521934 -0.97484857 -0.99554807  0.9474667 ]
expert:[-0.18834738 -0.96906006 -0.9957942   0.9470465 ]
expert:[-0.1292474  -0.91097325 -0.99343497  0.91395736]
expert:[-0.06944659 -0.7369217  -0.986744    0.8562167 ]
expert:[-0.03611458 -0.49896997 -0.97478473  0.8085168 ]
expert:[ 0.00306517 -0.326649   -0.9575219   0.7559103 ]
expert:[ 0.05207762 -0.23555693 -0.9389112   0.74251306]
expert:[ 0.07842024 -0.1482491  -0.91642636  0.74238235]
expert:[ 0.08062019 -0.09524264 -0.90244055  0.7600863 ]
expert:[ 0.06211821 -0.05824573 -0.9001137   0.78677034]
expert:[ 0.0266684  -0.02729653 -0.904926    0.8121693 ]
expert:[ 0.00542479 -0.00367446 -0.90902174  0.8277945 ]
expert:[-0.00907347  0.00916163 -0.91266763  0.83759797]
expert:[-0.01864091  0.01929333 -0.9153813   0.84382033]
expert:[-0.02328921  0.0260761  -0.9165556   0.84735847]
expert:[-0.0239663   0.02897828 -0.9163314   0.8485603 ]
expert:[-0.02184769  0.0299612  -0.9153656   0.84856176]
expert:[-0.01786741  0.02907657 -0.9135467   0.84754264]
expert:[-0.01222942  0.02768217 -0.9112704   0.84554166]
expert:[-0.006314    0.02638315 -0.90893036  0.8431291 ]
expert:[-0.00108718  0.02394371 -0.90677243  0.84068286]
expert:[ 0.00347507  0.02011311 -0.9048885   0.83802813]
expert:[ 0.00679871  0.01687947 -0.9036523   0.83593005]
expert:[ 0.00872162  0.014396   -0.9031384   0.8345136 ]
expert:[ 0.00933016  0.0126862  -0.9033004   0.83377326]
expert:[ 0.00880586  0.01166779 -0.90402544  0.8336309 ]
expert:[ 0.0074329   0.01119397 -0.9051497   0.83394635]
expert:[ 0.0053262   0.01141972 -0.90647864  0.8345689 ]
expert:[ 0.00299633  0.01200857 -0.9078255   0.8352849 ]
expert:[ 8.1021694e-04  1.2430356e-02 -9.0909994e-01  8.3596575e-01]
expert:[-0.00122266  0.0123642  -0.91020983  0.836553  ]
expert:[-0.00265325  0.01203089 -0.91104203  0.8368735 ]
expert:[-0.00339398  0.01144648 -0.9115773   0.8368943 ]
expert:[-0.00354234  0.01062464 -0.9118465   0.83665305]
expert:[-0.00317366  0.00961232 -0.91188914  0.8361872 ]
expert:[-0.00237738  0.00848222 -0.9117562   0.83554506]
expert:[-0.00146272  0.00720524 -0.91154915  0.83484054]
expert:[-5.2442023e-04  5.9723444e-03 -9.1132003e-01  8.3413965e-01]
expert:[ 3.2414123e-04  4.8472499e-03 -9.1111946e-01  8.3349961e-01]
expert:[ 0.00095568  0.00387458 -0.9109928   0.83297855]
expert:[ 0.0013491   0.00308468 -0.91095334  0.832593  ]
expert:[ 0.00147388  0.00247743 -0.9110089   0.832355  ]
expert:[ 0.00138928  0.00204077 -0.9111403   0.8322406 ]
expert:[ 0.00112806  0.00174323 -0.91133034  0.8322296 ]
expert:[ 7.5782451e-04  1.5480208e-03 -9.1155201e-01  8.3228815e-01]
expert:[ 3.6252660e-04  1.4189472e-03 -9.1177464e-01  8.3237618e-01]
expert:[-1.1850148e-05  1.3216428e-03 -9.1197819e-01  8.3246768e-01]
expert:[-3.0075386e-04  1.2306863e-03 -9.1214120e-01  8.3253270e-01]
expert:[-4.9187610e-04  1.1276300e-03 -9.1225731e-01  8.3256185e-01]
expert:[-5.7427952e-04  1.0044273e-03 -9.1232413e-01  8.3254862e-01]
expert:[-5.6071946e-04  8.6155511e-04 -9.1234672e-01  8.3249754e-01]
expert:[-4.7956777e-04  7.0384133e-04 -9.1233617e-01  8.3241963e-01]
expert:[-3.4056976e-04  5.4326648e-04 -9.1229999e-01  8.3232170e-01]
expert:[-1.8744543e-04  3.8799641e-04 -9.1225368e-01  8.3222085e-01]
expert:[-2.0641834e-05  2.5072694e-04 -9.1220230e-01  8.3212060e-01]
expert:[ 1.1555478e-04  1.3628602e-04 -9.1215974e-01  8.3203810e-01]
expert:[ 2.0981953e-04  5.0485134e-05 -9.1213155e-01  8.3197886e-01]
expert:[ 2.5088713e-04 -6.0796738e-06 -9.1212130e-01  8.3194697e-01]
expert:[ 2.5246665e-04 -3.5762787e-05 -9.1212678e-01  8.3193660e-01]
expert:[ 2.3643300e-04 -4.1633844e-05 -9.1214091e-01  8.3193934e-01]
expert:[ 1.7501041e-04 -3.2275915e-05 -9.1216838e-01  8.3196265e-01]
expert:[ 1.18058175e-04 -1.23083591e-05 -9.12196398e-01  8.31987321e-01]
expert:[ 4.6890229e-05  1.0341406e-05 -9.1222763e-01  8.3201802e-01]
expert:[-3.7141144e-06  3.2335520e-05 -9.1225207e-01  8.3204132e-01]
expert:[-5.1219016e-05  4.9084425e-05 -9.1227293e-01  8.3206224e-01]
expert:[-7.947162e-05  5.865097e-05 -9.122865e-01  8.320743e-01]
expert:[-9.1720372e-05  6.1154366e-05 -9.1229266e-01  8.3207893e-01]
expert:[-7.8786165e-05  5.6833029e-05 -9.1229051e-01  8.3207279e-01]
expert:[-7.0173293e-05  4.6819448e-05 -9.1228706e-01  8.3206683e-01]
expert:[-3.3129007e-05  3.4987926e-05 -9.1227609e-01  8.3204997e-01]
expert:[-1.4789402e-06  2.1845102e-05 -9.1226578e-01  8.3203489e-01]
expert:[ 2.111122e-05  8.791685e-06 -9.122579e-01  8.320229e-01]
expert:[ 3.8843602e-05 -1.1920929e-07 -9.1225213e-01  8.3201391e-01]
expert:[ 4.6443194e-05 -5.3942204e-06 -9.1224957e-01  8.3200961e-01]
expert:[ 7.0404261e-05 -6.1988831e-06 -9.1224504e-01  8.3200043e-01]
expert:[ 6.5427274e-05 -4.6789646e-06 -9.1224813e-01  8.3200234e-01]
expert:[ 5.1837415e-05 -5.3644180e-07 -9.1225433e-01  8.3200812e-01]
expert:[ 5.1390380e-05  5.8412552e-06 -9.1225851e-01  8.3200955e-01]
expert:[ 2.9843301e-05  1.2218952e-05 -9.1226745e-01  8.3201873e-01]
expert:[ 4.4815242e-06  1.7911196e-05 -9.1227716e-01  8.3202893e-01]
expert:[-5.8487058e-07  2.4050474e-05 -9.1228229e-01  8.3203208e-01]
expert:[-7.5586140e-06  2.6673079e-05 -9.1228658e-01  8.3203489e-01]
expert:[-1.8347055e-05  2.7507544e-05 -9.1229129e-01  8.3203864e-01]
expert:[-8.8103116e-06  2.7418137e-05 -9.1229039e-01  8.3203489e-01]
expert:[ 2.3953617e-06  2.5361776e-05 -9.1228890e-01  8.3203006e-01]
expert:[ 1.8011779e-05  2.2858381e-05 -9.1228604e-01  8.3202338e-01]
expert:[ 2.3495406e-05  2.0593405e-05 -9.1228563e-01  8.3202052e-01]
expert:[ 3.1303614e-05  1.7970800e-05 -9.1228509e-01  8.3201671e-01]
expert:[ 2.3882836e-05  1.6927719e-05 -9.1228837e-01  8.3201867e-01]
expert:[ 3.4522265e-05  1.7225742e-05 -9.1228819e-01  8.3201456e-01]
expert:[ 2.3256987e-05  1.7613173e-05 -9.1229296e-01  8.3201844e-01]
expert:[ 7.2233379e-06  1.7791986e-05 -9.1229892e-01  8.3202386e-01]
expert:[ 4.6007335e-06  1.9460917e-05 -9.1230208e-01  8.3202475e-01]
expert:[ 1.0024756e-05  2.0653009e-05 -9.1230321e-01  8.3202291e-01]
expert:[ 3.9152801e-06  1.9520521e-05 -9.1230655e-01  8.3202428e-01]
expert:[ 1.4167279e-05  1.9848347e-05 -9.1230583e-01  8.3202040e-01]
expert:[ 2.2184104e-05  1.9192696e-05 -9.1230583e-01  8.3201700e-01]
expert:[ 1.27367675e-05  1.82092190e-05 -9.12309468e-01  8.32019806e-01]
expert:[ 1.8250197e-05  1.8388033e-05 -9.1231006e-01  8.3201736e-01]
expert:[ 2.1498650e-05  1.8209219e-05 -9.1231102e-01  8.3201593e-01]
expert:[ 9.2498958e-06  1.7255545e-05 -9.1231579e-01  8.3201963e-01]
expert:[ 6.0014427e-06  1.7195940e-05 -9.1231811e-01  8.3202046e-01]
expert:[ 1.0322779e-05  1.7464161e-05 -9.1231924e-01  8.3201861e-01]
expert:[ 8.9220703e-06  1.6838312e-05 -9.1232091e-01  8.3201861e-01]
expert:[ 1.4465302e-05  1.7195940e-05 -9.1232133e-01  8.3201629e-01]
expert:[ 1.3630837e-05  1.5735626e-05 -9.1232300e-01  8.3201593e-01]
expert:[ 2.2184104e-05  1.5884638e-05 -9.1232282e-01  8.3201253e-01]
expert:[ 2.0842999e-05  1.5765429e-05 -9.1232479e-01  8.3201253e-01]
expert:[ 3.8515776e-05  1.7374754e-05 -9.1232288e-01  8.3200628e-01]
expert:[ 4.4714659e-05  1.8864870e-05 -9.1232371e-01  8.3200413e-01]
expert:[ 3.9916486e-05  2.0772219e-05 -9.1232753e-01  8.3200592e-01]
expert:[ 3.5833567e-05  2.2828579e-05 -9.1233164e-01  8.3200753e-01]
expert:[ 2.6684254e-05  2.6196241e-05 -9.1233712e-01  8.3201134e-01]
expert:[ 2.1647662e-05  2.8580427e-05 -9.1234177e-01  8.3201337e-01]
expert:[ 1.3452023e-05  3.1322241e-05 -9.1234708e-01  8.3201641e-01]
expert:[ 1.0799617e-05  3.2365322e-05 -9.1235071e-01  8.3201718e-01]
expert:[ 6.5378845e-06  3.3408403e-05 -9.1235441e-01  8.3201861e-01]
expert_success: 1.0
path_length: 150



-------------------------------- Iteration 0 -------------------------------- 
initial ob: [-0.03264849  0.51488124  0.2368859   0.          0.8         0.015
  0.          0.6         0.015       0.          0.6         0.015     ]
agent_success: 0

training time:  0.15813589096069336
evaluation time:  6.839492082595825
epoch time:  6.997656583786011


-------------------------------- Iteration 200 -------------------------------- 
initial ob: [-0.03264849  0.51488124  0.2368859   0.          0.8         0.015
  0.          0.6         0.015       0.          0.6         0.015     ]
agent_success: 0

training time:  0.002346515655517578
evaluation time:  7.24299955368042
epoch time:  7.24537467956543


-------------------------------- Iteration 400 -------------------------------- 
initial ob: [-0.03264849  0.51488124  0.2368859   0.          0.8         0.015
  0.          0.6         0.015       0.          0.6         0.015     ]
agent_success: 0

training time:  0.002572774887084961
evaluation time:  7.398602247238159
epoch time:  7.4012064933776855


-------------------------------- Iteration 600 -------------------------------- 
initial ob: [-0.03264849  0.51488124  0.2368859   0.          0.8         0.015
  0.          0.6         0.015       0.          0.6         0.015     ]
agent_success: 0

training time:  0.0024559497833251953
evaluation time:  7.334632396697998
epoch time:  7.337118148803711


-------------------------------- Iteration 800 -------------------------------- 
initial ob: [-0.03264849  0.51488124  0.2368859   0.          0.8         0.015
  0.          0.6         0.015       0.          0.6         0.015     ]
agent_success: 0

training time:  0.0024771690368652344
evaluation time:  7.30162501335144
epoch time:  7.304143905639648


-------------------------------- Iteration 1000 -------------------------------- 
initial ob: [-0.03264849  0.51488124  0.2368859   0.          0.8         0.015
  0.          0.6         0.015       0.          0.6         0.015     ]
agent_success: 0

training time:  0.0025060176849365234
evaluation time:  7.282113313674927
epoch time:  7.284663200378418


-------------------------------- Training stopped due to early stopping -------------------------------- 
min loss:  0.0034630955


-------------------------------- Test Results -------------------------------- 
initial ob: [-0.03264849  0.51488124  0.2368859   0.          0.8         0.015
  0.          0.6         0.015       0.          0.6         0.015     ]
agent_success: 0

mean_success_rate:  0.0
Done
