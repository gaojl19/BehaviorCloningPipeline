/var/lib/slurm/slurmd/job3513872/slurm_script: line 9: batch_scripts/MT50_batch/seed.sh: No such file or directory
SLURM_JOBID=3513872
working directory=/viscam/u/jialugao/Imitation-SoftModule
########################
logging outputs to  /viscam/u/jialugao/Imitation-SoftModule/data/Base_bc_reach_shelf-place-v1_2640.000124-01-2022_18-56-22
########################
{'expert_policy_file': '../Multi-Task-RL/log/MT50_Single_Task/shelf-place-v1/Fixed/238/model/model_pf_best.pth', 'exp_name': 'bc_reach', 'do_dagger': False, 'ep_len': 200, 'gradient_steps': 1, 'n_iter': 10000, 'render_interval': 1, 'eval_interval': 200, 'batch_size': 64, 'eval_batch_size': 32, 'train_batch_size': 32, 'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'video_log_freq': -1, 'scalar_log_freq': 1, 'no_gpu': False, 'which_gpu': 0, 'max_replay_buffer_size': 1000000, 'save_params': False, 'seed': 32, 'worker_nums': 1, 'eval_worker_nums': 1, 'config': 'config/BC.json', 'no_cuda': True, 'random_init': False, 'device': 'cpu', 'id': 'MT50_Single_Task', 'task_name': 'shelf-place-v1', 'task_env': 'MT50_task_env', 'cuda': False, 'log_dir': '/viscam/u/jialugao/Imitation-SoftModule/data/Base_bc_reach_shelf-place-v1_2640.000124-01-2022_18-56-22', 'agent_class': <class 'agents.bc_agent.MLPAgent'>, 'agent_params': {'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'max_replay_buffer_size': 1000000, 'discrete': False, 'ac_dim': 4, 'ob_dim': 9}}
{'env_name': 'single_task', 'env': {'reward_scale': 1, 'obs_norm': False}, 'meta_env': {'obs_type': 'with_goal', 'random_init': False}, 'replay_buffer': {'size': 1000000.0}, 'net': {'hidden_shapes': [400, 400], 'append_hidden_shapes': [400], 'base_type': <class 'networks.base.MLPBase'>}, 'general_setting': {'discount': 0.99, 'pretrain_epochs': 20, 'num_epochs': 7500, 'epoch_frames': 200, 'max_episode_frames': 200, 'batch_size': 1280, 'min_pool': 10000, 'target_hard_update_period': 1000, 'use_soft_update': True, 'tau': 0.005, 'opt_times': 200, 'eval_episodes': 100, 'train_render': False, 'eval_render': False, 'env': <NormAct<RewardShift<SingleWrapperNone>>>, 'logger': <utils.logger.Logger object at 0x7f18596f3c50>, 'device': device(type='cpu')}, 'sac': {'plr': 0.0003, 'qlr': 0.0003, 'reparameterization': True, 'automatic_entropy_tuning': True, 'policy_std_reg_weight': 0, 'policy_mean_reg_weight': 0}}
Loading expert policy from... ../Multi-Task-RL/log/MT50_Single_Task/shelf-place-v1/Fixed/238/model/model_pf_best.pth
tensor([[-7.0801e-01,  6.2124e-04, -1.9869e-01,  ..., -3.6539e-02,
         -2.8297e-02, -7.4241e-02],
        [ 5.2554e-01, -2.4877e-02, -5.6422e-01,  ...,  9.0029e-03,
          5.9366e-03, -6.3733e-02],
        [ 1.1745e-02, -8.6513e-02, -6.4239e-02,  ..., -1.5992e-03,
         -3.4977e-02, -5.6778e-02],
        ...,
        [ 8.4229e-02, -7.3450e-02, -7.7946e-03,  ...,  4.0015e-02,
         -4.2335e-02, -3.7576e-02],
        [-9.0240e-01, -1.7500e-01, -3.3102e-01,  ..., -4.6097e-02,
          6.0391e-02,  3.4805e-02],
        [ 5.3314e-01,  6.2485e-02, -5.8524e-01,  ..., -2.1146e-02,
         -6.4310e-02, -3.2409e-02]])
Done restoring expert policy...
<NormAct<RewardShift<AugObs<SawyerShelfPlaceEnv instance>>>>


-------------------------------- Iteration 0 -------------------------------- 
initial ob: [-0.03265248  0.51488137  0.23688703  0.          0.6         0.01999588
  0.          0.85000002  0.301       0.          0.85000002  0.301     ]
expert:[ 0.9086461   0.95959514 -0.96822894 -0.8508721 ]
expert:[ 0.9193052   0.96542585 -0.9737034  -0.83974445]
expert:[ 0.92426467  0.9703721  -0.9792562  -0.83354604]
expert:[ 0.9029212   0.9705952  -0.97959465 -0.7621005 ]
expert:[-0.7096521  -0.96362585 -0.9828117   0.9712889 ]
expert:[-0.866176   -0.96378046 -0.9816854   0.9692507 ]
expert:[-0.90920174 -0.9678847  -0.97960657  0.970932  ]
expert:[-0.92389685 -0.96854943 -0.9782303   0.9721445 ]
expert:[-0.92667925 -0.96769094 -0.9773772   0.97302306]
expert:[-0.9207636  -0.9659453  -0.9773643   0.97428167]
expert:[-0.896593   -0.9628023  -0.9770354   0.97465956]
expert:[-0.7071991  -0.95556545 -0.9741793   0.9741109 ]
expert:[ 0.9821219   0.96254367 -0.9925618   0.97872466]
expert:[ 0.9782316   0.9693436  -0.99106735  0.97982496]
expert:[ 0.9725005   0.96696496 -0.9875855   0.9792794 ]
expert:[ 0.9632172   0.95324105 -0.980437    0.978078  ]
expert:[ 0.9386953   0.91274273 -0.9425082   0.9729148 ]
expert:[0.7199731  0.9481165  0.37025276 0.8426676 ]
expert:[-0.11240572  0.97753507  0.98757     0.311848  ]
expert:[-0.37170082  0.9736139   0.98856163  0.29371515]
expert:[-0.33513865  0.974675    0.98426265  0.32885197]
expert:[-0.23953183  0.97648066  0.97951883  0.33498767]
expert:[-0.21764262  0.9737698   0.9766722   0.3221252 ]
expert:[-0.19289389  0.9737485   0.9794172   0.31068787]
expert:[-0.25565806  0.9765399   0.9835895   0.2339755 ]
expert:[-0.26668027  0.7308291   0.9262967   0.47208938]
expert:[-0.2666252  -0.7087112   0.83758223  0.62874883]
expert:[-0.4206368  -0.7637279   0.90180045  0.702746  ]
expert:[-0.26528597 -0.7813648   0.90208566  0.8460226 ]
expert:[-0.14404851 -0.7695246   0.91402084  0.9202278 ]
expert:[-0.07598155 -0.6458856   0.92820436  0.9472987 ]
expert:[-0.04035137 -0.4611634   0.9452668   0.96246886]
expert:[-0.01015838 -0.20537819  0.9557417   0.9724338 ]
expert:[-0.01327668  0.02056756  0.9605261   0.9770877 ]
expert:[-0.01696558  0.20665142  0.96318954  0.9785699 ]
expert:[-0.017686   0.3518981  0.9646127  0.9790205]
expert:[-0.01807959  0.47315115  0.9652765   0.9792825 ]
expert:[-0.02203464  0.58090067  0.9657311   0.9796535 ]
expert:[-0.02351006  0.66467804  0.9663572   0.97986984]
expert:[-0.02640143  0.7289778   0.96804637  0.97969466]
expert:[-0.03416347  0.77967423  0.9693725   0.9800051 ]
expert:[-0.03546334  0.82359046  0.9703434   0.98023576]
expert:[-0.03647711  0.85646206  0.97108054  0.98026174]
expert:[-0.04108496  0.88310105  0.9719024   0.9802886 ]
expert:[-0.04599374  0.9043452   0.9727995   0.9802894 ]
expert:[-0.0489574   0.920218    0.9740021   0.98026013]
expert:[-0.04851059  0.93019223  0.9750532   0.98030764]
expert:[-0.0482969   0.9380106   0.9761406   0.98043644]
expert:[-0.04405866  0.9395275   0.9770782   0.98060626]
expert:[-0.04132481  0.9373699   0.97757006  0.9807834 ]
expert:[-0.04144884  0.9346115   0.9777202   0.9809112 ]
expert:[-0.04259883  0.9317906   0.9778069   0.9810329 ]
expert:[-0.0438363   0.92856944  0.9779431   0.98116153]
expert:[-0.04471409  0.925482    0.97813207  0.9812751 ]
expert:[-0.04510374  0.922419    0.97837967  0.98137844]
expert:[-0.04502352  0.9192999   0.9786783   0.98147434]
expert:[-0.04453734  0.91607296  0.9790168   0.98156375]
expert:[-0.04463114  0.9131429   0.97925043  0.98161525]
expert:[-0.04532713  0.91066474  0.97941065  0.98166233]
expert:[-0.04631956  0.9085015   0.9795805   0.9817031 ]
expert:[-0.04746184  0.90645254  0.97974336  0.9817397 ]
expert:[-0.04866129  0.90440726  0.97990507  0.9817727 ]
expert:[-0.04987007  0.9023139   0.98007447  0.9818022 ]
expert:[-0.05106605  0.9001484   0.98025495  0.9818284 ]
expert:[-0.05213129  0.8978602   0.9804773   0.9818024 ]
expert:[-0.05317371  0.895966    0.980745    0.98165303]
expert:[-0.05462363  0.8944295   0.98101467  0.98152906]
expert:[-0.05596218  0.89285374  0.9812761   0.981408  ]
expert:[-0.05689523  0.89112526  0.9815283   0.9812532 ]
expert:[-0.05772591  0.88903886  0.98189133  0.98086035]
expert:[-0.05937959  0.88753706  0.98215765  0.98047817]
expert:[-0.0602981   0.8859034   0.9823498   0.98017263]
expert:[-0.06061422  0.8840255   0.98253554  0.97995555]
expert:[-0.06086277  0.8819876   0.9827227   0.9798108 ]
expert:[-0.06116138  0.8798435   0.982918    0.9796635 ]
expert:[-0.06238665  0.87822217  0.98310834  0.9791931 ]
expert:[-0.06299063  0.87653744  0.98309606  0.97894347]
expert:[-0.06356957  0.87536025  0.9829947   0.9786612 ]
expert:[-0.06402034  0.87545514  0.98228097  0.9777114 ]
expert:[-0.06727765  0.8766601   0.9793856   0.97590077]
expert:[-0.06963258  0.87753165  0.97371453  0.97308576]
expert:[-0.06931534  0.8778155   0.9649217   0.9705624 ]
expert:[-0.06870139  0.8793106   0.96027255  0.9695835 ]
expert:[-0.06742357  0.8782298   0.9611316   0.96976215]
expert:[-0.06600115  0.8767054   0.96276885  0.97009623]
expert:[-0.06497758  0.8752661   0.96413064  0.97034526]
expert:[-0.06390098  0.8738599   0.9651295   0.9705479 ]
expert:[-0.06266542  0.8725108   0.9658951   0.9707155 ]
expert:[-0.06102284  0.87149245  0.9664929   0.970819  ]
expert:[-0.05943987  0.8705096   0.9669962   0.9709063 ]
expert:[-0.05792425  0.8695499   0.96742564  0.9709821 ]
expert:[-0.05647155  0.86861366  0.96779627  0.97104836]
expert:[-0.05507674  0.86770046  0.96812016  0.971107  ]
expert:[-0.05373475  0.8668098   0.9684065   0.97115934]
expert:[-0.05244227  0.8659405   0.96866244  0.97120655]
expert:[-0.05119404  0.8650917   0.9688938   0.9712495 ]
expert:[-0.04998722  0.864262    0.9691051   0.971289  ]
expert:[-0.04881855  0.8634508   0.96930003  0.9713256 ]
expert:[-0.04768515  0.86265695  0.9694811   0.9713597 ]
expert:[-0.04658451  0.8618795   0.9696508   0.97139186]
expert:[-0.04551527  0.8611179   0.9698109   0.97142226]
expert:[-0.04447522  0.8603713   0.9699627   0.9714511 ]
expert:[-0.04346271  0.85963935  0.9701074   0.97147876]
expert:[-0.04247649  0.8589214   0.97024596  0.9715053 ]
expert:[-0.0415156   0.85821694  0.9703791   0.97153074]
expert:[-0.0405787   0.8575264   0.97050613  0.97155714]
expert:[-0.03966965  0.8568498   0.970626    0.9715849 ]
expert:[-0.03879036  0.8561846   0.9707415   0.97160906]
expert:[-0.03793208  0.8555314   0.97085357  0.9716325 ]
expert:[-0.03709409  0.85488987  0.97096246  0.9716553 ]
expert:[-0.03627637  0.85425997  0.9710683   0.97167754]
expert:[-0.03547745  0.8536413   0.9711715   0.9716992 ]
expert:[-0.03469752  0.8530334   0.97127205  0.9717203 ]
expert:[-0.03393516  0.85243636  0.97137016  0.97174084]
expert:[-0.03319084  0.85184985  0.9714659   0.971761  ]
expert:[-0.03246348  0.8512736   0.9715595   0.9717806 ]
expert:[-0.0317532  0.8507076  0.971651   0.9717998]
expert:[-0.03105878  0.85015136  0.9717404   0.9718185 ]
expert:[-0.03049343  0.8497229   0.97179466  0.9718177 ]
expert:[-0.02994251  0.84930396  0.9718474   0.97181654]
expert:[-0.02940388  0.84889215  0.9718992   0.9718154 ]
expert:[-0.02887646  0.848487    0.9719502   0.9718143 ]
expert:[-0.02836008  0.848088    0.9720004   0.9718132 ]
expert:[-0.02785403  0.8476952   0.9720499   0.9718122 ]
expert:[-0.02735766  0.84730816  0.9720987   0.9718112 ]
expert:[-0.02687095  0.84692675  0.97214675  0.9718102 ]
expert:[-0.02639381  0.84655064  0.97219425  0.97180927]
expert:[-0.02597636  0.8461704   0.9722393   0.97180855]
expert:[-0.02560148  0.8457931   0.97228307  0.9718093 ]
expert:[-0.02523317  0.84542096  0.97232634  0.9718101 ]
expert:[-0.02487149  0.8450534   0.9723691   0.97181094]
expert:[-0.02451589  0.84469044  0.97241133  0.97181165]
expert:[-0.02416611  0.84433156  0.9724532   0.9718125 ]
expert:[-0.02382193  0.8439768   0.9724946   0.9718132 ]
expert:[-0.02348346  0.84362614  0.97253555  0.9718139 ]
expert:[-0.02315577  0.84328157  0.97257304  0.97181517]
expert:[-0.0228355   0.8429415   0.9726093   0.97181636]
expert:[-0.02251988  0.84260535  0.9726451   0.9718176 ]
expert:[-0.02220912  0.8422725   0.9726806   0.97181886]
expert:[-0.02190366  0.8419434   0.9727158   0.97182006]
expert:[-0.02160231  0.8416175   0.97275066  0.9718213 ]
expert:[-0.0213059   0.8412952   0.9727851   0.97182256]
expert:[-0.02101359  0.84097606  0.9728193   0.97182375]
expert:[-0.02072599  0.84066045  0.9728532   0.97182494]
expert:[-0.02044253  0.840348    0.9728868   0.97182614]
expert:[-0.02016374  0.8400389   0.97292     0.9718273 ]
expert:[-0.01988879  0.8397327   0.97295296  0.97182846]
expert:[-0.01961818  0.83942974  0.9729857   0.97182965]
expert:[-0.01935154  0.83912987  0.97301805  0.9718308 ]
expert:[-0.0190892  0.8388331  0.9730502  0.971832 ]
expert_success: 1.0
path_length: 150



-------------------------------- Iteration 0 -------------------------------- 
initial ob: [-0.03265248  0.51488137  0.23688703  0.          0.6         0.01999588
  0.          0.85000002  0.301       0.          0.85000002  0.301     ]
agent_success: 0

training time:  0.19079327583312988
evaluation time:  8.20929503440857
epoch time:  8.400117874145508


-------------------------------- Iteration 200 -------------------------------- 
initial ob: [-0.03265248  0.51488137  0.23688703  0.          0.6         0.01999588
  0.          0.85000002  0.301       0.          0.85000002  0.301     ]
agent_success: 0

training time:  0.0023453235626220703
evaluation time:  8.479430437088013
epoch time:  8.481801748275757


-------------------------------- Iteration 400 -------------------------------- 
initial ob: [-0.03265248  0.51488137  0.23688703  0.          0.6         0.01999588
  0.          0.85000002  0.301       0.          0.85000002  0.301     ]
agent_success: 0

training time:  0.0023450851440429688
evaluation time:  8.430174350738525
epoch time:  8.432538270950317


-------------------------------- Iteration 600 -------------------------------- 
initial ob: [-0.03265248  0.51488137  0.23688703  0.          0.6         0.01999588
  0.          0.85000002  0.301       0.          0.85000002  0.301     ]
agent_success: 0

training time:  0.0023376941680908203
evaluation time:  8.426877975463867
epoch time:  8.42923617362976


-------------------------------- Iteration 800 -------------------------------- 
initial ob: [-0.03265248  0.51488137  0.23688703  0.          0.6         0.01999588
  0.          0.85000002  0.301       0.          0.85000002  0.301     ]
agent_success: 0

training time:  0.0023505687713623047
evaluation time:  8.438009023666382
epoch time:  8.440389394760132


-------------------------------- Iteration 1000 -------------------------------- 
initial ob: [-0.03265248  0.51488137  0.23688703  0.          0.6         0.01999588
  0.          0.85000002  0.301       0.          0.85000002  0.301     ]
agent_success: 0

training time:  0.002341747283935547
evaluation time:  8.462963104248047
epoch time:  8.465336799621582


-------------------------------- Training stopped due to early stopping -------------------------------- 
min loss:  0.003127969


-------------------------------- Test Results -------------------------------- 
initial ob: [-0.03265248  0.51488137  0.23688703  0.          0.6         0.01999588
  0.          0.85000002  0.301       0.          0.85000002  0.301     ]
agent_success: 0

mean_success_rate:  0.0
Done
