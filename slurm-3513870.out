/var/lib/slurm/slurmd/job3513870/slurm_script: line 9: batch_scripts/MT50_batch/seed.sh: No such file or directory
SLURM_JOBID=3513870
working directory=/viscam/u/jialugao/Imitation-SoftModule
########################
logging outputs to  /viscam/u/jialugao/Imitation-SoftModule/data/Base_bc_reach_pick-out-of-hole-v1_2640.000124-01-2022_18-56-22
########################
{'expert_policy_file': '../Multi-Task-RL/log/MT50_Single_Task/pick-out-of-hole-v1/Fixed/238/model/model_pf_best.pth', 'exp_name': 'bc_reach', 'do_dagger': False, 'ep_len': 200, 'gradient_steps': 1, 'n_iter': 10000, 'render_interval': 1, 'eval_interval': 200, 'batch_size': 64, 'eval_batch_size': 32, 'train_batch_size': 32, 'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'video_log_freq': -1, 'scalar_log_freq': 1, 'no_gpu': False, 'which_gpu': 0, 'max_replay_buffer_size': 1000000, 'save_params': False, 'seed': 32, 'worker_nums': 1, 'eval_worker_nums': 1, 'config': 'config/BC.json', 'no_cuda': True, 'random_init': False, 'device': 'cpu', 'id': 'MT50_Single_Task', 'task_name': 'pick-out-of-hole-v1', 'task_env': 'MT50_task_env', 'cuda': False, 'log_dir': '/viscam/u/jialugao/Imitation-SoftModule/data/Base_bc_reach_pick-out-of-hole-v1_2640.000124-01-2022_18-56-22', 'agent_class': <class 'agents.bc_agent.MLPAgent'>, 'agent_params': {'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'max_replay_buffer_size': 1000000, 'discrete': False, 'ac_dim': 4, 'ob_dim': 9}}
{'env_name': 'single_task', 'env': {'reward_scale': 1, 'obs_norm': False}, 'meta_env': {'obs_type': 'with_goal', 'random_init': False}, 'replay_buffer': {'size': 1000000.0}, 'net': {'hidden_shapes': [400, 400], 'append_hidden_shapes': [400], 'base_type': <class 'networks.base.MLPBase'>}, 'general_setting': {'discount': 0.99, 'pretrain_epochs': 20, 'num_epochs': 7500, 'epoch_frames': 200, 'max_episode_frames': 200, 'batch_size': 1280, 'min_pool': 10000, 'target_hard_update_period': 1000, 'use_soft_update': True, 'tau': 0.005, 'opt_times': 200, 'eval_episodes': 100, 'train_render': False, 'eval_render': False, 'env': <NormAct<RewardShift<SingleWrapperNone>>>, 'logger': <utils.logger.Logger object at 0x7fae01244b90>, 'device': device(type='cpu')}, 'sac': {'plr': 0.0003, 'qlr': 0.0003, 'reparameterization': True, 'automatic_entropy_tuning': True, 'policy_std_reg_weight': 0, 'policy_mean_reg_weight': 0}}
Loading expert policy from... ../Multi-Task-RL/log/MT50_Single_Task/pick-out-of-hole-v1/Fixed/238/model/model_pf_best.pth
tensor([[-0.7339,  0.2240, -0.3672,  ..., -0.0365, -0.0257, -0.0716],
        [ 0.0591, -0.0316, -0.0575,  ...,  0.0090, -0.0031, -0.0727],
        [-0.1173, -0.2324, -0.3262,  ..., -0.0016,  0.0664,  0.0445],
        ...,
        [ 0.0309, -0.0696, -0.0021,  ...,  0.0400, -0.0417, -0.0369],
        [-0.0229, -0.0365, -0.0508,  ..., -0.0461,  0.0082, -0.0173],
        [-0.1353,  0.0715, -0.4777,  ..., -0.0211, -0.0408, -0.0089]])
Done restoring expert policy...
<NormAct<RewardShift<AugObs<SawyerPickOutOfHoleEnv instance>>>>


-------------------------------- Iteration 0 -------------------------------- 
initial ob: [-0.03357615  0.51377786  0.2363442   0.          0.84       -0.03
  0.          0.6         0.2         0.          0.6         0.2       ]
expert:[ 0.3172611   0.99277246  0.8538122  -0.94561607]
expert:[-0.10057636  0.9926787   0.9890495  -0.55165493]
expert:[-0.8108521   0.99414265  0.9958786   0.4377681 ]
expert:[-0.8995038   0.99403363  0.99596614  0.77366525]
expert:[-0.8956901   0.99390614  0.9957123   0.83406574]
expert:[-0.8207506   0.9936602   0.99546736  0.8453689 ]
expert:[-0.4144184   0.9932014   0.9857895   0.77393967]
expert:[ 0.9066078   0.9890647  -0.9867834  -0.06743342]
expert:[ 0.93984187  0.9902315  -0.9866552  -0.01175176]
expert:[ 0.95176524  0.99013937 -0.98613733  0.13067101]
expert:[ 0.9546482   0.9877299  -0.98368627  0.45204216]
expert:[ 0.94937474  0.9840897  -0.97857744  0.44009683]
expert:[ 0.8757651   0.98705184 -0.37215284 -0.5882692 ]
expert:[ 0.8338348   0.9874948   0.8829545  -0.87665904]
expert:[ 0.7503416   0.9885838   0.95934504 -0.9124554 ]
expert:[ 0.49792692  0.9891388   0.9748609  -0.9071499 ]
expert:[ 0.05854215  0.98947823  0.97778785 -0.8855552 ]
expert:[-0.36006412  0.98873746  0.9759966  -0.83554167]
expert:[-0.12989153  0.9715085  -0.70323634  0.24117853]
expert:[ 0.05009306  0.94685704 -0.91455126  0.6898425 ]
expert:[ 0.27773526  0.94525313 -0.9141566   0.74562263]
expert:[ 0.48725858  0.94179755 -0.908142    0.74785167]
expert:[ 0.5536701   0.9280026  -0.89089143  0.6945674 ]
expert:[ 0.5267961   0.9370659  -0.29950202  0.1824178 ]
expert:[ 0.544023    0.95835054  0.8346889  -0.6081686 ]
expert:[ 0.31052494  0.9392621   0.7804018  -0.44927436]
expert:[-0.15338223  0.8707337   0.6464507  -0.09268982]
expert:[-0.30796048  0.71797645  0.41963807  0.04856946]
expert:[-0.26591372  0.42589322  0.17011502  0.04568119]
expert:[-0.10106899  0.11635665 -0.15124236  0.054787  ]
expert:[ 0.08501422 -0.0678336  -0.32728186  0.07974388]
expert:[ 0.2837903  -0.22103824 -0.36641055  0.11190744]
expert:[ 0.3894537  -0.30896667 -0.2286051   0.141104  ]
expert:[ 0.39569113 -0.35676172 -0.04308243  0.15094553]
expert:[ 0.3106517  -0.36276633  0.10707135  0.13284451]
expert:[ 0.1629251  -0.34697026  0.20691998  0.09444956]
expert:[-0.0216509  -0.32418367  0.23204227  0.06163009]
expert:[-0.17563309 -0.27876532  0.17061675  0.03624525]
expert:[-0.25993818 -0.23018973  0.05904341  0.02405265]
expert:[-0.2957099  -0.18483089 -0.05084787  0.01594488]
expert:[-0.2824495  -0.1615502  -0.11223617  0.01078162]
expert:[-0.22876897 -0.15906669 -0.11553641  0.00989912]
expert:[-0.14325555 -0.16986737 -0.0773476   0.01857604]
expert:[-0.0249188  -0.16025747 -0.04859063  0.04663617]
expert:[ 0.07126758 -0.14645132 -0.01315209  0.07409524]
expert:[ 0.12804432 -0.11875232  0.00952176  0.09440722]
expert:[ 0.131748   -0.06584934  0.01912521  0.10136945]
expert:[0.08629093 0.00691133 0.02650977 0.09809308]
expert:[0.01179233 0.07762283 0.02556234 0.08649203]
expert:[-0.05953094  0.13286965  0.02085184  0.07252775]
expert:[-0.10050388  0.16196841  0.01513846  0.06388552]
expert:[-0.10007878  0.16025811  0.00923759  0.06401455]
expert:[-0.05970603  0.13053417  0.00477178  0.07280049]
expert:[0.0076324  0.08327356 0.00701339 0.08619571]
expert:[0.07880206 0.02906906 0.01131936 0.09953957]
expert:[ 0.13143907 -0.02162993  0.01358992  0.10776147]
expert:[ 0.14679135 -0.0575868   0.01175006  0.10665219]
expert:[ 0.11535016 -0.06244972  0.0054582   0.09673377]
expert:[ 0.05414275 -0.05107294 -0.00460153  0.08011047]
expert:[-0.01738556 -0.02956088 -0.01773125  0.06175689]
expert:[-0.08183327 -0.00502162 -0.02989766  0.04678483]
expert:[-0.12088934  0.01213236 -0.03281044  0.03785772]
expert:[-0.12565508  0.01666363 -0.02620535  0.03702879]
expert:[-0.09703896  0.00798399 -0.01147031  0.04401737]
expert:[-0.04483103 -0.00918416  0.0086057   0.05645596]
expert:[ 0.01510333 -0.02671034  0.02481942  0.07146646]
expert:[ 0.06324896 -0.03924393  0.0329035   0.08413762]
expert:[ 0.09103984 -0.04215454  0.03085436  0.09191506]
expert:[ 0.08866414 -0.03432091  0.01943195  0.09209134]
expert:[ 0.05926466 -0.01716092  0.00187815  0.08543306]
expert:[ 0.01480936  0.00547524 -0.01608413  0.07499538]
expert:[-0.03115568  0.02770765 -0.02995653  0.06410738]
expert:[-0.06434295  0.04315321 -0.03462072  0.05622671]
expert:[-0.07552102  0.04695031 -0.02720047  0.05352979]
expert:[-0.06289043  0.03827908 -0.01054661  0.05603698]
expert:[-0.03149224  0.02152927  0.00838593  0.06315371]
expert:[0.00840184 0.00120405 0.02420074 0.07251112]
expert:[ 0.04343606 -0.01722471  0.03322182  0.08068311]
expert:[ 0.06481292 -0.02922031  0.03356425  0.08563674]
expert:[ 0.06624526 -0.03218078  0.02435434  0.08578575]
expert:[ 0.04809016 -0.02570906  0.00762943  0.08126303]
expert:[ 0.01718552 -0.01217387 -0.01109697  0.07375756]
expert:[-0.01806271  0.00468045 -0.02657998  0.06534215]
expert:[-0.04620318  0.01829966 -0.03551798  0.05874426]
expert:[-0.05914802  0.02418246 -0.03373898  0.05584599]
expert:[-0.05428063  0.02149465 -0.02159073  0.05687545]
expert:[-0.03413173  0.01256054 -0.00277056  0.06146913]
expert:[-0.0051624   0.00030384  0.01464117  0.06851233]
expert:[ 0.02347592 -0.01188888  0.02733519  0.075462  ]
expert:[ 0.04289511 -0.02043649  0.03262845  0.08018973]
expert:[ 0.04888498 -0.02287293  0.02860336  0.08169639]
expert:[ 0.04039389 -0.0183487   0.01618854  0.07975755]
expert:[ 0.02056035 -0.00856159 -0.00040766  0.0750993 ]
expert:[-0.00472717  0.00352196 -0.01616347  0.06911031]
expert:[-0.02714404  0.01458568 -0.02759852  0.06384928]
expert:[-0.03996575  0.02044962 -0.03006471  0.06077887]
expert:[-0.03991588  0.01953569 -0.02219474  0.06064583]
expert:[-0.02807955  0.013151   -0.0082832   0.0633175 ]
expert:[-0.00865502  0.00389854  0.0059279   0.06791798]
expert:[ 0.01233537 -0.00602118  0.01792195  0.0729063 ]
expert:[ 0.02864302 -0.01423694  0.0252646   0.07672781]
expert:[ 0.03551646 -0.01802781  0.02523031  0.07832935]
expert:[ 0.03155217 -0.01608576  0.01721173  0.07741701]
expert:[ 0.01829988 -0.00943134  0.00436778  0.07432983]
expert:[-4.1648746e-06 -3.3037970e-04 -9.1722645e-03  7.0041575e-02]
expert:[-0.01739118  0.00847118 -0.01976692  0.06598184]
expert:[-0.02855841  0.01424818 -0.02436626  0.06339125]
expert:[-0.03035405  0.01480427 -0.0202741   0.06290288]
expert:[-0.02299095  0.01070784 -0.01009431  0.0645441 ]
expert:[-0.00931531  0.00400727  0.00150875  0.06775582]
expert:[ 0.00638969 -0.00356151  0.01208091  0.07146611]
expert:[ 0.01953965 -0.01009947  0.01920725  0.07455667]
expert:[ 0.02606378 -0.01342325  0.02037986  0.07608543]
expert:[ 0.02430495 -0.01230288  0.01501996  0.07571962]
expert:[ 0.01512668 -0.0073889   0.00529614  0.07362276]
expert:[ 0.00183521 -0.00046312 -0.00552639  0.07054695]
expert:[-0.01132666  0.0063677  -0.01426564  0.06748889]
expert:[-0.02023711  0.01094489 -0.01835516  0.06541127]
expert:[-0.02224965  0.01150509 -0.01576643  0.0648708 ]
expert:[-0.01731445  0.00834803 -0.0083048   0.06593525]
expert:[-0.00750306  0.00295711  0.00093765  0.06817255]
expert:[ 0.00400253 -0.00303389  0.00928765  0.07084049]
expert:[ 0.01370808 -0.00796495  0.01451815  0.07311102]
expert:[ 0.01862347 -0.01022807  0.01490261  0.07429529]
expert:[ 0.01739269 -0.00910439  0.01038398  0.07407657]
expert:[ 0.01080986 -0.00519477  0.00280437  0.07261372]
expert:[ 0.0012565   0.00012573 -0.005284    0.07044082]
expert:[-0.00815459  0.00522326 -0.01144232  0.06827684]
expert:[-0.01437677  0.00836054 -0.01355975  0.06681257]
expert:[-0.01557889  0.00845349 -0.01082483  0.06646165]
expert:[-0.01182686  0.00577735 -0.00458114  0.06724035]
expert:[-0.0046958   0.0015066   0.00267691  0.068826  ]
expert:[ 0.00341469 -0.00295245  0.00860227  0.07068123]
expert:[ 0.00994296 -0.00624158  0.01142574  0.07221428]
expert:[ 0.01289702 -0.00734213  0.01033021  0.07295929]
expert:[ 0.01155747 -0.0060145   0.00587715  0.07273053]
expert:[ 0.00665314 -0.00284938 -0.00026847  0.07166973]
expert:[-2.8558075e-05  1.0667156e-03 -6.0848515e-03  7.0171468e-02]
expert:[-0.00622356  0.00443484 -0.00968878  0.06874649]
expert:[-0.00992426  0.00608905 -0.00981682  0.06784841]
expert:[-0.01013358  0.00554973 -0.00650107  0.06771614]
expert:[-0.00711441  0.00321755 -0.00114997  0.06832195]
expert:[-2.1064400e-03  4.1158404e-05  4.2280750e-03  6.9415294e-02]
expert:[ 0.0031626  -0.0029007   0.0078536   0.07061657]
expert:[ 0.00700062 -0.00468791  0.00865132  0.07153718]
expert:[ 0.00829283 -0.00483465  0.00654262  0.07190561]
expert:[ 0.00682226 -0.00341007  0.00240483  0.07164789]
expert:[ 0.00328636 -0.00098438 -0.00231092  0.07089958]
expert:[-0.00101497  0.0016081  -0.00605831  0.06994264]
expert:[-0.00460838  0.00348163 -0.00761443  0.06910534]
expert:[-0.00636971  0.0040258  -0.00649976  0.06864708]
expert:[-0.00590517  0.00316286 -0.00322575  0.0686762 ]
expert:[-0.00359003  0.00132359  0.00093047  0.06913505]
expert:[-0.00034328 -0.0007886   0.00449114  0.06983774]
expert:[ 0.0027037  -0.00245524  0.00631504  0.07053724]
expert:[ 0.00458531 -0.00317174  0.00593051  0.07100886]
expert:[ 0.00480275 -0.00279234  0.00363056  0.07112213]
expert:[ 0.00344306 -0.00153514  0.00029757  0.07087536]
expert:[ 0.00109288  0.00012825 -0.00293113  0.07038384]
expert:[-0.00138314  0.00161947 -0.00500911  0.06983256]
expert:[-0.00314869  0.00243754 -0.00529698  0.06940824]
expert:[-0.00369166  0.00235443 -0.0037966   0.06923535]
expert:[-0.00296535  0.00148092 -0.00113397  0.06934192]
expert:[-0.00134592  0.00019213  0.0017059   0.06966285]
expert:[ 0.00054049 -0.00103941  0.00376097  0.07007074]
expert:[ 0.0020466  -0.00181175  0.00441773  0.07042301]
expert:[ 0.00271505 -0.00191192  0.00357682  0.07060998]
expert:[ 0.00241048 -0.0013687   0.00163814  0.07058764]
expert:[ 0.00133634 -0.00041959 -0.00068725  0.0703867 ]
expert:[-6.9037080e-05  5.8673456e-04 -2.6133968e-03  7.0093974e-02]
expert:[-0.0012965   0.00130526 -0.00353902  0.06981805]
expert:[-0.00195002  0.00151386 -0.00322732  0.06964918]
expert:[-0.00187134  0.00118687 -0.00187456  0.06963147]
expert:[-1.1657024e-03  4.8284369e-04 -1.7389655e-05  6.9753490e-02]
expert:[-0.00014455 -0.00031708  0.00168253  0.06995761]
expert:[ 0.00081269 -0.00093493  0.00267896  0.07016546]
expert:[ 0.00138765 -0.0011808   0.0027074   0.07030611]
expert:[ 0.00142155 -0.00100355  0.00184769  0.07033847]
expert:[ 0.00096238 -0.00050682  0.00046229  0.07026394]
expert:[ 0.00021716  0.00011717 -0.00095292  0.07012   ]
expert:[-0.00052524  0.00064442 -0.00193149  0.06996477]
expert:[-0.00100666  0.00090297 -0.00218855  0.06985361]
expert:[-0.00108305  0.00082449 -0.00169884  0.06982102]
expert:[-0.00077219  0.00047117 -0.00069579  0.06986937]
expert:[-2.1853298e-04 -1.4177058e-05  4.3865290e-04  6.9973618e-02]
expert:[ 0.0003583  -0.00045148  0.0013172   0.0700908 ]
expert:[ 0.000754   -0.00069642  0.00167289  0.07017806]
expert:[ 0.00084618 -0.00068357  0.00144217  0.07020725]
expert:[ 0.00062743 -0.00043737  0.0007574   0.07017285]
expert:[ 2.02931464e-04 -6.41779043e-05 -1.10678375e-04  7.00930282e-02]
expert:[-0.00025834  0.00029703 -0.00085769  0.07000071]
expert:[-0.00058951  0.00052348 -0.00124643  0.06993033]
expert:[-0.00068402  0.00054903 -0.00118226  0.06990533]
expert:[-0.00052739  0.0003821  -0.00073031  0.06993115]
expert:[-1.931265e-04  9.483984e-05 -8.151680e-05  6.999485e-02]
expert:[ 0.00018526 -0.00020137  0.00052702  0.07007054]
expert:[ 0.0004718  -0.00040603  0.00089388  0.07013045]
expert:[ 0.00057043 -0.00045408  0.00092115  0.07015383]
expert:[ 0.00046042 -0.00034418  0.00063589  0.07013478]
expert:[ 0.00019541 -0.00012725  0.00016484  0.07008297]
expert_success: 0
path_length: 200



-------------------------------- Iteration 0 -------------------------------- 
initial ob: [-0.03357615  0.51377786  0.2363442   0.          0.84       -0.03
  0.          0.6         0.2         0.          0.6         0.2       ]
agent_success: 0

training time:  0.16064167022705078
evaluation time:  10.503257274627686
epoch time:  10.663925886154175


-------------------------------- Iteration 200 -------------------------------- 
initial ob: [-0.03357615  0.51377786  0.2363442   0.          0.84       -0.03
  0.          0.6         0.2         0.          0.6         0.2       ]
agent_success: 0

training time:  0.0023300647735595703
evaluation time:  10.36721920967102
epoch time:  10.36957859992981


-------------------------------- Iteration 400 -------------------------------- 
initial ob: [-0.03357615  0.51377786  0.2363442   0.          0.84       -0.03
  0.          0.6         0.2         0.          0.6         0.2       ]
agent_success: 0

training time:  0.0023071765899658203
evaluation time:  10.303831100463867
epoch time:  10.306158542633057


-------------------------------- Iteration 600 -------------------------------- 
initial ob: [-0.03357615  0.51377786  0.2363442   0.          0.84       -0.03
  0.          0.6         0.2         0.          0.6         0.2       ]
agent_success: 0

training time:  0.002315521240234375
evaluation time:  10.354288578033447
epoch time:  10.356625318527222


-------------------------------- Iteration 800 -------------------------------- 
initial ob: [-0.03357615  0.51377786  0.2363442   0.          0.84       -0.03
  0.          0.6         0.2         0.          0.6         0.2       ]
agent_success: 0

training time:  0.002306699752807617
evaluation time:  10.333577871322632
epoch time:  10.335919380187988


-------------------------------- Iteration 1000 -------------------------------- 
initial ob: [-0.03357615  0.51377786  0.2363442   0.          0.84       -0.03
  0.          0.6         0.2         0.          0.6         0.2       ]
agent_success: 0

training time:  0.002309560775756836
evaluation time:  10.28891897201538
epoch time:  10.291261672973633


-------------------------------- Training stopped due to early stopping -------------------------------- 
min loss:  0.0043620844


-------------------------------- Test Results -------------------------------- 
initial ob: [-0.03357615  0.51377786  0.2363442   0.          0.84       -0.03
  0.          0.6         0.2         0.          0.6         0.2       ]
agent_success: 0

mean_success_rate:  0.0
Done
