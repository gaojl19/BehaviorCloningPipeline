/var/lib/slurm/slurmd/job3511544/slurm_script: line 9: batch_scripts/MT50_batch/seed.sh: No such file or directory
SLURM_JOBID=3511544
working directory=/viscam/u/jialugao/Imitation-SoftModule
########################
logging outputs to  /viscam/u/jialugao/Imitation-SoftModule/data/Base_bc_reach_hammer-v1_2640.000123-01-2022_22-52-11
########################
{'expert_policy_file': '../Multi-Task-RL/log/MT50_Single_Task/hammer-v1/Fixed/238/model/model_pf_best.pth', 'exp_name': 'bc_reach', 'do_dagger': False, 'ep_len': 200, 'gradient_steps': 1, 'n_iter': 10000, 'render_interval': 1, 'eval_interval': 200, 'batch_size': 64, 'eval_batch_size': 32, 'train_batch_size': 32, 'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'video_log_freq': -1, 'scalar_log_freq': 1, 'no_gpu': False, 'which_gpu': 0, 'max_replay_buffer_size': 1000000, 'save_params': False, 'seed': 32, 'worker_nums': 1, 'eval_worker_nums': 1, 'config': 'config/BC.json', 'no_cuda': True, 'random_init': False, 'device': 'cpu', 'id': 'MT50_Single_Task', 'task_name': 'hammer-v1', 'task_env': 'MT50_task_env', 'cuda': False, 'log_dir': '/viscam/u/jialugao/Imitation-SoftModule/data/Base_bc_reach_hammer-v1_2640.000123-01-2022_22-52-11', 'agent_class': <class 'agents.bc_agent.MLPAgent'>, 'agent_params': {'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'max_replay_buffer_size': 1000000, 'discrete': False, 'ac_dim': 4, 'ob_dim': 9}}
{'env_name': 'single_task', 'env': {'reward_scale': 1, 'obs_norm': False}, 'meta_env': {'obs_type': 'with_goal', 'random_init': False}, 'replay_buffer': {'size': 1000000.0}, 'net': {'hidden_shapes': [400, 400], 'append_hidden_shapes': [400], 'base_type': <class 'networks.base.MLPBase'>}, 'general_setting': {'discount': 0.99, 'pretrain_epochs': 20, 'num_epochs': 7500, 'epoch_frames': 200, 'max_episode_frames': 200, 'batch_size': 1280, 'min_pool': 10000, 'target_hard_update_period': 1000, 'use_soft_update': True, 'tau': 0.005, 'opt_times': 200, 'eval_episodes': 100, 'train_render': False, 'eval_render': False, 'env': <NormAct<RewardShift<SingleWrapperNone>>>, 'logger': <utils.logger.Logger object at 0x7f7ab7df6b50>, 'device': device(type='cpu')}, 'sac': {'plr': 0.0003, 'qlr': 0.0003, 'reparameterization': True, 'automatic_entropy_tuning': True, 'policy_std_reg_weight': 0, 'policy_mean_reg_weight': 0}}
Loading expert policy from... ../Multi-Task-RL/log/MT50_Single_Task/hammer-v1/Fixed/238/model/model_pf_best.pth
Done restoring expert policy...
<NormAct<RewardShift<SawyerHammerEnv instance>>>
<NormAct<RewardShift<SawyerHammerEnv instance>>>


-------------------------------- Iteration 0 -------------------------------- 
initial ob: [-0.03265025  0.5148823   0.23687374  0.          0.6         0.02
  0.24        0.74        0.11      ]
expert_success: 0



-------------------------------- Iteration 0 -------------------------------- 
initial ob: [-0.03265025  0.5148823   0.23687374  0.          0.6         0.02
  0.24        0.74        0.11      ]
agent_success: 0

training time:  0.16260838508605957
evaluation time:  10.479530334472656
epoch time:  10.642164707183838


-------------------------------- Iteration 200 -------------------------------- 
initial ob: [-0.03265025  0.5148823   0.23687374  0.          0.6         0.02
  0.24        0.74        0.11      ]
agent_success: 0

training time:  0.0023458003997802734
evaluation time:  10.919301748275757
epoch time:  10.921672821044922


-------------------------------- Iteration 400 -------------------------------- 
initial ob: [-0.03265025  0.5148823   0.23687374  0.          0.6         0.02
  0.24        0.74        0.11      ]
agent_success: 0

training time:  0.002291440963745117
evaluation time:  10.984808683395386
epoch time:  10.987121343612671


-------------------------------- Iteration 600 -------------------------------- 
initial ob: [-0.03265025  0.5148823   0.23687374  0.          0.6         0.02
  0.24        0.74        0.11      ]
agent_success: 0

training time:  0.0022737979888916016
evaluation time:  10.691521644592285
epoch time:  10.693814277648926


-------------------------------- Iteration 800 -------------------------------- 
initial ob: [-0.03265025  0.5148823   0.23687374  0.          0.6         0.02
  0.24        0.74        0.11      ]
agent_success: 0

training time:  0.0022983551025390625
evaluation time:  10.571682214736938
epoch time:  10.574003219604492


-------------------------------- Iteration 1000 -------------------------------- 
initial ob: [-0.03265025  0.5148823   0.23687374  0.          0.6         0.02
  0.24        0.74        0.11      ]
agent_success: 0

training time:  0.002269268035888672
evaluation time:  10.494557619094849
epoch time:  10.496840715408325


-------------------------------- Iteration 1200 -------------------------------- 
initial ob: [-0.03265025  0.5148823   0.23687374  0.          0.6         0.02
  0.24        0.74        0.11      ]
agent_success: 0

training time:  0.002277851104736328
evaluation time:  10.475859880447388
epoch time:  10.478156328201294


-------------------------------- Iteration 1400 -------------------------------- 
initial ob: [-0.03265025  0.5148823   0.23687374  0.          0.6         0.02
  0.24        0.74        0.11      ]
agent_success: 0

training time:  0.002295970916748047
evaluation time:  10.438195943832397
epoch time:  10.440521478652954


-------------------------------- Iteration 1600 -------------------------------- 
initial ob: [-0.03265025  0.5148823   0.23687374  0.          0.6         0.02
  0.24        0.74        0.11      ]
agent_success: 0

training time:  0.002284526824951172
evaluation time:  10.400891780853271
epoch time:  10.403188467025757


-------------------------------- Iteration 1800 -------------------------------- 
initial ob: [-0.03265025  0.5148823   0.23687374  0.          0.6         0.02
  0.24        0.74        0.11      ]
agent_success: 0

training time:  0.0022923946380615234
evaluation time:  10.459744453430176
epoch time:  10.462050914764404


-------------------------------- Iteration 2000 -------------------------------- 
initial ob: [-0.03265025  0.5148823   0.23687374  0.          0.6         0.02
  0.24        0.74        0.11      ]
agent_success: 0

training time:  0.0022742748260498047
evaluation time:  10.342485666275024
epoch time:  10.3447847366333


-------------------------------- Iteration 2200 -------------------------------- 
initial ob: [-0.03265025  0.5148823   0.23687374  0.          0.6         0.02
  0.24        0.74        0.11      ]
agent_success: 0

training time:  0.0022890567779541016
evaluation time:  10.369399785995483
epoch time:  10.371702671051025


-------------------------------- Iteration 2400 -------------------------------- 
initial ob: [-0.03265025  0.5148823   0.23687374  0.          0.6         0.02
  0.24        0.74        0.11      ]
agent_success: 0

training time:  0.0022895336151123047
evaluation time:  10.431475400924683
epoch time:  10.433789730072021


-------------------------------- Iteration 2600 -------------------------------- 
initial ob: [-0.03265025  0.5148823   0.23687374  0.          0.6         0.02
  0.24        0.74        0.11      ]
agent_success: 0

training time:  0.0022618770599365234
evaluation time:  10.421046257019043
epoch time:  10.42332124710083


-------------------------------- Iteration 2800 -------------------------------- 
initial ob: [-0.03265025  0.5148823   0.23687374  0.          0.6         0.02
  0.24        0.74        0.11      ]
agent_success: 0

training time:  0.0022783279418945312
evaluation time:  10.446706533432007
epoch time:  10.449010610580444


-------------------------------- Iteration 3000 -------------------------------- 
initial ob: [-0.03265025  0.5148823   0.23687374  0.          0.6         0.02
  0.24        0.74        0.11      ]
agent_success: 0

training time:  0.002293109893798828
evaluation time:  10.353228330612183
epoch time:  10.355535984039307


-------------------------------- Iteration 3200 -------------------------------- 
initial ob: [-0.03265025  0.5148823   0.23687374  0.          0.6         0.02
  0.24        0.74        0.11      ]
agent_success: 0

training time:  0.0022881031036376953
evaluation time:  10.412593841552734
epoch time:  10.41490364074707


-------------------------------- Iteration 3400 -------------------------------- 
initial ob: [-0.03265025  0.5148823   0.23687374  0.          0.6         0.02
  0.24        0.74        0.11      ]
agent_success: 0

training time:  0.00228118896484375
evaluation time:  10.478035926818848
epoch time:  10.480336427688599


-------------------------------- Iteration 3600 -------------------------------- 
initial ob: [-0.03265025  0.5148823   0.23687374  0.          0.6         0.02
  0.24        0.74        0.11      ]
agent_success: 0

training time:  0.002288341522216797
evaluation time:  10.411484003067017
epoch time:  10.413787364959717


-------------------------------- Iteration 3800 -------------------------------- 
initial ob: [-0.03265025  0.5148823   0.23687374  0.          0.6         0.02
  0.24        0.74        0.11      ]
agent_success: 0

training time:  0.002277851104736328
evaluation time:  10.272924423217773
epoch time:  10.275213241577148


-------------------------------- Iteration 4000 -------------------------------- 
initial ob: [-0.03265025  0.5148823   0.23687374  0.          0.6         0.02
  0.24        0.74        0.11      ]
agent_success: 0

training time:  0.0022678375244140625
evaluation time:  10.462326526641846
epoch time:  10.464614391326904


-------------------------------- Iteration 4200 -------------------------------- 
initial ob: [-0.03265025  0.5148823   0.23687374  0.          0.6         0.02
  0.24        0.74        0.11      ]
agent_success: 0

training time:  0.002279520034790039
evaluation time:  10.444610834121704
epoch time:  10.44690227508545


-------------------------------- Iteration 4400 -------------------------------- 
initial ob: [-0.03265025  0.5148823   0.23687374  0.          0.6         0.02
  0.24        0.74        0.11      ]
agent_success: 0

training time:  0.0022826194763183594
evaluation time:  10.455747604370117
epoch time:  10.45804476737976


-------------------------------- Iteration 4600 -------------------------------- 
initial ob: [-0.03265025  0.5148823   0.23687374  0.          0.6         0.02
  0.24        0.74        0.11      ]
agent_success: 0

training time:  0.0023012161254882812
evaluation time:  10.419376373291016
epoch time:  10.421689510345459


-------------------------------- Iteration 4800 -------------------------------- 
initial ob: [-0.03265025  0.5148823   0.23687374  0.          0.6         0.02
  0.24        0.74        0.11      ]
agent_success: 0

training time:  0.0022678375244140625
evaluation time:  10.504151821136475
epoch time:  10.506433248519897


-------------------------------- Iteration 5000 -------------------------------- 
initial ob: [-0.03265025  0.5148823   0.23687374  0.          0.6         0.02
  0.24        0.74        0.11      ]
agent_success: 0

training time:  0.002290964126586914
evaluation time:  10.45919132232666
epoch time:  10.461493730545044


-------------------------------- Training stopped due to early stopping -------------------------------- 
min loss:  0.089110106


-------------------------------- Test Results -------------------------------- 
initial ob: [-0.03265025  0.5148823   0.23687374  0.          0.6         0.02
  0.24        0.74        0.11      ]
agent_success: 0

mean_success_rate:  0.0
Done
