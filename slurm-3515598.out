/var/lib/slurm/slurmd/job3515598/slurm_script: line 9: batch_scripts/MT50_batch/seed.sh: No such file or directory
SLURM_JOBID=3515598
working directory=/viscam/u/jialugao/Imitation-SoftModule
########################
logging outputs to  /viscam/u/jialugao/Imitation-SoftModule/data/Base_bc_reach_drawer-close-v1_2640.000125-01-2022_23-02-07
########################
{'expert_policy_file': '../Multi-Task-RL/log/MT50_Single_Task/drawer-close-v1/Fixed/238/model/model_pf_best.pth', 'exp_name': 'bc_reach', 'do_dagger': False, 'ep_len': 200, 'gradient_steps': 1, 'n_iter': 10000, 'render_interval': 1, 'eval_interval': 200, 'batch_size': 64, 'eval_batch_size': 32, 'train_batch_size': 32, 'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'video_log_freq': -1, 'scalar_log_freq': 1, 'no_gpu': False, 'which_gpu': 0, 'max_replay_buffer_size': 1000000, 'save_params': False, 'seed': 32, 'worker_nums': 1, 'eval_worker_nums': 1, 'config': 'config/BC.json', 'no_cuda': True, 'random_init': False, 'device': 'cpu', 'id': 'MT50_Single_Task', 'task_name': 'drawer-close-v1', 'task_env': 'MT50_task_env', 'cuda': False, 'log_dir': '/viscam/u/jialugao/Imitation-SoftModule/data/Base_bc_reach_drawer-close-v1_2640.000125-01-2022_23-02-07', 'agent_class': <class 'agents.bc_agent.MLPAgent'>, 'agent_params': {'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'max_replay_buffer_size': 1000000, 'discrete': False, 'ac_dim': 4, 'ob_dim': 9}}
{'env_name': 'single_task', 'env': {'reward_scale': 1, 'obs_norm': False}, 'meta_env': {'obs_type': 'with_goal', 'random_init': False}, 'replay_buffer': {'size': 1000000.0}, 'net': {'hidden_shapes': [400, 400], 'append_hidden_shapes': [400], 'base_type': <class 'networks.base.MLPBase'>}, 'general_setting': {'discount': 0.99, 'pretrain_epochs': 20, 'num_epochs': 7500, 'epoch_frames': 200, 'max_episode_frames': 200, 'batch_size': 1280, 'min_pool': 10000, 'target_hard_update_period': 1000, 'use_soft_update': True, 'tau': 0.005, 'opt_times': 200, 'eval_episodes': 100, 'train_render': False, 'eval_render': False, 'env': <NormAct<RewardShift<SingleWrapperNone>>>, 'logger': <utils.logger.Logger object at 0x7f6de9c9fdd0>, 'device': device(type='cpu')}, 'sac': {'plr': 0.0003, 'qlr': 0.0003, 'reparameterization': True, 'automatic_entropy_tuning': True, 'policy_std_reg_weight': 0, 'policy_mean_reg_weight': 0}}
Loading expert policy from... ../Multi-Task-RL/log/MT50_Single_Task/drawer-close-v1/Fixed/238/model/model_pf_best.pth
tensor([[-0.3719,  0.3580,  0.2069,  ..., -0.0365,  0.0282, -0.0178],
        [ 0.0004, -0.0440, -0.0428,  ...,  0.0090, -0.0171, -0.0867],
        [-0.0109, -0.0858, -0.0569,  ..., -0.0016, -0.0350, -0.0569],
        ...,
        [ 0.0203, -0.0812, -0.0119,  ...,  0.0400, -0.0501, -0.0452],
        [-0.0213, -0.0554, -0.0628,  ..., -0.0461, -0.0097, -0.0348],
        [-0.0147, -0.0190, -0.0713,  ..., -0.0211, -0.0659, -0.0339]])
Done restoring expert policy...
<NormAct<RewardShift<AugObs<SawyerDrawerCloseEnv instance>>>>


-------------------------------- Iteration 0 -------------------------------- 
initial ob: [-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.7         0.04      ]
expert:[ 0.8717024 -0.6743838 -0.7576408  0.3723605]
expert:[ 0.94819665 -0.96747434 -0.6107694   0.7552792 ]
expert:[ 0.9826478 -0.9577044 -0.8257613  0.9104077]
expert:[ 0.99380636 -0.9645835   0.8872899  -0.50954235]
expert:[ 0.2270919  -0.91375935  0.94766134 -0.32144424]
expert:[-0.9295034  -0.91552967  0.99166554  0.7768087 ]
expert:[-0.9638842  -0.88129026  0.99591047  0.84102213]
expert:[-0.9667568  -0.89662546  0.99511135  0.8961004 ]
expert:[-0.9550713  -0.90320885  0.9571727   0.93596387]
expert:[-0.9241638 -0.8062292 -0.3610911  0.8671188]
expert:[-0.9004717 -0.8581389 -0.8822287  0.7454166]
expert:[-0.7834848  -0.91587424 -0.92668384  0.39020404]
expert:[-0.92415726 -0.92916214 -0.96339613 -0.2304776 ]
expert:[-0.9538814  -0.8458838  -0.9696588  -0.49648046]
expert:[-0.95275    -0.44125542 -0.9800896  -0.37465113]
expert:[-0.39325744  0.6834975  -0.97865933 -0.14223261]
expert:[ 0.49358982  0.9263946  -0.9608226  -0.11385026]
expert:[ 0.74338365  0.96305096 -0.9646038  -0.16926616]
expert:[ 0.7395027   0.96654934 -0.95627904 -0.02309262]
expert:[ 0.67594945  0.96251565 -0.95211285  0.01374185]
expert:[ 0.4339194   0.8944805  -0.94551516  0.03445307]
expert:[ 0.23586367  0.8678403  -0.9531658   0.03885151]
expert:[ 0.16220164  0.8899525  -0.96312004  0.00240646]
expert:[ 0.18480825  0.92172474 -0.97238487 -0.0100727 ]
expert:[ 0.23524863  0.94013196 -0.97822976  0.02901603]
expert:[ 0.26909232  0.9424565  -0.9805848   0.04268792]
expert:[ 0.28531313  0.94252473 -0.9818607   0.0459442 ]
expert:[ 0.29281747  0.94285536 -0.9827079   0.04623599]
expert:[ 0.29435205  0.94440955 -0.98340464  0.04596852]
expert:[ 0.29134586  0.9472573  -0.9840702   0.04573477]
expert:[ 0.28434134  0.951401   -0.9846858   0.04745103]
expert:[ 0.2771721  0.9565926 -0.9852807  0.051272 ]
expert:[ 0.26957738  0.9623605  -0.9858737   0.05726733]
expert:[ 0.25843266  0.9683061  -0.986637    0.0757037 ]
expert:[ 0.2013084   0.9761741  -0.9864038   0.09257431]
expert:[ 0.13103227  0.9837249  -0.9814773   0.11625718]
expert:[ 0.12307277  0.9876674  -0.98070204  0.13017046]
expert:[ 0.12803432  0.99041903 -0.98139924  0.15456371]
expert:[ 0.13124721  0.99249434 -0.9812565   0.18157172]
expert:[ 0.03294301  0.99520934 -0.95691776  0.14909805]
expert:[-0.10701998  0.9977326  -0.7611528   0.03063765]
expert:[-0.11724631  0.9979438  -0.66312724  0.03063704]
expert:[-0.07458287  0.9980456  -0.6513708   0.06067528]
expert:[-0.05107446  0.9979273  -0.6530294   0.10846778]
expert:[-0.36144635  0.9994901   0.7945681  -0.12869094]
expert:[-0.50462675  0.9991457   0.95094913 -0.20299895]
expert:[-0.5044083   0.9988323   0.95149446 -0.18317077]
expert:[-0.42489725  0.99854535  0.89389277 -0.13334174]
expert:[-0.30212647  0.99760276  0.7279136  -0.1160874 ]
expert:[-0.21310249  0.9967626   0.41851327 -0.1126885 ]
expert:[-0.11984558  0.99484915 -0.18818222 -0.07814793]
expert:[-0.01035114  0.99262404 -0.6512387  -0.04303462]
expert:[ 0.09660761  0.99045825 -0.848096   -0.01773008]
expert:[ 0.23494364  0.9898421  -0.9262423   0.02718794]
expert:[ 0.38533506  0.9898016  -0.95593786  0.07691722]
expert:[ 0.4458684   0.9887124  -0.9674606   0.09987854]
expert:[ 0.5000078   0.98541564 -0.96669585  0.13576785]
expert:[ 0.51120347  0.9831366  -0.94905305  0.08323167]
expert:[ 0.45618394  0.98340976 -0.94383883  0.058617  ]
expert:[ 0.42651707  0.9835789  -0.94698024  0.03752076]
expert:[ 0.40923372  0.98367643 -0.9512624   0.01641153]
expert:[ 0.39645508  0.9837411  -0.9545641  -0.00129995]
expert:[ 0.38613468  0.9837909  -0.95678216 -0.01484656]
expert:[ 0.3772979   0.9838388  -0.958263   -0.02534217]
expert:[ 0.37051034  0.9838698  -0.9591141  -0.03241251]
expert:[ 0.36558852  0.983895   -0.9596945  -0.03743408]
expert:[ 0.35789257  0.98387736 -0.9592672  -0.04159575]
expert:[ 0.3518233  0.9838693 -0.9588263 -0.0435822]
expert:[ 0.3482543   0.9838749  -0.958731   -0.04516683]
expert:[ 0.3457239   0.9838833  -0.95876396 -0.04682543]
expert:[ 0.3364742   0.98385656 -0.9577758  -0.04980808]
expert:[ 0.32949832  0.9838597  -0.9572809  -0.05187462]
expert:[ 0.3253511   0.9838706  -0.95717293 -0.05383982]
expert:[ 0.32247904  0.98388183 -0.9572241  -0.05596827]
expert:[ 0.3150401   0.9838766  -0.95675844 -0.0597814 ]
expert:[ 0.3040211   0.9838868  -0.9561787  -0.06437822]
expert:[ 0.2977356   0.9839047  -0.95607126 -0.0676638 ]
expert:[ 0.29381743  0.98392016 -0.95615554 -0.07060443]
expert:[ 0.2904895   0.98393494 -0.956314   -0.07368969]
expert:[ 0.27715385  0.9839164  -0.95561624 -0.08064757]
expert:[ 0.2681681   0.9838904  -0.9552252  -0.08555418]
expert:[ 0.26328787  0.9838717  -0.9551485  -0.08920533]
expert:[ 0.2600992   0.9838532  -0.9551989  -0.09256937]
expert:[ 0.2569892   0.9838382  -0.9552847  -0.09610963]
expert:[ 0.2394975   0.98382884 -0.954427   -0.10520491]
expert:[ 0.23009971  0.9838275  -0.9541591  -0.11061555]
expert:[ 0.22488202  0.9838175  -0.95414764 -0.11480071]
expert:[ 0.22099337  0.9838     -0.95425355 -0.1190482 ]
expert:[ 0.21742345  0.9837801  -0.95438087 -0.12330309]
expert:[ 0.19722526  0.98376524 -0.9536393  -0.13475211]
expert:[ 0.18581074  0.98375124 -0.9534956  -0.14264777]
expert:[ 0.17907082  0.98372674 -0.95359516 -0.14909564]
expert:[ 0.17384504  0.98369676 -0.95378435 -0.15524653]
expert:[ 0.16891664  0.9836671  -0.9539775  -0.16117246]
expert:[ 0.14679854  0.9836479  -0.95328534 -0.17396294]
expert:[ 0.13443738  0.9836304  -0.95315164 -0.1824887 ]
expert:[ 0.1269961   0.9836006  -0.95325786 -0.18948792]
expert:[ 0.12111242  0.983563   -0.95346224 -0.19626454]
expert:[ 0.11566041  0.9835275  -0.9536547  -0.20257887]
expert:[ 0.09218603  0.9834713  -0.95341974 -0.2199999 ]
expert:[ 0.07920291  0.98342913 -0.9534722  -0.23057196]
expert:[ 0.07135573  0.9833945  -0.95364517 -0.23821741]
expert:[ 0.0650889   0.9833608  -0.9538724  -0.24511413]
expert:[ 0.0593784   0.98332924 -0.95408386 -0.25146303]
expert:[ 0.0378055  0.9832635 -0.9538603 -0.2672049]
expert:[ 0.02254411  0.98321724 -0.95387405 -0.27877143]
expert:[ 0.01373971  0.9831816  -0.95402646 -0.28664804]
expert:[ 0.00726285  0.983148   -0.95423967 -0.29336923]
expert:[ 0.0012674   0.98311746 -0.9544658  -0.29962936]
expert:[-0.01479196  0.98307306 -0.95435214 -0.31091833]
expert:[-0.02917243  0.98303837 -0.95429975 -0.3206764 ]
expert:[-0.03752454  0.9830122  -0.9544031  -0.3272541 ]
expert:[-0.04373765  0.98299485 -0.954653   -0.33387694]
expert:[-0.04887736  0.9829969  -0.9550769  -0.3420981 ]
expert:[-0.06526033  0.9831855  -0.9555251  -0.3680651 ]
expert:[-0.08136354  0.98348314 -0.95606333 -0.39707762]
expert:[-0.08966422  0.9836199  -0.95653826 -0.41322076]
expert:[-0.09518984  0.9836921  -0.9569715  -0.4244477 ]
expert:[-0.1001154   0.9837488  -0.95738953 -0.4344031 ]
expert:[-0.10733231  0.9838784  -0.95774186 -0.4490284 ]
expert:[-0.12026949  0.9842201  -0.95827603 -0.4767999 ]
expert:[-0.12720264  0.9843979  -0.95877606 -0.49232426]
expert:[-0.13176475  0.9844905  -0.9592233  -0.50248015]
expert:[-0.13568328  0.9845546  -0.95968866 -0.5111601 ]
expert:[-0.13839921  0.9846679  -0.959999   -0.5178264 ]
expert:[-0.14862931  0.9852938  -0.96024054 -0.54221696]
expert:[-0.15571147  0.9857699  -0.9603618  -0.5591508 ]
expert:[-0.15984969  0.98601854 -0.9605562  -0.5689425 ]
expert:[-0.16290276  0.9861782  -0.96078    -0.57610625]
expert:[-0.16563249  0.98630774 -0.9610123  -0.58245516]
expert:[-0.16948792  0.9865351  -0.96102655 -0.5911816 ]
expert:[-0.17744704  0.9870451  -0.9607779  -0.6104241 ]
expert:[-0.18210164  0.9873067  -0.9607407  -0.6219448 ]
expert:[-0.18464729  0.9874321  -0.9608161  -0.6284927 ]
expert:[-0.18672393  0.98752016 -0.9609291  -0.6337419 ]
expert:[-0.18824051  0.98757994 -0.96098876 -0.6375702 ]
expert:[-0.19341516  0.9878934  -0.9604924  -0.65090907]
expert:[-0.19829604  0.98818165 -0.9601433  -0.6634716 ]
expert:[-0.20011653  0.9882752  -0.95985013 -0.66973424]
expert:[-0.20110294  0.9883074  -0.95974183 -0.6733627 ]
expert:[-0.2018213   0.9883146  -0.95968574 -0.67625237]
expert:[-0.20231894  0.98831856 -0.9596006  -0.67832065]
expert:[-0.20547579  0.9885328  -0.95845103 -0.6885619 ]
expert:[-0.20787162  0.98868024 -0.95781225 -0.6960952 ]
expert:[-0.20909862  0.9887346  -0.9575871  -0.70014143]
expert:[-0.209807    0.9887475  -0.95750445 -0.70272964]
expert:[-0.2101815   0.98873955 -0.95744777 -0.7043641 ]
expert:[-0.21064131  0.988747   -0.95734763 -0.706096  ]
expert:[-0.21409556  0.9889827  -0.9558573  -0.7165287 ]
expert:[-0.21608561  0.98909664 -0.9552647  -0.7224507 ]
expert_success: 1.0
path_length: 150
