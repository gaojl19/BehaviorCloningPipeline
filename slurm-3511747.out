/var/lib/slurm/slurmd/job3511747/slurm_script: line 9: batch_scripts/MT50_batch/seed.sh: No such file or directory
SLURM_JOBID=3511747
working directory=/viscam/u/jialugao/Imitation-SoftModule
########################
logging outputs to  /viscam/u/jialugao/Imitation-SoftModule/data/Base_bc_reach_pick-place-wall-v1_2640.000124-01-2022_02-14-00
########################
{'expert_policy_file': '../Multi-Task-RL/log/MT50_Single_Task/pick-place-wall-v1/Fixed/238/model/model_pf_best.pth', 'exp_name': 'bc_reach', 'do_dagger': False, 'ep_len': 250, 'gradient_steps': 1, 'n_iter': 10000, 'render_interval': 1, 'eval_interval': 200, 'batch_size': 64, 'eval_batch_size': 32, 'train_batch_size': 32, 'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'video_log_freq': -1, 'scalar_log_freq': 1, 'no_gpu': False, 'which_gpu': 0, 'max_replay_buffer_size': 1000000, 'save_params': False, 'seed': 32, 'worker_nums': 1, 'eval_worker_nums': 1, 'config': 'config/BC.json', 'no_cuda': True, 'random_init': False, 'device': 'cpu', 'id': 'MT50_Single_Task', 'task_name': 'pick-place-wall-v1', 'task_env': 'MT50_task_env', 'cuda': False, 'log_dir': '/viscam/u/jialugao/Imitation-SoftModule/data/Base_bc_reach_pick-place-wall-v1_2640.000124-01-2022_02-14-00', 'agent_class': <class 'agents.bc_agent.MLPAgent'>, 'agent_params': {'n_layers': 2, 'size': 400, 'learning_rate': 0.0001, 'max_replay_buffer_size': 1000000, 'discrete': False, 'ac_dim': 4, 'ob_dim': 9}}
{'env_name': 'single_task', 'env': {'reward_scale': 1, 'obs_norm': False}, 'meta_env': {'obs_type': 'with_goal', 'random_init': False}, 'replay_buffer': {'size': 1000000.0}, 'net': {'hidden_shapes': [400, 400], 'append_hidden_shapes': [400], 'base_type': <class 'networks.base.MLPBase'>}, 'general_setting': {'discount': 0.99, 'pretrain_epochs': 20, 'num_epochs': 7500, 'epoch_frames': 200, 'max_episode_frames': 200, 'batch_size': 1280, 'min_pool': 10000, 'target_hard_update_period': 1000, 'use_soft_update': True, 'tau': 0.005, 'opt_times': 200, 'eval_episodes': 100, 'train_render': False, 'eval_render': False, 'env': <NormAct<RewardShift<SingleWrapperNone>>>, 'logger': <utils.logger.Logger object at 0x7f49f9ed8a10>, 'device': device(type='cpu')}, 'sac': {'plr': 0.0003, 'qlr': 0.0003, 'reparameterization': True, 'automatic_entropy_tuning': True, 'policy_std_reg_weight': 0, 'policy_mean_reg_weight': 0}}
Loading expert policy from... ../Multi-Task-RL/log/MT50_Single_Task/pick-place-wall-v1/Fixed/238/model/model_pf_best.pth
tensor([[ 8.9855e-03,  2.2713e-02, -1.6151e-02,  ..., -3.4844e-02,
          1.8385e-02, -2.7561e-02],
        [ 1.3635e-02, -6.3236e-03, -8.8071e-03,  ..., -9.0106e-04,
          2.1357e-02, -4.8310e-02],
        [-1.0402e-02, -4.8019e-02, -2.1718e-02,  ..., -8.2789e-03,
          4.8184e-03, -1.7066e-02],
        ...,
        [ 3.7048e-02, -5.3110e-02,  1.9728e-02,  ...,  2.7497e-02,
         -2.1658e-02, -1.6845e-02],
        [-2.1330e-02,  4.9459e-05, -8.9562e-03,  ..., -4.4593e-02,
          4.5613e-02,  2.0003e-02],
        [ 4.1823e-03,  2.6946e-02, -2.8268e-02,  ..., -2.5843e-02,
         -1.8639e-02,  1.3249e-02]])
Done restoring expert policy...
<NormAct<RewardShift<AugObs<SawyerReachPushPickPlaceWallEnv instance>>>>


-------------------------------- Iteration 0 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
  0.05        0.8         0.2         0.05        0.8         0.2       ]
expert:[ 0.0060316   0.01058036 -0.02158234  0.00627339]
expert:[ 0.00603265  0.0105809  -0.02157881  0.00627138]
expert:[ 0.00603339  0.01058068 -0.02157512  0.00626987]
expert:[ 0.00603383  0.01058037 -0.02157259  0.0062689 ]
expert:[ 0.00603411  0.01058016 -0.02157095  0.00626827]
expert:[ 0.00603428  0.01058003 -0.0215699   0.00626786]
expert:[ 0.0060344   0.01057997 -0.02156924  0.0062676 ]
expert:[ 0.00603448  0.01057995 -0.02156885  0.00626743]
expert:[ 0.00603453  0.01057995 -0.02156861  0.00626731]
expert:[ 0.00603457  0.01057996 -0.02156846  0.00626723]
expert:[ 0.00603461  0.01057997 -0.02156836  0.00626717]
expert:[ 0.00603463  0.01057998 -0.02156831  0.00626713]
expert:[ 0.00603465  0.01058    -0.02156826  0.0062671 ]
expert:[ 0.00603466  0.01058001 -0.02156823  0.00626706]
expert:[ 0.00603468  0.01058002 -0.02156821  0.00626703]
expert:[ 0.0060347   0.01058004 -0.02156819  0.00626701]
expert:[ 0.00603471  0.01058006 -0.02156817  0.00626698]
expert:[ 0.00603473  0.01058007 -0.02156815  0.00626695]
expert:[ 0.00603474  0.01058009 -0.02156814  0.00626693]
expert:[ 0.00603476  0.0105801  -0.02156812  0.0062669 ]
expert:[ 0.00603477  0.01058012 -0.02156811  0.00626688]
expert:[ 0.00603478  0.01058013 -0.0215681   0.00626686]
expert:[ 0.00603479  0.01058014 -0.02156809  0.00626684]
expert:[ 0.0060348   0.01058014 -0.02156807  0.00626683]
expert:[ 0.0060348   0.01058014 -0.02156805  0.00626681]
expert:[ 0.00603481  0.01058015 -0.02156803  0.00626679]
expert:[ 0.00603482  0.01058016 -0.02156801  0.00626677]
expert:[ 0.00603484  0.01058016 -0.02156799  0.00626674]
expert:[ 0.00603485  0.01058017 -0.02156798  0.00626672]
expert:[ 0.00603486  0.01058018 -0.02156796  0.0062667 ]
expert:[ 0.00603487  0.01058019 -0.02156794  0.00626668]
expert:[ 0.00603488  0.0105802  -0.02156793  0.00626666]
expert:[ 0.00603489  0.01058021 -0.02156791  0.00626664]
expert:[ 0.0060349   0.01058022 -0.02156789  0.00626661]
expert:[ 0.00603492  0.01058024 -0.02156787  0.00626659]
expert:[ 0.00603493  0.01058024 -0.02156786  0.00626657]
expert:[ 0.00603494  0.01058025 -0.02156784  0.00626655]
expert:[ 0.00603495  0.01058027 -0.02156782  0.00626653]
expert:[ 0.00603496  0.01058028 -0.02156781  0.0062665 ]
expert:[ 0.00603498  0.01058029 -0.02156779  0.00626648]
expert:[ 0.00603499  0.0105803  -0.02156777  0.00626646]
expert:[ 0.006035    0.01058031 -0.02156775  0.00626644]
expert:[ 0.00603501  0.01058032 -0.02156774  0.00626642]
expert:[ 0.00603502  0.01058033 -0.02156772  0.00626639]
expert:[ 0.00603503  0.01058034 -0.0215677   0.00626637]
expert:[ 0.00603505  0.01058035 -0.02156769  0.00626635]
expert:[ 0.00603506  0.01058036 -0.02156767  0.00626633]
expert:[ 0.00603507  0.01058037 -0.02156765  0.0062663 ]
expert:[ 0.00603508  0.01058038 -0.02156764  0.00626628]
expert:[ 0.00603509  0.01058039 -0.02156762  0.00626626]
expert:[ 0.00603511  0.0105804  -0.0215676   0.00626624]
expert:[ 0.00603512  0.01058041 -0.02156758  0.00626622]
expert:[ 0.00603513  0.01058043 -0.02156757  0.00626619]
expert:[ 0.00603514  0.01058043 -0.02156755  0.00626617]
expert:[ 0.00603515  0.01058045 -0.02156753  0.00626615]
expert:[ 0.00603516  0.01058046 -0.02156752  0.00626613]
expert:[ 0.00603518  0.01058047 -0.0215675   0.00626611]
expert:[ 0.00603519  0.01058048 -0.02156748  0.00626608]
expert:[ 0.0060352   0.01058049 -0.02156746  0.00626606]
expert:[ 0.00603521  0.0105805  -0.02156745  0.00626604]
expert:[ 0.00603522  0.01058051 -0.02156743  0.00626602]
expert:[ 0.00603523  0.01058052 -0.02156742  0.006266  ]
expert:[ 0.00603525  0.01058053 -0.0215674   0.00626597]
expert:[ 0.00603526  0.01058054 -0.02156738  0.00626595]
expert:[ 0.00603527  0.01058055 -0.02156736  0.00626593]
expert:[ 0.00603528  0.01058056 -0.02156735  0.00626591]
expert:[ 0.00603529  0.01058057 -0.02156733  0.00626589]
expert:[ 0.00603531  0.01058058 -0.02156731  0.00626586]
expert:[ 0.00603532  0.01058059 -0.0215673   0.00626584]
expert:[ 0.00603533  0.0105806  -0.02156728  0.00626582]
expert:[ 0.00603534  0.01058062 -0.02156726  0.0062658 ]
expert:[ 0.00603535  0.01058062 -0.02156724  0.00626578]
expert:[ 0.00603537  0.01058063 -0.02156723  0.00626575]
expert:[ 0.00603538  0.01058065 -0.02156721  0.00626573]
expert:[ 0.00603539  0.01058066 -0.02156719  0.00626571]
expert:[ 0.0060354   0.01058067 -0.02156718  0.00626569]
expert:[ 0.00603541  0.01058068 -0.02156716  0.00626567]
expert:[ 0.00603542  0.01058069 -0.02156714  0.00626564]
expert:[ 0.00603544  0.0105807  -0.02156712  0.00626562]
expert:[ 0.00603545  0.01058071 -0.02156711  0.0062656 ]
expert:[ 0.00603546  0.01058072 -0.02156709  0.00626558]
expert:[ 0.00603547  0.01058073 -0.02156707  0.00626556]
expert:[ 0.00603548  0.01058074 -0.02156706  0.00626553]
expert:[ 0.00603549  0.01058075 -0.02156704  0.00626551]
expert:[ 0.00603551  0.01058076 -0.02156702  0.00626549]
expert:[ 0.00603552  0.01058077 -0.02156701  0.00626547]
expert:[ 0.00603553  0.01058078 -0.02156699  0.00626545]
expert:[ 0.00603554  0.01058079 -0.02156697  0.00626542]
expert:[ 0.00603555  0.01058081 -0.02156696  0.0062654 ]
expert:[ 0.00603557  0.01058082 -0.02156694  0.00626538]
expert:[ 0.00603558  0.01058083 -0.02156692  0.00626536]
expert:[ 0.00603559  0.01058083 -0.0215669   0.00626533]
expert:[ 0.0060356   0.01058084 -0.02156689  0.00626531]
expert:[ 0.00603561  0.01058086 -0.02156687  0.00626529]
expert:[ 0.00603563  0.01058087 -0.02156685  0.00626527]
expert:[ 0.00603564  0.01058088 -0.02156683  0.00626525]
expert:[ 0.00603565  0.01058089 -0.02156682  0.00626522]
expert:[ 0.00603566  0.0105809  -0.0215668   0.0062652 ]
expert:[ 0.00603567  0.01058091 -0.02156679  0.00626518]
expert:[ 0.00603568  0.01058092 -0.02156677  0.00626516]
expert:[ 0.0060357   0.01058093 -0.02156675  0.00626514]
expert:[ 0.00603571  0.01058094 -0.02156674  0.00626511]
expert:[ 0.00603572  0.01058095 -0.02156672  0.00626509]
expert:[ 0.00603573  0.01058096 -0.0215667   0.00626507]
expert:[ 0.00603574  0.01058097 -0.02156668  0.00626505]
expert:[ 0.00603575  0.01058098 -0.02156667  0.00626503]
expert:[ 0.00603577  0.01058099 -0.02156665  0.00626501]
expert:[ 0.00603578  0.010581   -0.02156663  0.00626498]
expert:[ 0.00603579  0.01058101 -0.02156661  0.00626496]
expert:[ 0.0060358   0.01058103 -0.0215666   0.00626494]
expert:[ 0.00603581  0.01058104 -0.02156658  0.00626492]
expert:[ 0.00603582  0.01058105 -0.02156656  0.00626489]
expert:[ 0.00603584  0.01058106 -0.02156655  0.00626487]
expert:[ 0.00603585  0.01058107 -0.02156653  0.00626485]
expert:[ 0.00603586  0.01058108 -0.02156651  0.00626483]
expert:[ 0.00603587  0.01058109 -0.0215665   0.00626481]
expert:[ 0.00603588  0.0105811  -0.02156648  0.00626478]
expert:[ 0.0060359   0.01058111 -0.02156646  0.00626476]
expert:[ 0.00603591  0.01058112 -0.02156644  0.00626474]
expert:[ 0.00603592  0.01058113 -0.02156642  0.00626472]
expert:[ 0.00603593  0.01058114 -0.02156641  0.0062647 ]
expert:[ 0.00603594  0.01058115 -0.02156639  0.00626467]
expert:[ 0.00603596  0.01058116 -0.02156638  0.00626465]
expert:[ 0.00603597  0.01058117 -0.02156636  0.00626463]
expert:[ 0.00603598  0.01058118 -0.02156634  0.00626461]
expert:[ 0.00603599  0.01058119 -0.02156633  0.00626458]
expert:[ 0.006036    0.0105812  -0.02156631  0.00626456]
expert:[ 0.00603601  0.01058122 -0.02156629  0.00626454]
expert:[ 0.00603603  0.01058123 -0.02156628  0.00626452]
expert:[ 0.00603604  0.01058124 -0.02156626  0.0062645 ]
expert:[ 0.00603605  0.01058125 -0.02156624  0.00626448]
expert:[ 0.00603606  0.01058126 -0.02156622  0.00626445]
expert:[ 0.00603607  0.01058127 -0.02156621  0.00626443]
expert:[ 0.00603608  0.01058128 -0.02156619  0.00626441]
expert:[ 0.0060361   0.01058129 -0.02156617  0.00626439]
expert:[ 0.00603611  0.0105813  -0.02156616  0.00626437]
expert:[ 0.00603612  0.01058131 -0.02156614  0.00626434]
expert:[ 0.00603613  0.01058132 -0.02156612  0.00626432]
expert:[ 0.00603614  0.01058133 -0.02156611  0.0062643 ]
expert:[ 0.00603616  0.01058134 -0.02156609  0.00626428]
expert:[ 0.00603617  0.01058135 -0.02156607  0.00626425]
expert:[ 0.00603618  0.01058136 -0.02156606  0.00626423]
expert:[ 0.00603619  0.01058137 -0.02156604  0.00626421]
expert:[ 0.0060362   0.01058138 -0.02156602  0.00626419]
expert:[ 0.00603621  0.01058139 -0.02156601  0.00626417]
expert:[ 0.00603623  0.0105814  -0.02156599  0.00626415]
expert:[ 0.00603624  0.01058142 -0.02156597  0.00626412]
expert:[ 0.00603625  0.01058143 -0.02156595  0.0062641 ]
expert:[ 0.00603626  0.01058144 -0.02156593  0.00626408]
expert:[ 0.00603627  0.01058145 -0.02156592  0.00626406]
expert_success: 0
path_length: 150



-------------------------------- Iteration 0 -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
  0.05        0.8         0.2         0.05        0.8         0.2       ]
agent_success: 0

training time:  0.23329925537109375
evaluation time:  12.098150491714478
epoch time:  12.331475496292114


-------------------------------- Training stopped due to early stopping -------------------------------- 
min loss:  0.098178536


-------------------------------- Test Results -------------------------------- 
initial ob: [-0.03264955  0.51487924  0.23688597  0.          0.6         0.01499496
  0.05        0.8         0.2         0.05        0.8         0.2       ]
agent_success: 0

mean_success_rate:  0.0
Done
